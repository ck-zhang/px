use std::{
    collections::{BTreeMap, HashMap, HashSet},
    env, fmt,
    fmt::Write as _,
    fs,
    fs::File,
    io::Read,
    path::{Path, PathBuf},
    process::Command,
    str::FromStr,
};

use crate::context::{CommandContext, CommandInfo};
use crate::diagnostics::commands as diag_commands;
use crate::effects;
use crate::outcome::{CommandStatus, ExecutionOutcome, InstallUserError};
use crate::process::RunOutput;
use crate::progress::ProgressReporter;
use crate::python_sys::{detect_interpreter, detect_interpreter_tags, detect_marker_environment};
use crate::tools::disable_proxy_env;
use crate::traceback::{analyze_python_traceback, TracebackContext};
use anyhow::{anyhow, bail, Context, Result};
use pep508_rs::MarkerEnvironment;
use px_domain::{
    analyze_lock_diff, autopin_pin_key, autopin_spec_key, detect_lock_drift, format_specifier,
    load_lockfile_optional, marker_applies, merge_resolved_dependencies, render_lockfile, resolve,
    spec_requires_pin, verify_locked_artifacts, AutopinEntry, InstallOverride, LockSnapshot,
    PinSpec, ProjectSnapshot, PxOptions, ResolverRequest, ResolverTags,
};
use serde::{Deserialize, Serialize};
use serde_json::{json, Value};
use sha2::{Digest, Sha256};
use toml_edit::{Array, DocumentMut, Item, Table, TomlError, Value as TomlValue};
use tracing::warn;
use url::Url;

use super::artifacts::{ensure_exact_pins, parse_exact_pin, resolve_pins};
use crate::effects::Effects;
use crate::runtime_manager;

pub(crate) const PX_VERSION: &str = env!("CARGO_PKG_VERSION");
const SITE_CUSTOMIZE: &str = r#"# Auto-generated by px. Do not edit.
import os
import sys
import sysconfig
from pathlib import Path

def _collect_allowed_from_pythonpath():
    allowed = []
    env_py = os.environ.get("PYTHONPATH", "")
    for entry in env_py.split(os.pathsep):
        if not entry:
            continue
        allowed.append(entry)
        pth = Path(entry).joinpath("px.pth")
        try:
            with pth.open() as handle:
                for line in handle:
                    trimmed = line.strip()
                    if trimmed:
                        allowed.append(trimmed)
        except OSError:
            continue
    return allowed

def _stdlib_prefixes():
    prefixes = set()
    for key in ("stdlib", "platstdlib"):
        path = sysconfig.get_path(key)
        if path:
            prefixes.add(os.path.normpath(path))
    for attr in ("base_prefix", "base_exec_prefix", "exec_prefix"):
        value = getattr(sys, attr, None)
        if value:
            prefixes.add(os.path.normpath(value))
    return prefixes

_STD_PREFIXES = _stdlib_prefixes()
_PX_ALLOWED = os.environ.get("PX_ALLOWED_PATHS", "")
_ALLOWED = [p for p in _PX_ALLOWED.split(os.pathsep) if p]
if not _ALLOWED:
    _ALLOWED = _collect_allowed_from_pythonpath()
else:
    for entry in _collect_allowed_from_pythonpath():
        if entry not in _ALLOWED:
            _ALLOWED.append(entry)
_ALLOWED_ENV = os.pathsep.join(_ALLOWED)

_FILTER_PATHS = True
_target_exe = os.environ.get("PX_PYTHON")
if _target_exe:
    try:
        target_real = os.path.realpath(_target_exe)
        current_real = os.path.realpath(sys.executable)
        if os.path.normpath(target_real) != os.path.normpath(current_real):
            _FILTER_PATHS = False
    except Exception:
        _FILTER_PATHS = False

def _allow(path):
    if not path:
        return False
    norm = os.path.normpath(path)
    if os.environ.get("NO_SITE_PACKAGES") and ("site-packages" in norm or "dist-packages" in norm):
        return False
    if "__pypackages__" in norm:
        return True
    for prefix in _STD_PREFIXES:
        if norm == prefix or norm.startswith(prefix + os.sep):
            return True
    return False

if _FILTER_PATHS:
    _new_path = []
    _seen = set()
    _script_dir = sys.path[0] if sys.path else ""

    def _push(path):
        if not path:
            return
        if path in _seen:
            return
        _seen.add(path)
        _new_path.append(path)

    for path in _ALLOWED:
        _push(path)

    for path in sys.path:
        if _allow(path):
            _push(path)

    if _script_dir:
        _push(_script_dir)

    sys.path[:] = _new_path
    # Ensure child processes inherit the px path set instead of a mutated sys.path
    os.environ["PYTHONPATH"] = _ALLOWED_ENV

    _SITE_BIN = Path(__file__).resolve().parent / "bin"
    if not _SITE_BIN.exists():
        current = Path(__file__).resolve().parent
        for _ in range(4):
            candidate = current.parent / "bin"
            if candidate.exists():
                _SITE_BIN = candidate
                break
            current = current.parent
    if _SITE_BIN.exists():
        try:
            import sysconfig as _sysconfig
            _orig_get_path = _sysconfig.get_path
            def _px_get_path(name, scheme=None, vars=None, expand=True):
                if name == "scripts" and scheme is None:
                    return str(_SITE_BIN)
                resolved_scheme = scheme or _sysconfig.get_default_scheme()
                return _orig_get_path(name, scheme=resolved_scheme, vars=vars, expand=expand)
            _sysconfig.get_path = _px_get_path
        except Exception:
            pass
        try:
            current = os.environ.get("PATH", "")
            entries = [str(_SITE_BIN)] + [p for p in current.split(os.pathsep) if p]
            os.environ["PATH"] = os.pathsep.join(entries)
        except Exception:
            pass
else:
    px_allowed = set(_ALLOWED)
    sys.path[:] = [path for path in sys.path if path not in px_allowed]

if "" in sys.path:
    try:
        sys.path.remove("")
    except Exception:
        pass

try:
    _perf_baseline = os.environ.get("PX_PYTEST_PERF_BASELINE")
    if _perf_baseline:
        import pytest_perf.runner as _perf_runner
        def _px_perf_upstream_url(extras="", control=None):
            spec = _perf_baseline.replace("{extras}", extras)
            if control and "git+" in spec:
                return spec + f"@{control}"
            return spec
        _perf_runner.upstream_url = _px_perf_upstream_url
except Exception:
    pass

"#;

pub(crate) type ManifestSnapshot = ProjectSnapshot;

#[cfg(unix)]
fn set_exec_permissions(path: &Path) {
    use std::os::unix::fs::PermissionsExt;
    let _ = fs::set_permissions(path, fs::Permissions::from_mode(0o755));
}

#[cfg(not(unix))]
fn set_exec_permissions(_path: &Path) {
    // No-op on non-Unix; rely on defaults.
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "kebab-case")]
pub enum CommandGroup {
    Init,
    Add,
    Remove,
    Sync,
    Update,
    Run,
    Test,
    Fmt,
    Build,
    Publish,
    Migrate,
    Status,
    Why,
    Tool,
    Python,
}

impl fmt::Display for CommandGroup {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        let name = match self {
            CommandGroup::Init => "init",
            CommandGroup::Add => "add",
            CommandGroup::Remove => "remove",
            CommandGroup::Sync => "sync",
            CommandGroup::Update => "update",
            CommandGroup::Run => "run",
            CommandGroup::Test => "test",
            CommandGroup::Fmt => "fmt",
            CommandGroup::Build => "build",
            CommandGroup::Publish => "publish",
            CommandGroup::Migrate => "migrate",
            CommandGroup::Status => "status",
            CommandGroup::Why => "why",
            CommandGroup::Tool => "tool",
            CommandGroup::Python => "python",
        };
        f.write_str(name)
    }
}

pub const MISSING_PROJECT_MESSAGE: &str =
    "No px project found. Run `px init` in your project directory first.";
pub const MISSING_PROJECT_HINT: &str = "Run `px init` in your project directory first.";

pub(crate) struct InstallOutcome {
    pub(crate) state: InstallState,
    pub(crate) lockfile: String,
    pub(crate) drift: Vec<String>,
    #[allow(dead_code)]
    pub(crate) verified: bool,
}

#[derive(Clone, Copy, Debug, PartialEq)]
pub(crate) enum InstallState {
    Installed,
    UpToDate,
    Drift,
    MissingLock,
}

pub fn lock_is_fresh(snapshot: &ManifestSnapshot) -> Result<bool> {
    let marker_env = marker_env_for_snapshot(snapshot);
    match load_lockfile_optional(&snapshot.lock_path)? {
        Some(lock) => {
            if !detect_lock_drift(snapshot, &lock, marker_env.as_ref()).is_empty() {
                return Ok(false);
            }
            if let Some(fingerprint) = &lock.manifest_fingerprint {
                Ok(fingerprint == &snapshot.manifest_fingerprint)
            } else {
                Ok(true)
            }
        }
        None => Ok(false),
    }
}

pub(crate) fn relative_path_str(path: &Path, root: &Path) -> String {
    path.strip_prefix(root)
        .unwrap_or(path)
        .display()
        .to_string()
}

pub(crate) fn manifest_snapshot() -> Result<ManifestSnapshot> {
    ProjectSnapshot::read_current()
}

pub(crate) fn manifest_snapshot_at(root: &Path) -> Result<ManifestSnapshot> {
    ProjectSnapshot::read_from(root)
}

fn runtime_marker_environment(snapshot: &ManifestSnapshot) -> Result<MarkerEnvironment> {
    let runtime = prepare_project_runtime(snapshot)?;
    let resolver_env = detect_marker_environment(&runtime.record.path)?;
    resolver_env.to_marker_environment()
}

pub fn marker_env_for_snapshot(snapshot: &ManifestSnapshot) -> Option<MarkerEnvironment> {
    runtime_marker_environment(snapshot).ok().or_else(|| {
        detect_interpreter()
            .ok()
            .and_then(|python| detect_marker_environment(&python).ok())
            .and_then(|env| env.to_marker_environment().ok())
    })
}

pub(crate) fn install_snapshot(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
    frozen: bool,
    override_pins: Option<&InstallOverride>,
) -> Result<InstallOutcome> {
    let mut snapshot = snapshot.clone();
    let lockfile = snapshot.lock_path.display().to_string();
    let _ = prepare_project_runtime(&snapshot)?;

    if frozen {
        return verify_lock(&snapshot);
    }

    if lock_is_fresh(&snapshot)? {
        Ok(InstallOutcome {
            state: InstallState::UpToDate,
            lockfile,
            drift: Vec::new(),
            verified: false,
        })
    } else {
        if let Some(parent) = snapshot.lock_path.parent() {
            fs::create_dir_all(parent)?;
        }
        let mut manifest_updated = false;
        let mut manifest_dependencies = if let Some(override_data) = override_pins {
            override_data.dependencies.clone()
        } else {
            snapshot.dependencies.clone()
        };
        let mut requirements =
            merge_requirements(&manifest_dependencies, &snapshot.group_dependencies);
        let marker_env = ctx.marker_environment()?;
        let mut resolved_override = None;
        if override_pins.is_none() && ctx.config().resolver.enabled {
            let resolved = resolve_dependencies(ctx, &snapshot)?;
            if !resolved.specs.is_empty() {
                manifest_dependencies = merge_resolved_dependencies(
                    &manifest_dependencies,
                    &resolved.specs,
                    &marker_env,
                );
                persist_resolved_dependencies(&snapshot, &manifest_dependencies)?;
                manifest_updated = true;
                requirements =
                    merge_requirements(&manifest_dependencies, &snapshot.group_dependencies);
            }
            resolved_override = Some(resolved.pins);
        }
        let pins = if let Some(override_data) = override_pins {
            let mut pins: Vec<PinSpec> = override_data
                .pins
                .iter()
                .filter(|pin| marker_applies(&pin.specifier, &marker_env))
                .cloned()
                .collect();
            if pins.is_empty() {
                for spec in &requirements {
                    if !marker_applies(spec, &marker_env) {
                        continue;
                    }
                    pins.push(parse_exact_pin(spec)?);
                }
            }
            pins
        } else {
            match resolved_override {
                Some(pins) => pins,
                None => ensure_exact_pins(&marker_env, &requirements)?,
            }
        };
        if manifest_updated {
            snapshot = manifest_snapshot_at(&snapshot.root).map_err(|err| {
                InstallUserError::new(
                    "failed to reload project manifest",
                    json!({ "error": err.to_string() }),
                )
            })?;
        }
        let resolved = resolve_pins(ctx, &pins, ctx.config().resolver.force_sdist)?;
        let contents = render_lockfile(&snapshot, &resolved, PX_VERSION)?;
        fs::write(&snapshot.lock_path, contents)?;
        Ok(InstallOutcome {
            state: InstallState::Installed,
            lockfile,
            drift: Vec::new(),
            verified: false,
        })
    }
}

fn merge_requirements(base: &[String], groups: &[String]) -> Vec<String> {
    let mut merged = base.to_vec();
    merged.extend(groups.iter().cloned());
    merged.sort();
    merged.dedup();
    merged
}

pub(crate) fn refresh_project_site(
    snapshot: &ManifestSnapshot,
    ctx: &CommandContext,
) -> Result<()> {
    let _ = prepare_project_runtime(snapshot)?;
    let lock = load_lockfile_optional(&snapshot.lock_path)?.ok_or_else(|| {
        anyhow!(
            "px sync: lockfile missing at {}",
            snapshot.lock_path.display()
        )
    })?;
    let runtime = detect_runtime_metadata(ctx, snapshot)?;
    let lock_id = match lock.lock_id.clone() {
        Some(value) => value,
        None => compute_lock_hash(&snapshot.lock_path)?,
    };
    let env_id = compute_environment_id(&lock_id, &runtime);
    let env_root = snapshot.root.join(".px").join("envs").join(&env_id);
    ctx.fs().create_dir_all(&env_root)?;
    let site_dir = env_root.join("site");
    ctx.fs().create_dir_all(&site_dir)?;
    let site_packages = site_packages_dir(&site_dir, &runtime.version);
    ctx.fs().create_dir_all(&site_packages)?;
    let env_python = site_dir.join("bin").join("python");
    materialize_project_site(
        &site_dir,
        &site_packages,
        &lock,
        Some(&env_python),
        ctx.fs(),
    )?;
    write_project_metadata_stub(snapshot, &site_dir, ctx.fs())?;
    let env_python = write_python_environment_markers(&site_dir, &runtime, ctx.fs())?;
    let canonical_site = ctx.fs().canonicalize(&site_dir).unwrap_or(site_dir.clone());
    let runtime_state = StoredRuntime {
        path: runtime.path.clone(),
        version: runtime.version.clone(),
        platform: runtime.platform.clone(),
    };
    let env_state = StoredEnvironment {
        id: env_id,
        lock_id,
        platform: runtime.platform.clone(),
        site_packages: canonical_site.display().to_string(),
        python: StoredPython {
            path: env_python.display().to_string(),
            version: runtime.version.clone(),
        },
    };
    persist_project_state(ctx.fs(), &snapshot.root, env_state, runtime_state)
}

pub fn materialize_project_site(
    site_dir: &Path,
    site_packages: &Path,
    lock: &LockSnapshot,
    python: Option<&Path>,
    fs: &dyn effects::FileSystem,
) -> Result<()> {
    fs.create_dir_all(site_dir)?;
    fs.create_dir_all(site_packages)?;
    let pth_path = site_dir.join("px.pth");
    let pth_copy_path = site_packages.join("px.pth");
    let bin_dir = site_dir.join("bin");
    fs.create_dir_all(&bin_dir)?;
    let mut entries = Vec::new();
    for dep in &lock.resolved {
        let Some(artifact) = &dep.artifact else {
            continue;
        };
        if artifact.cached_path.is_empty() {
            continue;
        }
        let wheel_path = PathBuf::from(&artifact.cached_path);
        if !wheel_path.exists() {
            continue;
        }
        let dist_path = wheel_path.with_extension("dist");
        let entry_path = if dist_path.exists() {
            dist_path
        } else {
            wheel_path
        };
        let _ = materialize_wheel_scripts(&entry_path, &bin_dir, python);
        let canonical = entry_path.canonicalize().unwrap_or(entry_path);
        entries.push(canonical);
    }

    entries.sort();
    entries.dedup();

    let mut contents = entries
        .iter()
        .map(|path| path.display().to_string())
        .collect::<Vec<_>>()
        .join("\n");
    if !contents.is_empty() {
        contents.push('\n');
    }
    fs.write(&pth_path, contents.as_bytes())?;
    fs.write(&pth_copy_path, contents.as_bytes())?;
    write_sitecustomize(site_dir, Some(site_packages), fs)?;
    Ok(())
}

#[derive(Clone, Debug)]
struct EditableProjectMetadata {
    name: String,
    normalized_name: String,
    version: String,
    requires_python: Option<String>,
    requires_dist: Vec<String>,
    optional_requires: BTreeMap<String, Vec<String>>,
    summary: Option<String>,
    entry_points: BTreeMap<String, BTreeMap<String, String>>,
    top_level: Vec<String>,
}

fn write_project_metadata_stub(
    snapshot: &ManifestSnapshot,
    site_dir: &Path,
    fs_ops: &dyn effects::FileSystem,
) -> Result<()> {
    let metadata = match load_editable_project_metadata(&snapshot.manifest_path, fs_ops) {
        Ok(meta) => meta,
        Err(err) => {
            warn!(
                error = %err,
                path = %snapshot.manifest_path.display(),
                "skipping editable metadata stub"
            );
            return Ok(());
        }
    };

    cleanup_editable_metadata(site_dir, &metadata.normalized_name, fs_ops)?;
    if let Some(site_packages) = detect_local_site_packages(fs_ops, site_dir) {
        let prefix = format!("{}-", metadata.normalized_name);
        let mut installed = false;
        if let Ok(entries) = fs_ops.read_dir(&site_packages) {
            for entry in entries.flatten() {
                let file_name = entry.file_name();
                let name = file_name.to_str().unwrap_or_default();
                if name.starts_with(&prefix) && name.ends_with(".dist-info") {
                    installed = true;
                    break;
                }
            }
        }
        if installed {
            if let Ok(entries) = fs_ops.read_dir(site_dir) {
                for entry in entries.flatten() {
                    let file_name = entry.file_name();
                    let name = file_name.to_str().unwrap_or_default();
                    if name.starts_with(&prefix) && name.ends_with(".dist-info") {
                        let _ = fs_ops.remove_dir_all(&entry.path());
                    }
                }
            }
            return Ok(());
        }
    }
    let dist_dir = site_dir.join(format!(
        "{}-{}.dist-info",
        metadata.normalized_name, metadata.version
    ));
    fs_ops.create_dir_all(&dist_dir)?;

    let mut record_paths = Vec::new();

    let metadata_body = render_editable_metadata(&metadata);
    fs_ops.write(&dist_dir.join("METADATA"), metadata_body.as_bytes())?;
    record_paths.push(dist_dir.join("METADATA"));
    if let Some(entry_points) = render_editable_entry_points(&metadata) {
        fs_ops.write(&dist_dir.join("entry_points.txt"), entry_points.as_bytes())?;
        record_paths.push(dist_dir.join("entry_points.txt"));
    }
    let bin_dir = site_dir.join("bin");
    let python_path = bin_dir.join("python");
    let python = Some(python_path.as_path());
    let install_entrypoints = |entries: &BTreeMap<String, String>,
                               record_paths: &mut Vec<PathBuf>| {
        for (name, target) in entries {
            let _ = fs::remove_file(bin_dir.join(name));
            let target_value = target.split_whitespace().next().unwrap_or(target).trim();
            if let Some((module, callable)) = target_value.split_once(':') {
                if let Ok(script_path) =
                    write_entrypoint_script(&bin_dir, name, module.trim(), callable.trim(), python)
                {
                    record_paths.push(script_path);
                }
            }
        }
    };
    if let Some(entries) = metadata.entry_points.get("console_scripts") {
        install_entrypoints(entries, &mut record_paths);
    }
    if let Some(entries) = metadata.entry_points.get("gui_scripts") {
        install_entrypoints(entries, &mut record_paths);
    }

    let project_root = fs_ops
        .canonicalize(&snapshot.root)
        .unwrap_or_else(|_| snapshot.root.clone());
    let direct_url = Url::from_file_path(&project_root)
        .ok()
        .map(|url| url.to_string())
        .unwrap_or_else(|| format!("file://{}", project_root.display()));
    let direct_url = serde_json::to_string_pretty(&json!({
        "dir_info": { "editable": true },
        "url": direct_url,
    }))?;
    fs_ops.write(&dist_dir.join("direct_url.json"), direct_url.as_bytes())?;
    record_paths.push(dist_dir.join("direct_url.json"));
    fs_ops.write(&dist_dir.join("INSTALLER"), b"px\n")?;
    record_paths.push(dist_dir.join("INSTALLER"));
    fs_ops.write(&dist_dir.join("PX-EDITABLE"), b"px\n")?;
    record_paths.push(dist_dir.join("PX-EDITABLE"));

    if !metadata.top_level.is_empty() {
        let mut body = metadata.top_level.join("\n");
        body.push('\n');
        fs_ops.write(&dist_dir.join("top_level.txt"), body.as_bytes())?;
        record_paths.push(dist_dir.join("top_level.txt"));
    }
    write_record_file(site_dir, &dist_dir, record_paths, fs_ops)?;
    Ok(())
}

fn cleanup_editable_metadata(
    site_dir: &Path,
    normalized_name: &str,
    fs_ops: &dyn effects::FileSystem,
) -> Result<()> {
    if let Ok(entries) = fs_ops.read_dir(site_dir) {
        for entry in entries.flatten() {
            let path = entry.path();
            let Some(name) = path.file_name().and_then(|value| value.to_str()) else {
                continue;
            };
            if !name.starts_with(&format!("{normalized_name}-")) || !name.ends_with(".dist-info") {
                continue;
            }
            let marker = path.join("PX-EDITABLE");
            if marker.exists() {
                let _ = fs_ops.remove_dir_all(&path);
            }
        }
    }
    Ok(())
}

fn write_record_file(
    site_dir: &Path,
    dist_dir: &Path,
    mut record_paths: Vec<PathBuf>,
    fs_ops: &dyn effects::FileSystem,
) -> Result<()> {
    let record_path = dist_dir.join("RECORD");
    record_paths.push(record_path.clone());
    let mut seen = HashSet::new();
    let mut lines = Vec::new();
    for path in record_paths {
        if !path.exists() {
            continue;
        }
        let rel = path
            .strip_prefix(site_dir)
            .unwrap_or_else(|_| path.as_path());
        let rel_str = rel.to_string_lossy().replace('\\', "/");
        if !seen.insert(rel_str.clone()) {
            continue;
        }
        lines.push(format!("{rel_str},,"));
    }
    lines.sort();
    fs_ops.write(&record_path, lines.join("\n").as_bytes())?;
    Ok(())
}

fn load_editable_project_metadata(
    manifest_path: &Path,
    fs_ops: &dyn effects::FileSystem,
) -> Result<EditableProjectMetadata> {
    let contents = fs_ops.read_to_string(manifest_path)?;
    let doc: DocumentMut = contents.parse()?;
    let project = project_table(&doc)?;
    let name = project
        .get("name")
        .and_then(Item::as_str)
        .ok_or_else(|| anyhow!("pyproject missing [project].name"))?
        .to_string();
    let normalized_name = normalize_project_name(&name);
    let root = manifest_path
        .parent()
        .map(Path::to_path_buf)
        .unwrap_or_else(|| PathBuf::from("."));
    let version = project
        .get("version")
        .and_then(Item::as_str)
        .map(std::string::ToString::to_string)
        .or_else(|| infer_version_from_version_file(&root, &doc, fs_ops))
        .or_else(|| infer_version_from_versioneer(&root, &normalized_name, fs_ops))
        .or_else(|| infer_version_from_sources(&root, &normalized_name, fs_ops))
        .unwrap_or_else(|| "0.0.0+unknown".to_string());
    let requires_python = project
        .get("requires-python")
        .and_then(Item::as_str)
        .map(std::string::ToString::to_string);
    let requires_dist = project
        .get("dependencies")
        .and_then(Item::as_array)
        .map(|array| {
            array
                .iter()
                .filter_map(|value| value.as_str().map(std::string::ToString::to_string))
                .collect::<Vec<_>>()
        })
        .unwrap_or_default();
    let optional_requires = collect_optional_dependencies(project);
    let summary = project
        .get("description")
        .and_then(Item::as_str)
        .map(std::string::ToString::to_string);
    let entry_points = collect_entry_points(project);
    let top_level = discover_top_level_modules(&root, &normalized_name, fs_ops);

    Ok(EditableProjectMetadata {
        name,
        normalized_name,
        version,
        requires_python,
        requires_dist,
        optional_requires,
        summary,
        entry_points,
        top_level,
    })
}

fn infer_version_from_version_file(
    manifest_root: &Path,
    doc: &DocumentMut,
    fs_ops: &dyn effects::FileSystem,
) -> Option<String> {
    let candidates = [hatch_version_file(doc), setuptools_scm_version_file(doc)];
    for relative in candidates.into_iter().flatten() {
        let path = manifest_root.join(relative);
        if fs_ops.metadata(&path).is_err() {
            continue;
        }
        if let Ok(contents) = fs_ops.read_to_string(&path) {
            for line in contents.lines() {
                let trimmed = line.trim_start();
                if let Some(raw) = trimmed.strip_prefix("version =") {
                    let value = raw.trim().trim_matches('"');
                    if !value.is_empty() {
                        return Some(value.to_string());
                    }
                }
                if trimmed.starts_with("__version__") {
                    if let Some((_, raw_value)) = trimmed.split_once('=') {
                        let value = raw_value.trim();
                        if value.starts_with('"') || value.starts_with('\'') {
                            let clean = value
                                .trim_matches(|ch| matches!(ch, '"' | '\''))
                                .to_string();
                            if !clean.is_empty() {
                                return Some(clean);
                            }
                        }
                    }
                }
            }
        }
    }
    None
}

fn infer_version_from_versioneer(
    project_root: &Path,
    normalized_name: &str,
    fs_ops: &dyn effects::FileSystem,
) -> Option<String> {
    let module = normalized_name.replace(['-', '.'], "_").to_lowercase();
    let candidates = [
        project_root.join("src").join(&module).join("_version.py"),
        project_root.join(&module).join("_version.py"),
    ];
    let Some(path) = candidates.iter().find(|path| fs_ops.metadata(path).is_ok()) else {
        return None;
    };

    let python = detect_interpreter().ok()?;
    let script = format!(
        r#"import importlib.util, json, pathlib
path = pathlib.Path({path:?})
spec = importlib.util.spec_from_file_location("px_versioneer", path)
if spec is None or spec.loader is None:
    print(json.dumps({{}}))
    raise SystemExit(0)
mod = importlib.util.module_from_spec(spec)
spec.loader.exec_module(mod)
getter = getattr(mod, "get_versions", None) or getattr(mod, "get_version", None)
version = None
if callable(getter):
    value = getter()
    if isinstance(value, dict):
        version = value.get("version") or value.get("closest-tag") or value.get("closest_tag")
    else:
        version = value
print(json.dumps({{"version": version}}))
"#
    );
    let output = Command::new(python)
        .args(["-c", &script])
        .current_dir(project_root)
        .output()
        .ok()?;
    if !output.status.success() {
        return None;
    }
    let payload: Value = serde_json::from_slice(&output.stdout).ok()?;
    payload
        .get("version")
        .and_then(Value::as_str)
        .map(std::string::ToString::to_string)
        .filter(|value| !value.is_empty())
}

fn infer_version_from_sources(
    project_root: &Path,
    normalized_name: &str,
    fs_ops: &dyn effects::FileSystem,
) -> Option<String> {
    let module_name = normalized_name.replace(['-', '.'], "_").to_lowercase();
    let candidates = [
        project_root
            .join("src")
            .join(&module_name)
            .join("__init__.py"),
        project_root.join(&module_name).join("__init__.py"),
    ];
    for candidate in candidates {
        if fs_ops.metadata(&candidate).is_err() {
            continue;
        }
        if let Ok(contents) = fs_ops.read_to_string(&candidate) {
            for line in contents.lines() {
                let trimmed = line.trim_start();
                if !trimmed.starts_with("__version__") {
                    continue;
                }
                if let Some((_, raw_value)) = trimmed.split_once('=') {
                    let value = raw_value.trim();
                    let quoted = (value.starts_with('"') && value.ends_with('"'))
                        || (value.starts_with('\'') && value.ends_with('\''));
                    if !quoted {
                        continue;
                    }
                    let cleaned = value.trim_matches(|ch| ch == '"' || ch == '\'');
                    if !cleaned.is_empty() {
                        return Some(cleaned.to_string());
                    }
                }
            }
        }
    }
    None
}

fn discover_top_level_modules(
    project_root: &Path,
    normalized_name: &str,
    fs_ops: &dyn effects::FileSystem,
) -> Vec<String> {
    let mut names = Vec::new();
    let mut push_name = |value: &str| {
        if !value.is_empty() && !value.starts_with('.') && value != "__pycache__" {
            names.push(value.to_string());
        }
    };
    for base in [project_root.join("src"), project_root.to_path_buf()] {
        if let Ok(entries) = fs_ops.read_dir(&base) {
            for entry in entries.flatten() {
                let path = entry.path();
                if path.is_dir() {
                    if fs_ops.metadata(&path.join("__init__.py")).is_ok() {
                        if let Some(value) = path.file_name().and_then(|name| name.to_str()) {
                            push_name(value);
                        }
                    }
                } else if path.extension().is_some_and(|ext| ext == "py") {
                    if let Some(stem) = path.file_stem().and_then(|name| name.to_str()) {
                        push_name(stem);
                    }
                }
            }
        }
    }
    if names.is_empty() {
        names.push(normalized_name.replace(['-', '.'], "_").to_lowercase());
    }
    names.sort();
    names.dedup();
    names
}

fn collect_optional_dependencies(project: &Table) -> BTreeMap<String, Vec<String>> {
    let mut extras = BTreeMap::new();
    if let Some(optional) = project
        .get("optional-dependencies")
        .and_then(toml_edit::Item::as_table)
    {
        for (name, array) in optional.iter() {
            if let Some(values) = array.as_array() {
                let mut deps = Vec::new();
                for value in values {
                    if let Some(spec) = value.as_str() {
                        deps.push(spec.to_string());
                    }
                }
                if !deps.is_empty() {
                    extras.insert(name.to_string(), deps);
                }
            }
        }
    }
    extras
}

fn collect_entry_points(project: &Table) -> BTreeMap<String, BTreeMap<String, String>> {
    let mut groups = BTreeMap::new();
    collect_entry_point_group(project, "scripts", "console_scripts", &mut groups);
    collect_entry_point_group(project, "gui-scripts", "gui_scripts", &mut groups);
    if let Some(ep_table) = project
        .get("entry-points")
        .and_then(toml_edit::Item::as_table)
    {
        for (group, table) in ep_table.iter() {
            if let Some(entries) = table.as_table() {
                let mut mapped = BTreeMap::new();
                for (name, value) in entries.iter() {
                    if let Some(target) = value.as_str() {
                        mapped.insert(name.to_string(), target.to_string());
                    }
                }
                if !mapped.is_empty() {
                    groups.insert(group.to_string(), mapped);
                }
            }
        }
    }
    groups
}

fn collect_entry_point_group(
    project: &Table,
    project_key: &str,
    entry_point_group: &str,
    groups: &mut BTreeMap<String, BTreeMap<String, String>>,
) {
    if let Some(scripts) = project.get(project_key).and_then(toml_edit::Item::as_table) {
        let mut mapped = BTreeMap::new();
        for (name, value) in scripts.iter() {
            if let Some(target) = value.as_str() {
                mapped.insert(name.to_string(), target.to_string());
            }
        }
        if !mapped.is_empty() {
            groups.insert(entry_point_group.to_string(), mapped);
        }
    }
}

fn render_editable_entry_points(metadata: &EditableProjectMetadata) -> Option<String> {
    if metadata.entry_points.is_empty() {
        return None;
    }
    let mut sections = Vec::new();
    for (group, entries) in &metadata.entry_points {
        sections.push(format!("[{group}]"));
        for (name, target) in entries {
            sections.push(format!("{name} = {target}"));
        }
        sections.push(String::new());
    }
    Some(sections.join("\n"))
}

fn render_editable_metadata(metadata: &EditableProjectMetadata) -> String {
    let mut lines = Vec::new();
    lines.push("Metadata-Version: 2.1".to_string());
    lines.push(format!("Name: {}", metadata.name));
    lines.push(format!("Version: {}", metadata.version));
    if let Some(summary) = &metadata.summary {
        lines.push(format!("Summary: {summary}"));
    }
    if let Some(rp) = &metadata.requires_python {
        lines.push(format!("Requires-Python: {rp}"));
    }
    for extra in metadata.optional_requires.keys() {
        lines.push(format!("Provides-Extra: {extra}"));
    }
    for req in &metadata.requires_dist {
        lines.push(format!("Requires-Dist: {req}"));
    }
    for (extra, reqs) in &metadata.optional_requires {
        for req in reqs {
            lines.push(format!(r#"Requires-Dist: {req} ; extra == "{extra}""#));
        }
    }
    lines.push(String::new());
    lines.join("\n")
}

fn normalize_project_name(name: &str) -> String {
    let mut result = String::new();
    for ch in name.chars() {
        if matches!(ch, '-' | '.' | ' ') {
            result.push('_');
        } else {
            result.push(ch);
        }
    }
    result
}

fn write_entrypoint_script(
    bin_dir: &Path,
    name: &str,
    module: &str,
    callable: &str,
    python: Option<&Path>,
) -> Result<PathBuf> {
    fs::create_dir_all(bin_dir)?;
    let python_shebang = python
        .map(|path| path.display().to_string())
        .unwrap_or_else(|| "/usr/bin/env python3".to_string());
    let parts: Vec<String> = callable
        .split('.')
        .filter(|part| !part.is_empty())
        .map(ToString::to_string)
        .collect();
    let parts_repr = format!("{parts:?}");
    let contents = format!(
        "#!{python_shebang}\nimport importlib\nimport sys\n\ndef _load():\n    module = importlib.import_module({module:?})\n    target = module\n    for attr in {parts_repr}:\n        target = getattr(target, attr)\n    return target\n\nif __name__ == '__main__':\n    sys.exit(_load()())\n"
    );
    let script_path = bin_dir.join(name);
    fs::write(&script_path, contents)?;
    set_exec_permissions(&script_path);
    Ok(script_path)
}

fn materialize_wheel_scripts(
    artifact_path: &Path,
    bin_dir: &Path,
    python: Option<&Path>,
) -> Result<()> {
    fs::create_dir_all(bin_dir)?;
    if artifact_path.extension().is_some_and(|ext| ext == "dist") && artifact_path.is_dir() {
        let entry_points = fs::read_dir(artifact_path)?
            .filter_map(|entry| entry.ok())
            .map(|entry| entry.path())
            .find(|path| path.extension().is_some_and(|ext| ext == "dist-info"))
            .and_then(|dist_info| {
                let ep = dist_info.join("entry_points.txt");
                ep.exists().then_some(ep)
            });
        if let Some(ep_path) = entry_points {
            if let Ok(contents) = fs::read_to_string(&ep_path) {
                let mut section = String::new();
                for line in contents.lines() {
                    let trimmed = line.trim();
                    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with(';') {
                        continue;
                    }
                    if trimmed.starts_with('[') && trimmed.ends_with(']') {
                        section = trimmed
                            .trim_start_matches('[')
                            .trim_end_matches(']')
                            .to_string();
                        continue;
                    }
                    if section != "console_scripts" && section != "gui_scripts" {
                        continue;
                    }
                    if let Some((name, target)) = trimmed.split_once('=') {
                        let entry_name = name.trim();
                        let raw_target = target.trim();
                        let target_value = raw_target
                            .split_whitespace()
                            .next()
                            .unwrap_or(raw_target)
                            .trim();
                        if let Some((module, callable)) = target_value.split_once(':') {
                            let _ = write_entrypoint_script(
                                bin_dir,
                                entry_name,
                                module.trim(),
                                callable.trim(),
                                python,
                            );
                        }
                    }
                }
            }
        }

        let script_dirs: Vec<PathBuf> = fs::read_dir(artifact_path)?
            .filter_map(|entry| entry.ok())
            .map(|entry| entry.path())
            .filter(|path| {
                path.file_name()
                    .and_then(|name| name.to_str())
                    .map(|name| name.ends_with(".data"))
                    .unwrap_or(false)
            })
            .map(|data_dir| data_dir.join("scripts"))
            .filter(|path| path.exists())
            .collect();
        for dir in script_dirs {
            for entry in fs::read_dir(&dir)? {
                let entry = entry?;
                if entry.file_type()?.is_file() {
                    let dest = bin_dir.join(entry.file_name());
                    fs::copy(entry.path(), &dest)?;
                    set_exec_permissions(&dest);
                }
            }
        }
        return Ok(());
    }

    if artifact_path.extension().is_some_and(|ext| ext == "whl") && artifact_path.is_file() {
        let file = File::open(artifact_path)?;
        let mut archive = zip::ZipArchive::new(file)?;

        if let Some(idx) = (0..archive.len()).find(|i| {
            archive
                .by_index(*i)
                .ok()
                .map(|file| file.name().ends_with("entry_points.txt"))
                .unwrap_or(false)
        }) {
            if let Ok(mut ep_file) = archive.by_index(idx) {
                let mut contents = String::new();
                ep_file.read_to_string(&mut contents)?;
                let mut section = String::new();
                for line in contents.lines() {
                    let trimmed = line.trim();
                    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with(';') {
                        continue;
                    }
                    if trimmed.starts_with('[') && trimmed.ends_with(']') {
                        section = trimmed
                            .trim_start_matches('[')
                            .trim_end_matches(']')
                            .to_string();
                        continue;
                    }
                    if section != "console_scripts" && section != "gui_scripts" {
                        continue;
                    }
                    if let Some((name, target)) = trimmed.split_once('=') {
                        let entry_name = name.trim();
                        let raw_target = target.trim();
                        let target_value = raw_target
                            .split_whitespace()
                            .next()
                            .unwrap_or(raw_target)
                            .trim();
                        if let Some((module, callable)) = target_value.split_once(':') {
                            let _ = write_entrypoint_script(
                                bin_dir,
                                entry_name,
                                module.trim(),
                                callable.trim(),
                                python,
                            );
                        }
                    }
                }
            }
        }

        for i in 0..archive.len() {
            let mut file = archive.by_index(i)?;
            let name = file.name().to_string();
            if !name.contains(".data/scripts/") || name.ends_with('/') {
                continue;
            }
            if let Some((_, script_name)) = name.rsplit_once(".data/scripts/") {
                let dest = bin_dir.join(script_name);
                let mut contents = Vec::new();
                file.read_to_end(&mut contents)?;
                fs::write(&dest, contents)?;
                set_exec_permissions(&dest);
            }
        }
    }

    Ok(())
}

fn write_sitecustomize(
    site_dir: &Path,
    extra_dir: Option<&Path>,
    fs: &dyn effects::FileSystem,
) -> Result<()> {
    let path = site_dir.join("sitecustomize.py");
    fs.write(&path, SITE_CUSTOMIZE.as_bytes())?;
    if let Some(extra) = extra_dir {
        fs.create_dir_all(extra)?;
        fs.write(&extra.join("sitecustomize.py"), SITE_CUSTOMIZE.as_bytes())?;
    }
    Ok(())
}

pub(crate) fn write_python_environment_markers(
    site_dir: &Path,
    runtime: &RuntimeMetadata,
    fs: &dyn effects::FileSystem,
) -> Result<PathBuf> {
    let bin_dir = site_dir.join("bin");
    fs.create_dir_all(&bin_dir)?;

    let runtime_path = PathBuf::from(&runtime.path);
    let canonical_runtime = fs
        .canonicalize(&runtime_path)
        .unwrap_or_else(|_| runtime_path.clone());
    let home = canonical_runtime
        .parent()
        .and_then(|parent| parent.parent())
        .unwrap_or_else(|| canonical_runtime.parent().unwrap_or(Path::new("")));
    let pyvenv_cfg = format!(
        "home = {}\ninclude-system-site-packages = false\nversion = {}\n",
        home.display(),
        runtime.version
    );
    fs.write(&site_dir.join("pyvenv.cfg"), pyvenv_cfg.as_bytes())?;

    let mut names = vec!["python".to_string(), "python3".to_string()];
    if let Some((major, minor)) = parse_python_version(&runtime.version) {
        names.push(format!("python{major}"));
        names.push(format!("python{major}.{minor}"));
    }
    for name in names {
        let dest = bin_dir.join(&name);
        install_python_link(&canonical_runtime, &dest)?;
    }
    Ok(bin_dir.join("python"))
}

fn parse_python_version(version: &str) -> Option<(String, String)> {
    let mut parts = version.split('.');
    let major = parts.next()?.to_string();
    let minor = parts.next().unwrap_or_default().to_string();
    if major.is_empty() || minor.is_empty() {
        None
    } else {
        Some((major, minor))
    }
}

pub(crate) fn site_packages_dir(site_dir: &Path, runtime_version: &str) -> PathBuf {
    if let Some((major, minor)) = parse_python_version(runtime_version) {
        site_dir
            .join("lib")
            .join(format!("python{major}.{minor}"))
            .join("site-packages")
    } else {
        site_dir.join("site-packages")
    }
}

fn install_python_link(source: &Path, dest: &Path) -> Result<()> {
    if dest.exists() {
        let _ = fs::remove_file(dest);
    }
    if let Some(parent) = dest.parent() {
        fs::create_dir_all(parent)?;
    }
    #[cfg(unix)]
    {
        use std::os::unix::fs::symlink;
        if symlink(source, dest).is_ok() {
            return Ok(());
        }
    }
    if std::fs::hard_link(source, dest).is_ok() {
        return Ok(());
    }
    fs::copy(source, dest)?;
    set_exec_permissions(dest);
    Ok(())
}

fn select_python_from_site(
    site_bin: &Option<PathBuf>,
    runtime_path: &str,
    runtime_version: &str,
) -> String {
    if let Some(bin) = site_bin {
        let mut candidates = vec![bin.join("python"), bin.join("python3")];
        if let Some((major, minor)) = parse_python_version(runtime_version) {
            candidates.push(bin.join(format!("python{major}")));
            candidates.push(bin.join(format!("python{major}.{minor}")));
        }
        if let Some(found) = candidates.into_iter().find(|path| path.exists()) {
            return found.display().to_string();
        }
    }
    runtime_path.to_string()
}

fn persist_project_state(
    filesystem: &dyn effects::FileSystem,
    project_root: &Path,
    env: StoredEnvironment,
    runtime: StoredRuntime,
) -> Result<()> {
    let mut state = load_project_state(filesystem, project_root)?;
    state.current_env = Some(env);
    state.runtime = Some(runtime);
    write_project_state(filesystem, project_root, &state)
}

pub(crate) fn load_project_state(
    filesystem: &dyn effects::FileSystem,
    project_root: &Path,
) -> Result<ProjectState> {
    let path = project_root.join(".px").join("state.json");
    match filesystem.read_to_string(&path) {
        Ok(contents) => {
            let state: ProjectState = serde_json::from_str(&contents)
                .with_context(|| format!("failed to parse {}", path.display()))?;
            validate_project_state(&state)?;
            Ok(state)
        }
        Err(err) => {
            if filesystem.metadata(&path).is_ok() {
                Err(err)
            } else {
                Ok(ProjectState::default())
            }
        }
    }
}

fn write_project_state(
    filesystem: &dyn effects::FileSystem,
    project_root: &Path,
    state: &ProjectState,
) -> Result<()> {
    let path = project_root.join(".px").join("state.json");
    let mut contents = serde_json::to_vec_pretty(state)?;
    contents.push(b'\n');
    if let Some(dir) = path.parent() {
        filesystem.create_dir_all(dir)?;
    }
    let tmp_path = path.with_extension("json.tmp");
    filesystem.write(&tmp_path, &contents)?;
    std::fs::rename(&tmp_path, &path).with_context(|| format!("writing {}", path.display()))?;
    Ok(())
}

fn validate_project_state(state: &ProjectState) -> Result<()> {
    if let Some(env) = &state.current_env {
        if env.id.trim().is_empty() || env.lock_id.trim().is_empty() {
            bail!("invalid project state: missing environment identity");
        }
        if env.site_packages.trim().is_empty() {
            bail!("invalid project state: missing site-packages path");
        }
        if env.python.path.trim().is_empty() || env.python.version.trim().is_empty() {
            bail!("invalid project state: missing python metadata");
        }
    }
    if let Some(runtime) = &state.runtime {
        if runtime.path.trim().is_empty()
            || runtime.version.trim().is_empty()
            || runtime.platform.trim().is_empty()
        {
            bail!("invalid project runtime metadata");
        }
    }
    Ok(())
}

fn resolve_project_site(
    filesystem: &dyn effects::FileSystem,
    project_root: &Path,
) -> Result<Option<PathBuf>> {
    let state = load_project_state(filesystem, project_root)?;
    if let Some(env) = state.current_env {
        let path = PathBuf::from(env.site_packages);
        if path.exists() {
            return Ok(Some(path));
        }
    }
    let fallback = project_root.join(".px").join("site");
    if fallback.exists() {
        Ok(Some(fallback))
    } else {
        Ok(None)
    }
}

#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub(crate) struct ProjectState {
    #[serde(default)]
    pub(crate) current_env: Option<StoredEnvironment>,
    #[serde(default)]
    pub(crate) runtime: Option<StoredRuntime>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub(crate) struct StoredEnvironment {
    pub(crate) id: String,
    #[serde(alias = "lock_hash")]
    pub(crate) lock_id: String,
    pub(crate) platform: String,
    pub(crate) site_packages: String,
    pub(crate) python: StoredPython,
}

#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub(crate) struct StoredRuntime {
    pub(crate) path: String,
    pub(crate) version: String,
    pub(crate) platform: String,
}
#[derive(Debug, Clone, Serialize, Deserialize)]
pub(crate) struct StoredPython {
    pub(crate) path: String,
    pub(crate) version: String,
}

#[derive(Clone, Debug)]
pub(crate) struct RuntimeMetadata {
    pub(crate) path: String,
    pub(crate) version: String,
    pub(crate) platform: String,
}

pub(crate) fn prepare_project_runtime(
    snapshot: &ManifestSnapshot,
) -> Result<runtime_manager::RuntimeSelection> {
    if let Ok(explicit) = env::var("PX_RUNTIME_PYTHON") {
        if let Ok(details) = runtime_manager::inspect_python(Path::new(&explicit)) {
            let requirement = snapshot
                .python_override
                .as_deref()
                .unwrap_or(&snapshot.python_requirement);
            if let (Ok(specs), Ok(version)) = (
                pep440_rs::VersionSpecifiers::from_str(requirement),
                pep440_rs::Version::from_str(&details.full_version),
            ) {
                if specs.contains(&version) {
                    let channel = runtime_manager::format_channel(&details.full_version)
                        .unwrap_or_else(|_| requirement.to_string());
                    let record = runtime_manager::RuntimeRecord {
                        version: channel,
                        full_version: details.full_version,
                        path: details.executable,
                        default: false,
                    };
                    let selection = runtime_manager::RuntimeSelection {
                        record,
                        source: runtime_manager::RuntimeSource::Explicit,
                    };
                    env::set_var("PX_RUNTIME_PYTHON", &selection.record.path);
                    return Ok(selection);
                }
            }
        }
    }

    let selection = runtime_manager::resolve_runtime(
        snapshot.python_override.as_deref(),
        &snapshot.python_requirement,
    )
    .map_err(|err| {
        InstallUserError::new(
            "python runtime unavailable",
            json!({
                "hint": err.to_string(),
                "reason": "missing_runtime",
            }),
        )
    })?;
    env::set_var("PX_RUNTIME_PYTHON", &selection.record.path);
    Ok(selection)
}

pub(crate) fn detect_runtime_metadata(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
) -> Result<RuntimeMetadata> {
    let path = ctx.python_runtime().detect_interpreter()?;
    let version = probe_python_version(ctx, snapshot, &path)?;
    let tags = detect_interpreter_tags(&path)?;
    let platform = tags
        .platform
        .first()
        .cloned()
        .unwrap_or_else(|| "any".to_string());
    Ok(RuntimeMetadata {
        path,
        version,
        platform,
    })
}

fn compute_environment_id(lock_id: &str, runtime: &RuntimeMetadata) -> String {
    let mut hasher = Sha256::new();
    hasher.update(lock_id.as_bytes());
    hasher.update(runtime.version.as_bytes());
    hasher.update(runtime.platform.as_bytes());
    hasher.update(runtime.path.as_bytes());
    let digest = format!("{:x}", hasher.finalize());
    let short = &digest[..digest.len().min(16)];
    format!("env-{short}")
}

pub(crate) fn compute_lock_hash(lock_path: &Path) -> Result<String> {
    let contents = fs::read(lock_path)?;
    let mut hasher = Sha256::new();
    hasher.update(contents);
    Ok(format!("{:x}", hasher.finalize()))
}

fn probe_python_version(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
    python: &str,
) -> Result<String> {
    const SCRIPT: &str =
        "import json, platform; print(json.dumps({'version': platform.python_version()}))";
    let args = vec!["-c".to_string(), SCRIPT.to_string()];
    let output = ctx
        .python_runtime()
        .run_command(python, &args, &[], &snapshot.root)?;
    if output.code != 0 {
        return Err(anyhow!("python exited with {}", output.code));
    }
    let payload: RuntimeProbe =
        serde_json::from_str(output.stdout.trim()).context("invalid runtime probe payload")?;
    Ok(payload.version)
}

#[derive(Deserialize)]
struct RuntimeProbe {
    version: String,
}

fn verify_lock(snapshot: &ManifestSnapshot) -> Result<InstallOutcome> {
    let lockfile = snapshot.lock_path.display().to_string();
    let marker_env = marker_env_for_snapshot(snapshot);
    match load_lockfile_optional(&snapshot.lock_path)? {
        Some(lock) => {
            let report = analyze_lock_diff(snapshot, &lock, marker_env.as_ref());
            let mut drift = report.to_messages();
            if drift.is_empty() {
                drift = verify_locked_artifacts(&lock);
            }
            if drift.is_empty() {
                Ok(InstallOutcome {
                    state: InstallState::UpToDate,
                    lockfile,
                    drift,
                    verified: true,
                })
            } else {
                Ok(InstallOutcome {
                    state: InstallState::Drift,
                    lockfile,
                    drift,
                    verified: true,
                })
            }
        }
        None => Ok(InstallOutcome {
            state: InstallState::MissingLock,
            lockfile,
            drift: Vec::new(),
            verified: true,
        }),
    }
}

pub(crate) struct ResolvedSpecOutput {
    pub(crate) specs: Vec<String>,
    pub(crate) pins: Vec<PinSpec>,
}

fn resolve_dependencies(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
) -> Result<ResolvedSpecOutput> {
    resolve_dependencies_with_effects(ctx.effects(), snapshot, true)
}

pub(crate) fn resolve_dependencies_with_effects(
    effects: &dyn Effects,
    snapshot: &ManifestSnapshot,
    show_progress: bool,
) -> Result<ResolvedSpecOutput> {
    let spinner = show_progress.then(|| ProgressReporter::spinner("Resolving dependencies"));
    let python = effects.python().detect_interpreter()?;
    let tags = detect_interpreter_tags(&python)?;
    let resolver_env = detect_marker_environment(&python)?;
    let marker_env = resolver_env
        .to_marker_environment()
        .map_err(|err| anyhow!("invalid marker environment: {err}"))?;
    let cache_dir = effects.cache().resolve_store_path()?.path;
    let requirements: Vec<String> = snapshot
        .requirements
        .iter()
        .filter(|spec| marker_applies(spec, &marker_env))
        .cloned()
        .collect();
    tracing::debug!(?requirements, "resolver_requirements");
    let request = ResolverRequest {
        project: snapshot.name.clone(),
        requirements,
        tags: ResolverTags {
            python: tags.python.clone(),
            abi: tags.abi.clone(),
            platform: tags.platform.clone(),
        },
        env: resolver_env.clone(),
        indexes: resolver_indexes(),
        cache_dir,
        python: python.clone(),
    };
    let resolved = resolve(&request).map_err(|err| {
        InstallUserError::new(
            "dependency resolution failed",
            resolver_failure_details(&err),
        )
    })?;
    let mut pins = Vec::new();
    let mut autopin_lookup = HashMap::new();
    let mut seen = HashSet::new();
    for spec in resolved {
        let formatted = format_specifier(
            &spec.normalized,
            &spec.extras,
            &spec.selected_version,
            spec.marker.as_deref(),
        );
        let pin = PinSpec {
            name: spec.name,
            specifier: formatted.clone(),
            version: spec.selected_version,
            normalized: spec.normalized,
            extras: spec.extras,
            marker: spec.marker,
            direct: spec.direct,
            requires: spec.requires,
        };
        autopin_lookup.insert(autopin_pin_key(&pin), formatted);
        if seen.insert(pin.normalized.clone()) {
            pins.push(pin);
        }
    }

    let mut autopin_specs = Vec::new();
    for spec in &snapshot.dependencies {
        if spec_requires_pin(spec) && marker_applies(spec, &marker_env) {
            let key = autopin_spec_key(spec);
            if let Some(pinned) = autopin_lookup.get(&key) {
                autopin_specs.push(pinned.clone());
            } else {
                autopin_specs.push(spec.clone());
            }
        }
    }
    if let Some(spinner) = spinner {
        spinner.finish(format!("Resolved {} dependencies", pins.len()));
    }
    Ok(ResolvedSpecOutput {
        specs: autopin_specs,
        pins,
    })
}

fn resolver_indexes() -> Vec<String> {
    let mut indexes = Vec::new();
    if let Ok(primary) = env::var("PX_INDEX_URL")
        .or_else(|_| env::var("PIP_INDEX_URL"))
        .map(|value| value.trim().to_string())
    {
        if !primary.is_empty() {
            indexes.push(normalize_index_url(&primary));
        }
    }
    if let Ok(extra) = env::var("PIP_EXTRA_INDEX_URL") {
        for entry in extra.split_whitespace() {
            let trimmed = entry.trim();
            if !trimmed.is_empty() {
                indexes.push(normalize_index_url(trimmed));
            }
        }
    }
    if indexes.is_empty() {
        indexes.push("https://pypi.org/simple".to_string());
    }
    indexes
}

fn normalize_index_url(raw: &str) -> String {
    let mut url = raw.trim_end_matches('/').to_string();
    if url.ends_with("/simple") {
        return url;
    }
    if let Some(stripped) = url.strip_suffix("/pypi") {
        url = stripped.to_string();
    } else if let Some(stripped) = url.strip_suffix("/json") {
        url = stripped.to_string();
    }
    url.push_str("/simple");
    url
}

fn resolver_failure_details(err: &anyhow::Error) -> Value {
    let message = err.to_string();
    let mut issues = vec![message.clone()];
    issues.extend(err.chain().skip(1).map(std::string::ToString::to_string));
    let details = json!({
        "reason": "resolve_failed",
        "issues": issues,
        "hint": "Inspect dependency constraints and rerun `px sync`.",
        "code": diag_commands::SYNC,
    });
    if let Some(req) = extract_quoted_requirement(&message) {
        if message.contains("unable to resolve") {
            return json!({
                "reason": "resolve_no_match",
                "issues": issues,
                "requirement": req,
                "hint": format!("Relax or remove `{}` in pyproject.toml, then rerun `px sync`.", req),
                "code": diag_commands::SYNC,
            });
        }
        if message.contains("failed to parse requirement")
            || message.contains("failed to parse specifiers")
        {
            return json!({
                "reason": "invalid_requirement",
                "issues": issues,
                "requirement": req,
                "hint": format!("Fix `{}` to a valid PEP 508 requirement, then rerun `px sync`.", req),
                "code": diag_commands::SYNC,
            });
        }
    }
    if message.contains("failed to query PyPI") || message.contains("PyPI error") {
        return json!({
            "reason": "pypi_unreachable",
            "issues": issues,
            "hint": "Check your network connection (PX_ONLINE=1) and rerun `px sync`.",
            "code": diag_commands::SYNC,
        });
    }
    details
}

fn extract_quoted_requirement(message: &str) -> Option<String> {
    let start = message.find('`')?;
    let rest = &message[start + 1..];
    let end = rest.find('`')?;
    Some(rest[..end].to_string())
}

pub(crate) fn persist_resolved_dependencies(
    snapshot: &ManifestSnapshot,
    specs: &[String],
) -> Result<()> {
    let contents = fs::read_to_string(&snapshot.manifest_path)?;
    let mut doc: DocumentMut = contents.parse()?;
    write_dependencies(&mut doc, specs)?;
    fs::write(&snapshot.manifest_path, doc.to_string())?;
    Ok(())
}

pub(crate) fn summarize_autopins(entries: &[AutopinEntry]) -> Option<String> {
    if entries.is_empty() {
        return None;
    }
    let mut labels = Vec::new();
    for entry in entries.iter().take(3) {
        labels.push(entry.short_label());
    }
    let mut summary = format!(
        "Pinned {} package{} automatically",
        entries.len(),
        if entries.len() == 1 { "" } else { "s" }
    );
    if !labels.is_empty() {
        summary.push_str(" (");
        summary.push_str(&labels.join(", "));
        if entries.len() > 3 {
            let _ = write!(&mut summary, ", +{} more", entries.len() - 3);
        }
        summary.push(')');
    }
    Some(summary)
}

fn write_dependencies(doc: &mut DocumentMut, specs: &[String]) -> Result<()> {
    let table = project_table_mut(doc)?;
    let mut array = Array::new();
    for spec in specs {
        array.push_formatted(TomlValue::from(spec.clone()));
    }
    table.insert("dependencies", Item::Value(TomlValue::Array(array)));
    Ok(())
}

pub(crate) fn project_table(doc: &DocumentMut) -> Result<&Table> {
    doc.get("project")
        .and_then(Item::as_table)
        .ok_or_else(|| anyhow!("[project] must be a table"))
}

fn project_table_mut(doc: &mut DocumentMut) -> Result<&mut Table> {
    doc.entry("project")
        .or_insert(Item::Table(Table::new()))
        .as_table_mut()
        .ok_or_else(|| anyhow!("[project] must be a table"))
}

pub(crate) fn outcome_from_output(
    command_name: &str,
    target: &str,
    output: &RunOutput,
    prefix: &str,
    extra: Option<Value>,
) -> ExecutionOutcome {
    let mut extra_details = extra;
    let context = TracebackContext::new(command_name, target, extra_details.as_ref());
    let mut details = json!({
        "stdout": output.stdout.clone(),
        "stderr": output.stderr.clone(),
        "code": output.code,
        "target": target,
    });

    if let Some(extra_value) = extra_details.take() {
        if let Value::Object(map) = extra_value {
            if let Some(details_map) = details.as_object_mut() {
                for (key, value) in map {
                    details_map.insert(key, value);
                }
            }
        } else {
            details["extra"] = extra_value;
        }
    }

    let mut has_traceback = false;
    if output.code != 0 {
        if let Some(report) = analyze_python_traceback(&output.stderr, &context) {
            has_traceback = true;
            let recommendation = report.recommendation.clone();
            let trace_value = serde_json::to_value(&report).expect("traceback serialization");
            if let Some(map) = details.as_object_mut() {
                map.insert("traceback".to_string(), trace_value);
            }
            if let Some(rec) = recommendation {
                let hint_text = rec.hint.clone();
                let rec_value = serde_json::to_value(&rec).expect("traceback recommendation");
                if let Some(map) = details.as_object_mut() {
                    map.insert("recommendation".to_string(), rec_value);
                    if !map.contains_key("hint") {
                        map.insert("hint".to_string(), Value::String(hint_text));
                    }
                }
            }
        }
    }

    if output.code == 0 {
        let stdout = output.stdout.trim_end();
        if !stdout.is_empty() {
            details["passthrough"] = Value::Bool(true);
            return ExecutionOutcome::success(stdout.to_string(), details);
        }
        let stderr = output.stderr.trim_end();
        if !stderr.is_empty() {
            details["passthrough"] = Value::Bool(true);
            return ExecutionOutcome::success(stderr.to_string(), details);
        }
        let message = format!("{prefix} {command_name}({target}) succeeded");
        ExecutionOutcome::success(message, details)
    } else {
        let trimmed_stderr = output.stderr.trim();
        let message = if trimmed_stderr.is_empty() || has_traceback {
            format!(
                "{prefix} {command_name}({target}) exited with {}",
                output.code
            )
        } else {
            details["passthrough"] = Value::Bool(true);
            output.stderr.trim_end().to_string()
        };
        ExecutionOutcome::failure(message, details)
    }
}

pub(crate) struct PythonContext {
    pub(crate) project_root: PathBuf,
    pub(crate) project_name: String,
    pub(crate) python: String,
    pub(crate) pythonpath: String,
    pub(crate) allowed_paths: Vec<PathBuf>,
    pub(crate) site_bin: Option<PathBuf>,
    pub(crate) pep582_bin: Vec<PathBuf>,
    pub(crate) px_options: PxOptions,
}

#[derive(Clone, Copy, Debug)]
pub(crate) enum EnvGuard {
    Strict,
    AutoSync,
}

#[derive(Clone, Debug)]
pub(crate) struct EnvironmentSyncReport {
    action: &'static str,
    note: String,
}

impl EnvironmentSyncReport {
    pub(crate) fn new(issue: EnvironmentIssue) -> Self {
        Self {
            action: issue.action_key(),
            note: issue.note().to_string(),
        }
    }

    fn to_json(&self) -> Value {
        json!({
            "action": self.action,
            "note": self.note,
        })
    }
}

#[derive(Clone, Copy, Debug)]
pub(crate) enum EnvironmentIssue {
    MissingLock,
    LockDrift,
    MissingArtifacts,
    MissingEnv,
    EnvOutdated,
    RuntimeMismatch,
}

impl EnvironmentIssue {
    fn from_details(details: &Value) -> Option<Self> {
        let reason = details
            .as_object()
            .and_then(|map| map.get("reason"))
            .and_then(Value::as_str)?;
        match reason {
            "missing_lock" => Some(EnvironmentIssue::MissingLock),
            "lock_drift" => Some(EnvironmentIssue::LockDrift),
            "missing_artifacts" => Some(EnvironmentIssue::MissingArtifacts),
            "missing_env" => Some(EnvironmentIssue::MissingEnv),
            "env_outdated" => Some(EnvironmentIssue::EnvOutdated),
            "runtime_mismatch" => Some(EnvironmentIssue::RuntimeMismatch),
            _ => None,
        }
    }

    fn note(self) -> &'static str {
        match self {
            EnvironmentIssue::MissingLock => "No px.lock found, resolving dependencies",
            EnvironmentIssue::LockDrift => {
                "Manifest drift detected; syncing px.lock and environment"
            }
            EnvironmentIssue::MissingArtifacts => {
                "Cached artifacts missing; rehydrating environment"
            }
            EnvironmentIssue::MissingEnv => "Environment missing; rebuilding from px.lock",
            EnvironmentIssue::EnvOutdated => {
                "Environment stale; syncing with latest lock and runtime"
            }
            EnvironmentIssue::RuntimeMismatch => {
                "Environment runtime mismatch; rebuilding for current Python"
            }
        }
    }

    fn action_key(self) -> &'static str {
        match self {
            EnvironmentIssue::MissingLock => "lock-bootstrap",
            EnvironmentIssue::LockDrift => "lock-sync",
            EnvironmentIssue::MissingArtifacts => "env-rehydrate",
            EnvironmentIssue::MissingEnv => "env-recreate",
            EnvironmentIssue::EnvOutdated => "env-refresh",
            EnvironmentIssue::RuntimeMismatch => "env-runtime",
        }
    }

    fn auto_fixable(self) -> bool {
        matches!(
            self,
            EnvironmentIssue::MissingArtifacts
                | EnvironmentIssue::MissingEnv
                | EnvironmentIssue::EnvOutdated
                | EnvironmentIssue::RuntimeMismatch
        )
    }
}
#[allow(dead_code)]
pub(crate) fn issue_from_details(details: &Value) -> Option<EnvironmentIssue> {
    EnvironmentIssue::from_details(details)
}

impl PythonContext {
    fn new_with_guard(
        ctx: &CommandContext,
        guard: EnvGuard,
    ) -> Result<(Self, Option<EnvironmentSyncReport>)> {
        let project_root = ctx.project_root()?;
        let manifest_path = project_root.join("pyproject.toml");
        if !manifest_path.exists() {
            return Err(InstallUserError::new(
                format!("pyproject.toml not found in {}", project_root.display()),
                json!({
                    "pyproject": manifest_path.display().to_string(),
                    "hint": "run `px migrate --apply` or create pyproject.toml first",
                    "reason": "missing_manifest",
                }),
            )
            .into());
        }
        ensure_version_file(&manifest_path)?;
        let snapshot = manifest_snapshot_at(&project_root)?;
        let runtime = prepare_project_runtime(&snapshot)?;
        let sync_report = ensure_environment_with_guard(ctx, &snapshot, guard)?;
        let paths = build_pythonpath(ctx.fs(), &project_root, None)?;
        let python = select_python_from_site(
            &paths.site_bin,
            &runtime.record.path,
            &runtime.record.full_version,
        );
        Ok((
            Self {
                project_root,
                project_name: snapshot.name.clone(),
                python,
                pythonpath: paths.pythonpath,
                allowed_paths: paths.allowed_paths,
                site_bin: paths.site_bin,
                pep582_bin: paths.pep582_bin,
                px_options: snapshot.px_options.clone(),
            },
            sync_report,
        ))
    }

    pub(crate) fn base_env(&self, command_args: &Value) -> Result<Vec<(String, String)>> {
        let mut envs = Vec::new();
        envs.push(("PYTHONPATH".into(), self.pythonpath.clone()));
        envs.push(("PYTHONUNBUFFERED".into(), "1".into()));
        envs.push(("PYTHONDONTWRITEBYTECODE".into(), "1".into()));
        envs.push(("PYTHONSAFEPATH".into(), "1".into()));
        let allowed =
            env::join_paths(&self.allowed_paths).context("allowed path contains invalid UTF-8")?;
        let allowed = allowed
            .into_string()
            .map_err(|_| anyhow!("allowed path contains non-utf8 data"))?;
        envs.push(("PX_ALLOWED_PATHS".into(), allowed));
        envs.push((
            "PX_PROJECT_ROOT".into(),
            self.project_root.display().to_string(),
        ));
        envs.push(("PX_PYTHON".into(), self.python.clone()));
        envs.push(("PX_COMMAND_JSON".into(), command_args.to_string()));
        if let Some(alias) = self.px_options.manage_command.as_ref() {
            let trimmed = alias.trim();
            if !trimmed.is_empty() {
                envs.push(("PYAPP_COMMAND_NAME".into(), trimmed.to_string()));
            }
        }
        if let Some(bin) = &self.site_bin {
            if let Some(site_dir) = bin.parent() {
                let virtual_env = site_dir
                    .canonicalize()
                    .unwrap_or_else(|_| site_dir.to_path_buf());
                envs.push(("VIRTUAL_ENV".into(), virtual_env.display().to_string()));
            }
        }
        let mut path_entries = Vec::new();
        if let Some(bin) = &self.site_bin {
            path_entries.push(bin.clone());
        }
        path_entries.extend(self.pep582_bin.iter().cloned());
        if let Some(python_dir) = Path::new(&self.python).parent() {
            path_entries.push(python_dir.to_path_buf());
        }
        if let Ok(existing) = env::var("PATH") {
            path_entries.extend(env::split_paths(&existing));
        }
        let mut unique = Vec::new();
        let mut seen = std::collections::HashSet::new();
        for entry in path_entries.into_iter().filter(|p| p.exists()) {
            if seen.insert(entry.clone()) {
                unique.push(entry);
            }
        }
        if !unique.is_empty() {
            if let Ok(joined) = env::join_paths(&unique) {
                if let Ok(value) = joined.into_string() {
                    envs.push(("PATH".into(), value));
                }
            }
        }
        disable_proxy_env(&mut envs);
        Ok(envs)
    }
}

pub(crate) fn ensure_version_file(manifest_path: &Path) -> Result<()> {
    let contents = fs::read_to_string(manifest_path)?;
    let doc: toml_edit::DocumentMut = contents.parse()?;
    let manifest_dir = manifest_path
        .parent()
        .unwrap_or_else(|| Path::new("."))
        .to_path_buf();

    if let Some(version_file) = hatch_version_file(&doc) {
        ensure_version_stub(&manifest_dir, &version_file, VersionFileStyle::HatchVcsHook)?;
    }

    if let Some(version_file) = setuptools_scm_version_file(&doc) {
        ensure_version_stub(
            &manifest_dir,
            &version_file,
            VersionFileStyle::SetuptoolsScm,
        )?;
    }

    ensure_inline_version_module(&manifest_dir, &doc)?;

    Ok(())
}

fn hatch_version_file(doc: &toml_edit::DocumentMut) -> Option<PathBuf> {
    doc.get("tool")
        .and_then(|tool| tool.get("hatch"))
        .and_then(|hatch| hatch.get("build"))
        .and_then(|build| build.get("hooks"))
        .and_then(|hooks| hooks.get("vcs"))
        .and_then(|vcs| vcs.get("version-file"))
        .and_then(|item| item.as_str())
        .map(PathBuf::from)
}

fn setuptools_scm_version_file(doc: &toml_edit::DocumentMut) -> Option<PathBuf> {
    doc.get("tool")
        .and_then(|tool| tool.get("setuptools_scm"))
        .and_then(|cfg| cfg.get("write_to").or_else(|| cfg.get("version_file")))
        .and_then(|item| item.as_str())
        .map(PathBuf::from)
}

fn ensure_inline_version_module(manifest_dir: &Path, doc: &toml_edit::DocumentMut) -> Result<()> {
    let Some(project) = doc.get("project").and_then(Item::as_table) else {
        return Ok(());
    };
    if project
        .get("dynamic")
        .and_then(Item::as_array)
        .map_or(false, |items| {
            items
                .iter()
                .any(|item| item.as_str().is_some_and(|value| value == "version"))
        })
    {
        return Ok(());
    }

    let Some(name) = project.get("name").and_then(Item::as_str) else {
        return Ok(());
    };
    let Some(version) = project.get("version").and_then(Item::as_str) else {
        return Ok(());
    };

    let module = name.replace(['-', '.'], "_").to_lowercase();
    let candidates = [
        manifest_dir.join("src").join(&module),
        manifest_dir.join("python").join(&module),
        manifest_dir.join(&module),
    ];
    let Some(package_dir) = candidates.iter().find(|path| path.exists()) else {
        return Ok(());
    };
    let version_pyi = package_dir.join("version.pyi");
    if !version_pyi.exists() {
        return Ok(());
    }
    let version_py = package_dir.join("version.py");

    let (version_value, git_revision) = inline_version_values(manifest_dir, version);
    let release_flag = if !version_value.contains("dev") && !version_value.contains('+') {
        "True"
    } else {
        "False"
    };
    let contents = format!(
        "\"\"\"\nModule to expose more detailed version info for the installed `{name}`\n\"\"\"\n\
version = \"{version_value}\"\n\
__version__ = version\n\
full_version = version\n\n\
git_revision = \"{git_revision}\"\n\
release = {release_flag}\n\
short_version = version.split(\"+\")[0]\n"
    );

    if let Some(parent) = version_py.parent() {
        fs::create_dir_all(parent)?;
    }
    if version_py.exists() {
        if let Ok(current) = fs::read_to_string(&version_py) {
            if current == contents {
                return Ok(());
            }
        }
    }
    fs::write(&version_py, contents)?;
    Ok(())
}

fn inline_version_values(manifest_dir: &Path, version: &str) -> (String, String) {
    let mut version_value = version.to_string();
    let mut git_revision = String::new();

    if let Some((hash, date)) = latest_git_commit(manifest_dir) {
        git_revision = hash.clone();
        if version_value.contains("dev") && !date.is_empty() {
            let short = hash.chars().take(7).collect::<String>();
            if !short.is_empty() {
                version_value = format!("{version_value}+git{date}.{short}");
            }
        }
    }

    (version_value, git_revision)
}

fn latest_git_commit(manifest_dir: &Path) -> Option<(String, String)> {
    let output = Command::new("git")
        .args([
            "-c",
            "log.showSignature=false",
            "log",
            "-1",
            "--format=\"%H %aI\"",
        ])
        .current_dir(manifest_dir)
        .output()
        .ok()?;
    if !output.status.success() {
        return None;
    }

    let stdout = String::from_utf8_lossy(&output.stdout);
    let mut parts = stdout.trim().trim_matches('"').split_whitespace();
    let hash = parts.next().unwrap_or_default();
    if hash.is_empty() {
        return None;
    }
    let timestamp = parts.next().unwrap_or_default();
    let date = timestamp
        .split('T')
        .next()
        .unwrap_or_default()
        .replace('-', "");
    Some((hash.to_string(), date))
}

#[derive(Clone, Copy)]
enum VersionFileStyle {
    HatchVcsHook,
    SetuptoolsScm,
}

fn ensure_version_stub(root: &Path, target: &Path, style: VersionFileStyle) -> Result<()> {
    let version_path = root.join(target);
    let mut rewrite = false;
    if version_path.exists() {
        match style {
            VersionFileStyle::HatchVcsHook => {
                if let Ok(contents) = fs::read_to_string(&version_path) {
                    let has_version = contents.contains("version =");
                    let has_alias = contents.contains("__version__");
                    let fallback_version = contents.lines().find_map(|line| {
                        let trimmed = line.trim_start();
                        if !trimmed.starts_with("version =") {
                            return None;
                        }
                        let value = trimmed
                            .split_once('=')
                            .map(|(_, rhs)| rhs.trim().trim_matches('"'))
                            .unwrap_or_default();
                        Some(
                            value == "unknown"
                                || value.starts_with("0.0.0+")
                                || value.starts_with("0+"),
                        )
                    });
                    let needs_upgrade = fallback_version.unwrap_or(false);
                    if !(has_version && has_alias) || needs_upgrade {
                        rewrite = true;
                    }
                } else {
                    rewrite = true;
                }
            }
            VersionFileStyle::SetuptoolsScm => {
                if let Ok(contents) = fs::read_to_string(&version_path) {
                    let has_version = contents.contains("version =");
                    let has_alias = contents.contains("__version__");
                    let has_tuple = contents.contains("version_tuple = tuple(_v.release)");
                    let has_packaging =
                        contents.contains("from packaging.version import Version as _Version");
                    let fallback_version = contents.lines().find_map(|line| {
                        let trimmed = line.trim_start();
                        if !trimmed.starts_with("version =") {
                            return None;
                        }
                        let value = trimmed
                            .split_once('=')
                            .map(|(_, rhs)| rhs.trim().trim_matches('"'))
                            .unwrap_or_default();
                        Some(
                            value == "unknown"
                                || value.starts_with("0.0.0+")
                                || value.starts_with("0+"),
                        )
                    });
                    let needs_upgrade = fallback_version.unwrap_or(false);
                    if !(has_version && has_alias && has_tuple && has_packaging) || needs_upgrade {
                        rewrite = true;
                    }
                } else {
                    rewrite = true;
                }
            }
        }
        if !rewrite {
            return Ok(());
        }
    }
    if !version_path.exists() || rewrite {
        if let Some(parent) = version_path.parent() {
            fs::create_dir_all(parent)?;
        }
    }

    let derived = match derive_vcs_version(root) {
        Ok(version) => version,
        Err(err) => {
            warn!(
                error = %err,
                path = %root.display(),
                "git metadata unavailable; writing fallback vcs version"
            );
            "0.0.0+unknown".to_string()
        }
    };

    let contents = match style {
        VersionFileStyle::HatchVcsHook => format!(
            "version = \"{derived}\"\n\
__version__ = version\n\
__all__ = [\"__version__\", \"version\"]\n"
        ),
        VersionFileStyle::SetuptoolsScm => format!(
            "from packaging.version import Version as _Version\n\
version = \"{derived}\"\n\
__version__ = version\n\
_v = _Version(version)\n\
version_tuple = tuple(_v.release)\n\
__all__ = [\"__version__\", \"version\", \"version_tuple\"]\n"
        ),
    };
    if rewrite || !version_path.exists() {
        fs::write(&version_path, contents)?;
    }
    Ok(())
}

fn derive_vcs_version(manifest_dir: &Path) -> Result<String> {
    if let Ok(output) = Command::new("git")
        .args(["describe", "--tags", "--dirty", "--long"])
        .current_dir(manifest_dir)
        .output()
    {
        if output.status.success() {
            let desc = String::from_utf8_lossy(&output.stdout).trim().to_string();
            if let Some(version) = pep440_from_describe(&desc) {
                return Ok(version);
            }
        }
    }

    if let Ok(output) = Command::new("git")
        .args(["rev-parse", "--short", "HEAD"])
        .current_dir(manifest_dir)
        .output()
    {
        if output.status.success() {
            let hash = String::from_utf8_lossy(&output.stdout)
                .trim()
                .trim_start_matches('g')
                .to_string();
            if !hash.is_empty() {
                return Ok(format!("0.0.0+g{hash}"));
            }
        }
    }

    Err(anyhow!(
        "unable to derive version from git; add tags or version-file"
    ))
}

fn pep440_from_describe(desc: &str) -> Option<String> {
    let trimmed = desc.trim();
    if trimmed.is_empty() {
        return None;
    }
    let mut dirty = false;
    let mut core = trimmed.to_string();
    if core.ends_with("-dirty") {
        dirty = true;
        core = core.trim_end_matches("-dirty").to_string();
    }
    let mut iter = core.rsplitn(3, '-');
    let sha_part = iter.next()?;
    let commits_part = iter.next()?;
    let tag_part = iter.next()?;

    let sha = sha_part.trim_start_matches('g');
    let tag = tag_part.trim_start_matches('v');
    let mut version = format!("{tag}+{commits_part}.g{sha}");
    if dirty {
        version.push_str(".dirty");
    }
    Some(version)
}

pub(crate) struct PythonPathInfo {
    pub(crate) pythonpath: String,
    pub(crate) allowed_paths: Vec<PathBuf>,
    pub(crate) site_bin: Option<PathBuf>,
    pub(crate) pep582_bin: Vec<PathBuf>,
}

fn detect_local_site_packages(fs: &dyn effects::FileSystem, site_dir: &Path) -> Option<PathBuf> {
    let lib_dir = site_dir.join("lib");
    if let Ok(entries) = fs.read_dir(&lib_dir) {
        for entry in entries.flatten() {
            let path = entry.path();
            if !path.is_dir() {
                continue;
            }
            if let Some(name) = path.file_name().and_then(|value| value.to_str()) {
                if !name.starts_with("python") {
                    continue;
                }
            }
            let candidate = path.join("site-packages");
            if fs.metadata(&candidate).is_ok() {
                return Some(candidate);
            }
        }
    }
    let fallback = site_dir.join("site-packages");
    fs.metadata(&fallback).ok().map(|_| fallback)
}

fn discover_code_generator_paths(
    fs: &dyn effects::FileSystem,
    project_root: &Path,
    max_depth: usize,
) -> Vec<PathBuf> {
    let mut extras = Vec::new();
    let mut stack = vec![(project_root.to_path_buf(), 0usize)];
    while let Some((dir, depth)) = stack.pop() {
        let Ok(entries) = fs.read_dir(&dir) else {
            continue;
        };
        for entry in entries.flatten() {
            let path = entry.path();
            if !path.is_dir() {
                continue;
            }
            let name = entry.file_name();
            if name
                .to_str()
                .is_some_and(|value| value == "code_generators")
            {
                extras.push(path.clone());
                continue;
            }
            if depth < max_depth {
                stack.push((path, depth + 1));
            }
        }
    }
    extras
}

pub(crate) fn build_pythonpath(
    fs: &dyn effects::FileSystem,
    project_root: &Path,
    site_override: Option<PathBuf>,
) -> Result<PythonPathInfo> {
    let mut site_paths = Vec::new();
    let mut site_dir_used = None;
    let mut site_packages_used = None;
    let code_paths = discover_code_generator_paths(fs, project_root, 3);

    if let Some(site_dir) =
        site_override.or_else(|| resolve_project_site(fs, project_root).ok().flatten())
    {
        let canonical = fs.canonicalize(&site_dir).unwrap_or(site_dir.clone());
        site_dir_used = Some(canonical.clone());
        site_paths.push(canonical.clone());
        if let Some(site_packages) = detect_local_site_packages(fs, &canonical) {
            site_packages_used = Some(site_packages.clone());
            site_paths.push(site_packages);
        }
        let pth = canonical.join("px.pth");
        if pth.exists() {
            if let Ok(contents) = fs.read_to_string(&pth) {
                for line in contents.lines() {
                    let trimmed = line.trim();
                    if trimmed.is_empty() {
                        continue;
                    }
                    let entry_path = PathBuf::from(trimmed);
                    if entry_path.exists() {
                        site_paths.push(entry_path);
                    }
                }
            }
        }
    }

    let mut project_paths = Vec::new();
    let src = project_root.join("src");
    if src.exists() {
        project_paths.push(src);
    }
    let python_dir = project_root.join("python");
    if python_dir.exists() {
        project_paths.push(python_dir);
    }
    let mut child_projects = Vec::new();
    if let Ok(entries) = fs.read_dir(project_root) {
        for entry in entries.flatten() {
            let path = entry.path();
            if !path.is_dir() {
                continue;
            }
            let manifest = path.join("pyproject.toml");
            if fs.metadata(&manifest).is_ok() {
                child_projects.push(path);
            }
        }
    }
    child_projects.sort();
    for path in child_projects {
        if path != project_root {
            project_paths.push(path);
        }
    }
    project_paths.push(project_root.to_path_buf());

    let mut pep582_libs = Vec::new();
    let mut pep582_bins = Vec::new();
    let pep582_root = project_root.join("__pypackages__");
    if pep582_root.exists() {
        if let Ok(entries) = fs.read_dir(&pep582_root) {
            for entry in entries.flatten() {
                let path = entry.path();
                if !path.is_dir() {
                    continue;
                }
                let lib = path.join("lib");
                if lib.exists() {
                    pep582_libs.push(lib);
                } else {
                    pep582_libs.push(path.clone());
                }
                let bin = path.join("bin");
                if bin.exists() {
                    pep582_bins.push(bin);
                }
            }
        }
    }

    let mut paths = Vec::new();
    if let Some(dir) = site_dir_used.as_ref() {
        paths.push(dir.clone());
    }
    paths.extend(code_paths.clone());
    paths.extend(project_paths.clone());
    if let Some(pkgs) = site_packages_used.as_ref() {
        paths.push(pkgs.clone());
    }
    for path in site_paths {
        if Some(&path) == site_dir_used.as_ref() {
            continue;
        }
        if site_packages_used
            .as_ref()
            .is_some_and(|pkgs| pkgs == &path)
        {
            continue;
        }
        if project_paths.iter().any(|pkg| pkg == &path) {
            continue;
        }
        if code_paths.iter().any(|extra| extra == &path) {
            continue;
        }
        paths.push(path);
    }
    paths.extend(pep582_libs);
    paths.retain(|p| p.exists());
    if paths.is_empty() {
        paths.push(project_root.to_path_buf());
    }

    let joined = env::join_paths(&paths).context("failed to build PYTHONPATH")?;
    let pythonpath = joined
        .into_string()
        .map_err(|_| anyhow!("pythonpath contains non-UTF paths"))?;
    let site_bin = site_dir_used
        .map(|dir| dir.join("bin"))
        .filter(|bin| bin.exists());
    Ok(PythonPathInfo {
        pythonpath,
        allowed_paths: paths,
        site_bin,
        pep582_bin: pep582_bins,
    })
}

pub(crate) fn ensure_project_environment_synced(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
) -> Result<()> {
    if !snapshot.manifest_path.exists() {
        return Err(InstallUserError::new(
            format!("pyproject.toml not found in {}", snapshot.root.display()),
            json!({
                "hint": "run `px migrate --apply` or pass ENTRY explicitly",
                "project_root": snapshot.root.display().to_string(),
                "manifest": snapshot.manifest_path.display().to_string(),
                "reason": "missing_manifest",
            }),
        )
        .into());
    }
    let lock_path = snapshot.lock_path.clone();
    let Some(lock) = load_lockfile_optional(&lock_path)? else {
        return Err(InstallUserError::new(
            "missing px.lock (run `px sync`)",
            json!({
                "lockfile": lock_path.display().to_string(),
                "hint": "run `px sync` to generate px.lock before running this command",
                "reason": "missing_lock",
            }),
        )
        .into());
    };

    let runtime = prepare_project_runtime(snapshot)?;
    let marker_env = detect_marker_environment(&runtime.record.path)?.to_marker_environment()?;

    let drift = detect_lock_drift(snapshot, &lock, Some(&marker_env));
    if !drift.is_empty() {
        return Err(InstallUserError::new(
            "px.lock is out of date",
            json!({
                "lockfile": lock_path.display().to_string(),
                "drift": drift,
                "hint": "run `px sync` to refresh px.lock",
                "reason": "lock_drift",
            }),
        )
        .into());
    }

    let missing = verify_locked_artifacts(&lock);
    if !missing.is_empty() {
        return Err(InstallUserError::new(
            "cached artifacts missing",
            json!({
                "lockfile": lock_path.display().to_string(),
                "missing": missing,
                "hint": "run `px sync` to rehydrate the environment",
                "reason": "missing_artifacts",
            }),
        )
        .into());
    }

    let lock_id = match lock.lock_id.clone() {
        Some(value) => value,
        None => compute_lock_hash(&lock_path)?,
    };
    ensure_env_matches_lock(ctx, snapshot, &lock_id)
}

pub fn ensure_env_matches_lock(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
    lock_id: &str,
) -> Result<()> {
    let state = match load_project_state(ctx.fs(), &snapshot.root) {
        Ok(state) => state,
        Err(err) => {
            return Err(InstallUserError::new(
                "px state file is unreadable",
                json!({
                    "error": err.to_string(),
                    "state": snapshot.root.join(".px").join("state.json"),
                    "hint": "Repair or delete the corrupted .px/state.json file, then rerun the command.",
                    "reason": "invalid_state",
                }),
            )
            .into());
        }
    };
    let Some(env) = state.current_env else {
        return Err(InstallUserError::new(
            "project environment missing",
            json!({
                "hint": "run `px sync` to build the environment",
                "reason": "missing_env",
            }),
        )
        .into());
    };
    if env.lock_id != lock_id {
        return Err(InstallUserError::new(
            "environment is out of date",
            json!({
                "expected_lock_id": lock_id,
                "current_lock_id": env.lock_id,
                "hint": "run `px sync` to rebuild the environment",
                "reason": "env_outdated",
            }),
        )
        .into());
    }
    let site_dir = PathBuf::from(&env.site_packages);
    if !site_dir.exists() {
        return Err(InstallUserError::new(
            "environment files missing",
            json!({
                "site": env.site_packages,
                "hint": "run `px sync` to rebuild the environment",
                "reason": "missing_env",
            }),
        )
        .into());
    }

    let runtime = detect_runtime_metadata(ctx, snapshot)?;
    if runtime.version != env.python.version || runtime.platform != env.platform {
        return Err(InstallUserError::new(
            format!(
                "environment targets Python {} ({}) but {} ({}) is active",
                env.python.version, env.platform, runtime.version, runtime.platform
            ),
            json!({
                "expected_python": env.python.version,
                "current_python": runtime.version,
                "expected_platform": env.platform,
                "current_platform": runtime.platform,
                "hint": "run `px sync` to rebuild for the current runtime",
                "reason": "runtime_mismatch",
            }),
        )
        .into());
    }

    Ok(())
}

fn ensure_environment_with_guard(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
    guard: EnvGuard,
) -> Result<Option<EnvironmentSyncReport>> {
    match ensure_project_environment_synced(ctx, snapshot) {
        Ok(()) => Ok(None),
        Err(err) => match err.downcast::<InstallUserError>() {
            Ok(user) => match guard {
                EnvGuard::Strict => Err(user.into()),
                EnvGuard::AutoSync => {
                    if let Some(issue) = EnvironmentIssue::from_details(&user.details) {
                        if issue.auto_fixable() {
                            auto_sync_environment(ctx, snapshot, issue)
                        } else {
                            Err(user.into())
                        }
                    } else {
                        Err(user.into())
                    }
                }
            },
            Err(err) => Err(err),
        },
    }
}

pub(crate) fn auto_sync_environment(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
    issue: EnvironmentIssue,
) -> Result<Option<EnvironmentSyncReport>> {
    install_snapshot(ctx, snapshot, false, None)?;
    refresh_project_site(snapshot, ctx)?;
    Ok(Some(EnvironmentSyncReport::new(issue)))
}

pub(crate) fn attach_autosync_details(
    outcome: &mut ExecutionOutcome,
    report: Option<EnvironmentSyncReport>,
) {
    let Some(report) = report else {
        return;
    };
    let autosync = report.to_json();
    match outcome.details {
        Value::Object(ref mut map) => {
            map.insert("autosync".to_string(), autosync);
        }
        Value::Null => {
            outcome.details = json!({ "autosync": autosync });
        }
        ref mut other => {
            let previous = other.take();
            outcome.details = json!({
                "value": previous,
                "autosync": autosync,
            });
        }
    }
}

pub(crate) fn python_context(ctx: &CommandContext) -> Result<PythonContext, ExecutionOutcome> {
    python_context_with_mode(ctx, EnvGuard::Strict).map(|(py, _)| py)
}

pub(crate) fn python_context_with_mode(
    ctx: &CommandContext,
    guard: EnvGuard,
) -> Result<(PythonContext, Option<EnvironmentSyncReport>), ExecutionOutcome> {
    match PythonContext::new_with_guard(ctx, guard) {
        Ok(result) => Ok(result),
        Err(err) => {
            if is_missing_project_error(&err) {
                return Err(missing_project_outcome());
            }
            match err.downcast::<InstallUserError>() {
                Ok(user) => Err(ExecutionOutcome::user_error(user.message, user.details)),
                Err(err) => Err(ExecutionOutcome::failure(
                    "failed to prepare python environment",
                    json!({ "error": err.to_string() }),
                )),
            }
        }
    }
}

pub fn missing_project_outcome() -> ExecutionOutcome {
    ExecutionOutcome::user_error(
        MISSING_PROJECT_MESSAGE,
        json!({
            "reason": "missing_project",
            "hint": MISSING_PROJECT_HINT,
        }),
    )
}

pub fn is_missing_project_error(err: &anyhow::Error) -> bool {
    err.chain()
        .any(|cause| cause.to_string().contains("No px project found"))
}

pub fn manifest_error_outcome(err: &anyhow::Error) -> Option<ExecutionOutcome> {
    if err
        .chain()
        .any(|cause| cause.to_string().contains("pyproject.toml not found"))
    {
        return Some(ExecutionOutcome::user_error(
            "pyproject.toml not found",
            json!({
                "reason": "missing_manifest",
                "hint": "Run `px init` to create pyproject.toml, or restore it from version control.",
            }),
        ));
    }

    let parse_error = err
        .chain()
        .find_map(|cause| cause.downcast_ref::<TomlError>().map(ToString::to_string))?;

    let mut target = "pyproject.toml";
    for cause in err.chain() {
        let msg = cause.to_string();
        if msg.contains("px.lock") {
            target = "px.lock";
            break;
        }
        if msg.contains("pyproject.toml") {
            target = "pyproject.toml";
            break;
        }
    }

    let (reason, hint) = if target == "px.lock" {
        (
            "invalid_lock",
            "Delete or fix px.lock, then run `px sync` to regenerate it.",
        )
    } else {
        (
            "invalid_manifest",
            "Fix pyproject.toml syntax and rerun the command.",
        )
    };

    Some(ExecutionOutcome::user_error(
        format!("{target} is not valid TOML"),
        json!({
            "reason": reason,
            "target": target,
            "error": parse_error,
            "hint": hint,
        }),
    ))
}

#[must_use]
pub fn to_json_response(info: CommandInfo, outcome: &ExecutionOutcome, _code: i32) -> Value {
    let status = match outcome.status {
        CommandStatus::Ok => "ok",
        CommandStatus::UserError => "user-error",
        CommandStatus::Failure => "error",
    };
    let details = match &outcome.details {
        Value::Object(_) => outcome.details.clone(),
        Value::Null => json!({}),
        other => json!({ "value": other }),
    };
    json!({
        "status": status,
        "message": format_status_message(info, &outcome.message),
        "details": details,
    })
}

#[must_use]
pub fn format_status_message(info: CommandInfo, message: &str) -> String {
    let group_name = info.group.to_string();
    let prefix = if group_name == info.name {
        format!("px {}", info.name)
    } else {
        format!("px {} {}", group_name, info.name)
    };
    if message.is_empty() {
        prefix
    } else if message.starts_with(&prefix) {
        message.to_string()
    } else {
        format!("{prefix}: {message}")
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::SystemEffects;
    use anyhow::Result;
    use serde_json::Value;
    use std::env;
    use std::fs;
    use std::io::Write;
    use std::path::Path;
    use std::process::Command;
    use tempfile::tempdir;
    use zip::write::FileOptions;

    #[test]
    fn base_env_disables_pyc_writes() -> Result<()> {
        let temp = tempdir()?;
        let ctx = PythonContext {
            project_root: temp.path().to_path_buf(),
            project_name: "demo".to_string(),
            python: "python".into(),
            pythonpath: temp.path().display().to_string(),
            allowed_paths: vec![temp.path().to_path_buf()],
            site_bin: None,
            pep582_bin: Vec::new(),
            px_options: PxOptions::default(),
        };
        let envs = ctx.base_env(&json!({}))?;
        let flag = envs
            .iter()
            .find(|(key, _)| key == "PYTHONDONTWRITEBYTECODE")
            .map(|(_, value)| value.as_str());
        assert_eq!(flag, Some("1"));
        Ok(())
    }

    #[test]
    fn materialize_scripts_from_dist_directory() -> Result<()> {
        let temp = tempdir()?;
        let artifact = temp.path().join("demo-0.1.0.dist");
        let dist_info = artifact.join("demo-0.1.0.dist-info");
        let data_scripts = artifact.join("demo-0.1.0.data").join("scripts");
        fs::create_dir_all(&dist_info)?;
        fs::create_dir_all(&data_scripts)?;
        fs::write(
            dist_info.join("entry_points.txt"),
            "[console_scripts]\nalpha = demo.cli:main\n[gui_scripts]\nbeta = demo.gui:run\n",
        )?;
        fs::write(data_scripts.join("copied.sh"), "echo copied\n")?;

        let bin_dir = temp.path().join("bin");
        materialize_wheel_scripts(&artifact, &bin_dir, Some(Path::new("/custom/python")))?;

        let alpha = fs::read_to_string(bin_dir.join("alpha"))?;
        assert!(
            alpha.starts_with("#!/custom/python"),
            "shebang honors python"
        );
        assert!(alpha.contains("demo.cli"));
        let beta = fs::read_to_string(bin_dir.join("beta"))?;
        assert!(beta.contains("demo.gui"));
        let copied = fs::read_to_string(bin_dir.join("copied.sh"))?;
        assert!(copied.contains("copied"));
        Ok(())
    }

    #[test]
    fn materialize_scripts_from_wheel_file() -> Result<()> {
        let temp = tempdir()?;
        let wheel_path = temp.path().join("demo-0.2.0-py3-none-any.whl");
        let file = fs::File::create(&wheel_path)?;
        let mut zip = zip::ZipWriter::new(file);
        let opts = FileOptions::default();
        zip.start_file("demo-0.2.0.dist-info/entry_points.txt", opts)?;
        zip.write_all(b"[console_scripts]\ngamma = demo.core:run\n")?;
        zip.start_file("demo-0.2.0.data/scripts/helper.sh", opts)?;
        zip.write_all(b"echo helper\n")?;
        zip.finish()?;

        let bin_dir = temp.path().join("wheel-bin");
        materialize_wheel_scripts(&wheel_path, &bin_dir, None)?;

        let gamma = fs::read_to_string(bin_dir.join("gamma"))?;
        assert!(gamma.starts_with("#!/usr/bin/env python3"));
        assert!(gamma.contains("demo.core"));
        let helper = fs::read_to_string(bin_dir.join("helper.sh"))?;
        assert!(helper.contains("helper"));
        Ok(())
    }

    #[test]
    fn site_dir_precedes_project_root_in_sys_path() -> Result<()> {
        let temp = tempdir()?;
        let project_root = temp.path();
        let site_dir = project_root.join("site");
        fs::create_dir_all(&site_dir)?;
        fs::write(site_dir.join("sitecustomize.py"), SITE_CUSTOMIZE)?;

        let dep_pkg = site_dir.join("deps");
        let dep_mod = dep_pkg.join("dep");
        fs::create_dir_all(&dep_mod)?;
        fs::write(dep_mod.join("__init__.py"), "VALUE = 'site'\n")?;
        fs::write(site_dir.join("px.pth"), format!("{}\n", dep_pkg.display()))?;

        // Namespace-like directory at the project root should not shadow site packages
        fs::create_dir_all(project_root.join("dep"))?;

        let effects = SystemEffects::new();
        let paths = build_pythonpath(effects.fs(), project_root, Some(site_dir.clone()))?;
        let allowed = env::join_paths(&paths.allowed_paths)
            .expect("allowed paths")
            .into_string()
            .expect("utf8 allowed paths");
        let allowed_env = allowed.clone();
        let python = match effects.python().detect_interpreter() {
            Ok(path) => path,
            Err(_) => return Ok(()),
        };

        let mut cmd = Command::new(&python);
        cmd.current_dir(project_root);
        cmd.env("PYTHONPATH", paths.pythonpath.clone());
        cmd.env("PX_ALLOWED_PATHS", allowed_env.clone());
        cmd.arg("-c").arg(
            "import importlib, json, os, sys; mod = importlib.import_module('dep'); \
             print(json.dumps({'file': getattr(mod, '__file__', ''), 'value': getattr(mod, 'VALUE', ''), 'prefix': sys.path[:3], 'env_py': os.environ.get('PYTHONPATH')}))",
        );
        let output = cmd.output()?;
        let stdout = String::from_utf8_lossy(&output.stdout);
        assert!(
            output.status.success(),
            "python exited with {}: {}\n{}",
            output.status,
            stdout,
            String::from_utf8_lossy(&output.stderr)
        );

        let payload: Value = serde_json::from_str(stdout.trim())?;
        let prefix: Vec<String> = payload
            .get("prefix")
            .and_then(Value::as_array)
            .map(|entries| {
                entries
                    .iter()
                    .filter_map(Value::as_str)
                    .map(std::string::ToString::to_string)
                    .collect()
            })
            .unwrap_or_default();
        let canonical_site = effects.fs().canonicalize(&site_dir)?;
        let canonical_site_str = canonical_site.display().to_string();
        let first_nonempty = if prefix.first().is_some_and(|entry| entry.is_empty()) {
            prefix.get(1).map(String::as_str)
        } else {
            prefix.first().map(String::as_str)
        };
        assert_eq!(first_nonempty, Some(canonical_site_str.as_str()));
        let value = payload
            .get("value")
            .and_then(Value::as_str)
            .unwrap_or_default();
        assert_eq!(value, "site");
        let env_py = payload
            .get("env_py")
            .and_then(Value::as_str)
            .unwrap_or_default();
        assert_eq!(env_py, allowed_env);
        let file = payload.get("file").and_then(Value::as_str).unwrap_or("");
        assert!(
            file.contains(dep_mod.to_string_lossy().as_ref()),
            "expected module to load from site packages, got {file}"
        );
        Ok(())
    }

    #[test]
    fn project_paths_precede_local_site_packages() -> Result<()> {
        let temp = tempdir()?;
        let project_root = temp.path();
        let site_dir = project_root.join("site");
        let site_packages = site_dir.join("site-packages");
        fs::create_dir_all(&site_packages)?;
        fs::write(site_dir.join("sitecustomize.py"), SITE_CUSTOMIZE)?;

        let site_pkg = site_packages.join("demo");
        fs::create_dir_all(&site_pkg)?;
        fs::write(site_pkg.join("__init__.py"), "VALUE = 'site'\n")?;

        let project_pkg = project_root.join("demo");
        fs::create_dir_all(&project_pkg)?;
        fs::write(project_pkg.join("__init__.py"), "VALUE = 'project'\n")?;

        let effects = SystemEffects::new();
        let paths = build_pythonpath(effects.fs(), project_root, Some(site_dir.clone()))?;
        let allowed_env = env::join_paths(&paths.allowed_paths)?
            .into_string()
            .expect("allowed paths");
        let python = match effects.python().detect_interpreter() {
            Ok(path) => path,
            Err(_) => return Ok(()),
        };

        let mut cmd = Command::new(&python);
        cmd.current_dir(project_root);
        cmd.env("PYTHONPATH", paths.pythonpath.clone());
        cmd.env("PX_ALLOWED_PATHS", allowed_env);
        cmd.env("PYTHONSAFEPATH", "1");
        cmd.arg("-c").arg(
            "import importlib, json, sys; mod = importlib.import_module('demo'); \
             print(json.dumps({'value': getattr(mod, 'VALUE', ''), 'file': getattr(mod, '__file__', ''), 'prefix': sys.path[:4]}))",
        );
        let output = cmd.output()?;
        let stdout = String::from_utf8_lossy(&output.stdout);
        assert!(
            output.status.success(),
            "python exited with {}: {}\n{}",
            output.status,
            stdout,
            String::from_utf8_lossy(&output.stderr)
        );

        let payload: Value = serde_json::from_str(stdout.trim())?;
        let value = payload
            .get("value")
            .and_then(Value::as_str)
            .unwrap_or_default();
        assert_eq!(value, "project");
        let file = payload.get("file").and_then(Value::as_str).unwrap_or("");
        assert!(
            file.contains(project_pkg.to_string_lossy().as_ref()),
            "expected project package, got {file}"
        );
        let prefix: Vec<PathBuf> = payload
            .get("prefix")
            .and_then(Value::as_array)
            .map(|entries| {
                entries
                    .iter()
                    .filter_map(Value::as_str)
                    .map(PathBuf::from)
                    .collect()
            })
            .unwrap_or_default();
        let proj_pos = prefix
            .iter()
            .position(|entry| fs::canonicalize(entry).ok() == Some(project_root.to_path_buf()));
        let site_pos = prefix
            .iter()
            .position(|entry| fs::canonicalize(entry).ok() == Some(site_packages.clone()));
        assert!(
            proj_pos < site_pos,
            "project path should precede site-packages in sys.path, got {:?}",
            prefix
        );
        Ok(())
    }

    #[test]
    fn sitecustomize_uses_pythonpath_when_px_allowed_missing() -> Result<()> {
        let temp = tempdir()?;
        let site_dir = temp.path().join("site");
        fs::create_dir_all(&site_dir)?;
        fs::write(site_dir.join("sitecustomize.py"), SITE_CUSTOMIZE)?;

        let dep_dir = site_dir.join("deps");
        fs::create_dir_all(&dep_dir)?;
        fs::write(dep_dir.join("shim.py"), "VALUE = 'ok'\n")?;
        fs::write(site_dir.join("px.pth"), format!("{}\n", dep_dir.display()))?;

        let python = match SystemEffects::new().python().detect_interpreter() {
            Ok(path) => path,
            Err(_) => return Ok(()),
        };

        let mut cmd = Command::new(&python);
        cmd.current_dir(temp.path());
        cmd.env_clear();
        cmd.env("PYTHONPATH", site_dir.display().to_string());
        cmd.arg("-c").arg(
            "import json, sys, shim; print(json.dumps({'value': shim.VALUE, 'path': sys.path}))",
        );
        let output = cmd.output()?;
        let stdout = String::from_utf8_lossy(&output.stdout);
        assert!(
            output.status.success(),
            "python exited with {}: {}\n{}",
            output.status,
            stdout,
            String::from_utf8_lossy(&output.stderr)
        );

        let payload: Value = serde_json::from_str(stdout.trim())?;
        let value = payload
            .get("value")
            .and_then(Value::as_str)
            .unwrap_or_default();
        assert_eq!(value, "ok");
        let paths: Vec<String> = payload
            .get("path")
            .and_then(Value::as_array)
            .map(|entries| {
                entries
                    .iter()
                    .filter_map(Value::as_str)
                    .map(std::string::ToString::to_string)
                    .collect()
            })
            .unwrap_or_default();
        let dep_canon = fs::canonicalize(&dep_dir)?;
        assert!(
            paths
                .iter()
                .any(|entry| fs::canonicalize(entry).ok() == Some(dep_canon.clone())),
            "px.pth entries should persist even when PX_ALLOWED_PATHS is unset; sys.path={paths:?}"
        );
        Ok(())
    }

    #[test]
    fn sitecustomize_merges_pythonpath_when_px_allowed_set() -> Result<()> {
        let temp = tempdir()?;
        let site_dir = temp.path().join("site");
        fs::create_dir_all(&site_dir)?;
        fs::write(site_dir.join("sitecustomize.py"), SITE_CUSTOMIZE)?;

        let extra = temp.path().join("extra");
        fs::create_dir_all(&extra)?;
        fs::write(extra.join("shim.py"), "VALUE = 'ok'\n")?;

        let python = match SystemEffects::new().python().detect_interpreter() {
            Ok(path) => path,
            Err(_) => return Ok(()),
        };

        let mut cmd = Command::new(&python);
        cmd.current_dir(temp.path());
        cmd.env_clear();
        cmd.env("PX_ALLOWED_PATHS", site_dir.display().to_string());
        let pythonpath = env::join_paths([extra.clone(), site_dir.clone()])?;
        cmd.env("PYTHONPATH", pythonpath);
        cmd.arg("-c").arg(
            "import json, sys, shim; print(json.dumps({'value': shim.VALUE, 'path': sys.path}))",
        );
        let output = cmd.output()?;
        let stdout = String::from_utf8_lossy(&output.stdout);
        assert!(
            output.status.success(),
            "python exited with {}: {}\n{}",
            output.status,
            stdout,
            String::from_utf8_lossy(&output.stderr)
        );

        let payload: Value = serde_json::from_str(stdout.trim())?;
        let value = payload
            .get("value")
            .and_then(Value::as_str)
            .unwrap_or_default();
        assert_eq!(value, "ok");
        let paths: Vec<String> = payload
            .get("path")
            .and_then(Value::as_array)
            .map(|entries| {
                entries
                    .iter()
                    .filter_map(Value::as_str)
                    .map(std::string::ToString::to_string)
                    .collect()
            })
            .unwrap_or_default();
        let extra_canon = fs::canonicalize(&extra)?;
        assert!(
            paths
                .iter()
                .any(|entry| fs::canonicalize(entry).ok() == Some(extra_canon.clone())),
            "extra PYTHONPATH entries should persist when PX_ALLOWED_PATHS is set; sys.path={paths:?}"
        );
        Ok(())
    }

    #[test]
    fn editable_stub_exposes_project_version_metadata() -> Result<()> {
        let temp = tempdir()?;
        let project_root = temp.path();
        let pyproject = project_root.join("pyproject.toml");
        fs::write(
            &pyproject,
            r#"[project]
name = "demo-proj"
version = "1.2.3"
requires-python = ">=3.11"
dependencies = []

[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"
"#,
        )?;
        let pkg_dir = project_root.join("src/demo_proj");
        fs::create_dir_all(&pkg_dir)?;
        fs::write(pkg_dir.join("__init__.py"), "__version__ = '1.2.3'\n")?;

        let snapshot = ProjectSnapshot::read_from(project_root)?;
        let site_dir = project_root.join(".px").join("env").join("site");
        let effects = SystemEffects::new();
        effects.fs().create_dir_all(&site_dir)?;
        write_sitecustomize(&site_dir, None, effects.fs())?;
        write_project_metadata_stub(&snapshot, &site_dir, effects.fs())?;

        let python = match effects.python().detect_interpreter() {
            Ok(path) => path,
            Err(_) => return Ok(()),
        };
        let allowed = env::join_paths([site_dir.clone(), project_root.join("src")])?;
        let allowed_str = allowed.to_string_lossy().into_owned();
        let mut cmd = Command::new(&python);
        cmd.current_dir(project_root);
        cmd.env("PYTHONPATH", allowed_str.clone());
        cmd.env("PX_ALLOWED_PATHS", allowed_str);
        cmd.arg("-c").arg(
            "import importlib.metadata, json; print(json.dumps({'version': importlib.metadata.version('demo-proj')}))",
        );
        let output = cmd.output()?;
        if !output.status.success() {
            return Ok(());
        }
        let payload: Value = serde_json::from_slice(&output.stdout)?;
        assert_eq!(
            payload.get("version").and_then(Value::as_str),
            Some("1.2.3")
        );
        Ok(())
    }

    #[test]
    fn editable_stub_writes_file_url_direct_url() -> Result<()> {
        let temp = tempdir()?;
        let project_root = temp.path();
        let pyproject = project_root.join("pyproject.toml");
        fs::write(
            &pyproject,
            r#"[project]
name = "demo-dir-url"
version = "0.1.0"
requires-python = ">=3.11"
dependencies = []

[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"
"#,
        )?;
        let pkg_dir = project_root.join("demo_dir_url");
        fs::create_dir_all(&pkg_dir)?;
        fs::write(pkg_dir.join("__init__.py"), "")?;

        let snapshot = ProjectSnapshot::read_from(project_root)?;
        let site_dir = project_root.join(".px").join("env").join("site");
        let effects = SystemEffects::new();
        effects.fs().create_dir_all(&site_dir)?;
        write_project_metadata_stub(&snapshot, &site_dir, effects.fs())?;

        let contents =
            fs::read_to_string(site_dir.join("demo_dir_url-0.1.0.dist-info/direct_url.json"))?;
        let payload: Value = serde_json::from_str(&contents)?;
        let url = payload
            .get("url")
            .and_then(Value::as_str)
            .unwrap_or_default();
        assert!(
            url.starts_with("file://"),
            "direct_url.json should contain a file:// URL, got {url}"
        );
        Ok(())
    }

    #[test]
    fn editable_stub_uses_source_version_when_manifest_missing() -> Result<()> {
        let temp = tempdir()?;
        let project_root = temp.path();
        let pyproject = project_root.join("pyproject.toml");
        fs::write(
            &pyproject,
            r#"[project]
name = "dynamic-demo"
dynamic = ["version"]
requires-python = ">=3.11"
dependencies = []

[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"
"#,
        )?;
        let pkg_dir = project_root.join("src/dynamic_demo");
        fs::create_dir_all(&pkg_dir)?;
        fs::write(pkg_dir.join("__init__.py"), "__version__ = '9.9.9'\n")?;

        let snapshot = ProjectSnapshot::read_from(project_root)?;
        let site_dir = project_root.join(".px").join("env").join("site");
        let effects = SystemEffects::new();
        effects.fs().create_dir_all(&site_dir)?;
        write_sitecustomize(&site_dir, None, effects.fs())?;
        write_project_metadata_stub(&snapshot, &site_dir, effects.fs())?;

        let dist = site_dir
            .join("dynamic_demo-9.9.9.dist-info")
            .join("METADATA");
        let metadata = fs::read_to_string(&dist)?;
        assert!(
            metadata.contains("Version: 9.9.9"),
            "metadata should contain source-derived version"
        );
        Ok(())
    }

    #[test]
    fn editable_stub_prefers_version_file_value() -> Result<()> {
        let temp = tempdir()?;
        let project_root = temp.path();
        let pyproject = project_root.join("pyproject.toml");
        fs::write(
            &pyproject,
            r#"[project]
name = "demo"
dynamic = ["version"]
requires-python = ">=3.11"
dependencies = []

[build-system]
requires = ["hatchling", "hatch-vcs"]
build-backend = "hatchling.build"

[tool.hatch.build.hooks.vcs]
version-file = "src/demo/version.py"
"#,
        )?;
        let pkg_dir = project_root.join("src/demo");
        fs::create_dir_all(&pkg_dir)?;
        fs::write(pkg_dir.join("__init__.py"), "")?;
        fs::write(
            pkg_dir.join("version.py"),
            "version = \"9.9.9\"\n__version__ = version\n",
        )?;

        let snapshot = ProjectSnapshot::read_from(project_root)?;
        let site_dir = project_root.join(".px").join("env").join("site");
        let effects = SystemEffects::new();
        effects.fs().create_dir_all(&site_dir)?;
        write_project_metadata_stub(&snapshot, &site_dir, effects.fs())?;

        let metadata = fs::read_to_string(site_dir.join("demo-9.9.9.dist-info").join("METADATA"))?;
        assert!(
            metadata.contains("Version: 9.9.9"),
            "metadata should use version from version-file stub"
        );
        Ok(())
    }

    #[test]
    fn editable_stub_writes_console_scripts() -> Result<()> {
        let temp = tempdir()?;
        let project_root = temp.path();
        let pyproject = project_root.join("pyproject.toml");
        fs::write(
            &pyproject,
            r#"[project]
name = "demo"
dynamic = ["version"]
requires-python = ">=3.11"
dependencies = []

[project.scripts]
tox = "demo.run:main"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"
"#,
        )?;
        let pkg_dir = project_root.join("src/demo");
        fs::create_dir_all(&pkg_dir)?;
        fs::write(pkg_dir.join("__init__.py"), "__version__ = '1.0.0'\n")?;
        fs::write(pkg_dir.join("run.py"), "def main():\n    return 0\n")?;

        let snapshot = ProjectSnapshot::read_from(project_root)?;
        let site_dir = project_root.join(".px").join("env").join("site");
        let effects = SystemEffects::new();
        effects.fs().create_dir_all(&site_dir)?;
        write_project_metadata_stub(&snapshot, &site_dir, effects.fs())?;

        let script = site_dir.join("bin").join("tox");
        assert!(
            script.exists(),
            "console script should be generated for project entry points"
        );
        let contents = fs::read_to_string(script)?;
        assert!(
            contents.contains("demo.run"),
            "entrypoint should import target module"
        );
        Ok(())
    }

    #[test]
    fn ensure_version_file_populates_missing_file_from_git() -> Result<()> {
        if Command::new("git").arg("--version").status().is_err() {
            return Ok(());
        }
        let temp = tempdir()?;
        let manifest = temp.path().join("pyproject.toml");
        fs::write(
            &manifest,
            r#"[project]
name = "demo"
version = "0.1.0"
requires-python = ">=3.11"

[tool.hatch.build.hooks.vcs]
version-file = "demo/_version.py"
"#,
        )?;
        let demo_dir = temp.path().join("demo");
        fs::create_dir_all(&demo_dir)?;
        fs::write(demo_dir.join("__init__.py"), "")?;

        if Command::new("git").arg("--version").output().is_err() {
            eprintln!("skipping version file test (git not available)");
            return Ok(());
        }

        assert!(
            Command::new("git")
                .arg("init")
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git init failed"
        );
        assert!(
            Command::new("git")
                .args(["config", "user.email", "ci@example.com"])
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git config email failed"
        );
        assert!(
            Command::new("git")
                .args(["config", "user.name", "CI"])
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git config name failed"
        );
        assert!(
            Command::new("git")
                .args(["add", "."])
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git add failed"
        );
        assert!(
            Command::new("git")
                .args(["commit", "-m", "init"])
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git commit failed"
        );

        ensure_version_file(&manifest)?;
        let contents = fs::read_to_string(temp.path().join("demo/_version.py"))?;
        assert!(
            contents.contains("version = \"0.0.0+g"),
            "version file should be derived from git rev"
        );
        assert!(
            contents.contains("__version__ = version"),
            "git stub should alias __version__ to version"
        );
        Ok(())
    }

    #[test]
    fn ensure_version_file_falls_back_without_git_metadata() -> Result<()> {
        let temp = tempdir()?;
        let manifest = temp.path().join("pyproject.toml");
        fs::write(
            &manifest,
            r#"[project]
name = "demo"
version = "0.1.0"
requires-python = ">=3.11"

[tool.hatch.build.hooks.vcs]
version-file = "demo/_version.py"
"#,
        )?;
        let demo_dir = temp.path().join("demo");
        fs::create_dir_all(&demo_dir)?;
        fs::write(demo_dir.join("__init__.py"), "")?;

        ensure_version_file(&manifest)?;
        let contents = fs::read_to_string(temp.path().join("demo/_version.py"))?;
        assert!(
            contents.contains("version = \"0.0.0+unknown\""),
            "fallback version should be written when git metadata is missing"
        );
        assert!(
            contents.contains("__version__ = version"),
            "fallback stub should alias __version__ to version"
        );
        Ok(())
    }

    #[test]
    fn ensure_version_file_upgrades_hatch_stub_missing_alias() -> Result<()> {
        let temp = tempdir()?;
        let manifest = temp.path().join("pyproject.toml");
        fs::write(
            &manifest,
            r#"[project]
name = "demo"
version = "0.1.0"
requires-python = ">=3.11"

[tool.hatch.build.hooks.vcs]
version-file = "demo/_version.py"
"#,
        )?;
        let demo_dir = temp.path().join("demo");
        fs::create_dir_all(&demo_dir)?;
        fs::write(demo_dir.join("__init__.py"), "")?;
        fs::write(demo_dir.join("_version.py"), "__version__ = \"1.2.3\"\n")?;

        ensure_version_file(&manifest)?;
        let contents = fs::read_to_string(demo_dir.join("_version.py"))?;
        assert!(
            contents.contains("version = \"0.0.0+unknown\""),
            "hatch stub should rewrite missing alias with derived version"
        );
        assert!(
            contents.contains("__version__ = version"),
            "hatch stub should alias __version__ to version"
        );
        assert!(
            contents.contains("__all__ = [\"__version__\", \"version\"]"),
            "hatch stub should export both aliases"
        );
        Ok(())
    }

    #[test]
    fn ensure_version_file_supports_setuptools_scm_write_to() -> Result<()> {
        let temp = tempdir()?;
        let manifest = temp.path().join("pyproject.toml");
        fs::write(
            &manifest,
            r#"[project]
name = "demo"
version = "0.1.0"
requires-python = ">=3.11"

[tool.setuptools_scm]
write_to = "demo/_version.py"
"#,
        )?;
        let demo_dir = temp.path().join("demo");
        fs::create_dir_all(&demo_dir)?;
        fs::write(demo_dir.join("__init__.py"), "")?;

        ensure_version_file(&manifest)?;
        let contents = fs::read_to_string(demo_dir.join("_version.py"))?;
        assert!(
            contents.contains("version = \"0.0.0+unknown\""),
            "setuptools_scm stub should include derived version"
        );
        assert!(
            contents.contains("__version__ = version"),
            "setuptools_scm stub should alias __version__"
        );
        assert!(
            contents.contains("version_tuple = tuple(_v.release)"),
            "setuptools_scm stub should export version_tuple from parsed release"
        );
        Ok(())
    }

    #[test]
    fn ensure_version_file_writes_inline_version_stub() -> Result<()> {
        let temp = tempdir()?;
        let manifest = temp.path().join("pyproject.toml");
        fs::write(
            &manifest,
            r#"[project]
name = "demo-pkg"
version = "1.2.3.dev0"
requires-python = ">=3.11"

[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"
"#,
        )?;
        let pkg_dir = temp.path().join("demo_pkg");
        fs::create_dir_all(&pkg_dir)?;
        fs::write(pkg_dir.join("__init__.py"), "")?;
        fs::write(pkg_dir.join("version.pyi"), "version: str\n")?;

        ensure_version_file(&manifest)?;
        let contents = fs::read_to_string(pkg_dir.join("version.py"))?;
        assert!(
            contents.contains("version = \"1.2.3.dev0\""),
            "stub should use manifest version"
        );
        assert!(
            contents.contains("release = False"),
            "dev versions should mark release as False"
        );
        assert!(
            contents.contains("short_version = version.split(\"+\")[0]"),
            "stub should set short_version"
        );
        Ok(())
    }

    #[test]
    fn infers_version_from_versioneer_module() -> Result<()> {
        let temp = tempdir()?;
        let manifest = temp.path().join("pyproject.toml");
        fs::write(
            &manifest,
            r#"[project]
name = "demo-ver"
dynamic = ["version"]
requires-python = ">=3.11"
dependencies = []

[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"
"#,
        )?;
        let pkg_dir = temp.path().join("demo_ver");
        fs::create_dir_all(&pkg_dir)?;
        fs::write(
            pkg_dir.join("__init__.py"),
            "from ._version import get_versions\nv = get_versions()\n__version__ = v.get('closest-tag', v['version'])\n",
        )?;
        fs::write(
            pkg_dir.join("_version.py"),
            "def get_versions():\n    return {'version': '1.2.3+dev', 'closest-tag': 'v1.2.3'}\n",
        )?;

        let metadata =
            load_editable_project_metadata(&manifest, SystemEffects::new().fs()).unwrap();
        assert_eq!(metadata.version, "1.2.3+dev");
        Ok(())
    }

    #[test]
    fn pep440_from_describe_formats_dirty_and_tagged() {
        let version = pep440_from_describe("v1.2.3-4-gabc123").unwrap();
        assert_eq!(version, "1.2.3+4.gabc123");
        let dirty = pep440_from_describe("v0.1.0-0-gdeadbeef-dirty").unwrap();
        assert_eq!(dirty, "0.1.0+0.gdeadbeef.dirty");
    }

    #[test]
    fn pep440_from_describe_handles_tags_with_hyphens() {
        let version = pep440_from_describe("v1.2.3-beta.1-0-gabc123").unwrap();
        assert_eq!(version, "1.2.3-beta.1+0.gabc123");
    }
}
