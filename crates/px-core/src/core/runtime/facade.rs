use std::{
    borrow::Cow,
    collections::{BTreeMap, HashMap, HashSet},
    env, fmt,
    fmt::Write as _,
    fs::{self, File},
    io::Read,
    path::{Path, PathBuf},
    process::Command,
    str::FromStr,
};

use crate::context::{CommandContext, CommandInfo};
use crate::core::runtime::artifacts::select_wheel;
use crate::core::tooling::diagnostics;
use crate::diagnostics::commands as diag_commands;
use crate::effects;
use crate::outcome::{CommandStatus, ExecutionOutcome, InstallUserError};
use crate::process::RunOutput;
use crate::progress::ProgressReporter;
use crate::python_sys::{detect_interpreter, detect_interpreter_tags, detect_marker_environment};
use crate::store::cas::{
    archive_dir_canonical, global_store, pkg_build_lookup_key, run_gc_with_env_policy,
    source_lookup_key, LoadedObject, ObjectKind, ObjectPayload, OwnerId, OwnerType, PkgBuildHeader,
    ProfilePackage, SourceHeader, MATERIALIZED_PKG_BUILDS_DIR,
};
use crate::store::{ensure_wheel_dist, wheel_build_options_hash, ArtifactRequest};
use crate::traceback::{analyze_python_traceback, TracebackContext};
use anyhow::{anyhow, bail, Context, Result};
use hex;
use pep508_rs::MarkerEnvironment;
#[cfg(test)]
use px_domain::LockSnapshot;
use px_domain::{
    analyze_lock_diff, autopin_pin_key, autopin_spec_key, detect_lock_drift, format_specifier,
    load_lockfile_optional, marker_applies, merge_resolved_dependencies, missing_project_guidance,
    render_lockfile, resolve, spec_requires_pin, verify_locked_artifacts, AutopinEntry,
    InstallOverride, MissingProjectGuidance, PinSpec, ProjectSnapshot, PxOptions, ResolverRequest,
    ResolverTags,
};
use serde::{Deserialize, Serialize};
use serde_json::{json, Value};
use sha2::{Digest, Sha256};
use toml_edit::{Array, DocumentMut, Item, Table, TomlError, Value as TomlValue};
use tracing::warn;
use url::Url;

use super::artifacts::{ensure_exact_pins, parse_exact_pin, resolve_pins};
use super::cas_env::{
    copy_tree, default_envs_root, ensure_profile_env, project_env_owner_id, write_python_shim,
};
use crate::effects::Effects;
use crate::runtime_manager;
use crate::tools::disable_proxy_env;

pub(crate) const PX_VERSION: &str = env!("CARGO_PKG_VERSION");
pub(crate) const SITE_CUSTOMIZE: &str = r#"# Auto-generated by px. Do not edit.
import os
import sys
import sysconfig
from pathlib import Path

def _collect_allowed_from_pythonpath():
    allowed = []
    env_py = os.environ.get("PYTHONPATH", "")
    for entry in env_py.split(os.pathsep):
        if not entry:
            continue
        allowed.append(entry)
        pth = Path(entry).joinpath("px.pth")
        try:
            with pth.open() as handle:
                for line in handle:
                    trimmed = line.strip()
                    if trimmed:
                        allowed.append(trimmed)
        except OSError:
            continue
    return allowed

def _stdlib_prefixes():
    prefixes = set()
    for key in ("stdlib", "platstdlib"):
        path = sysconfig.get_path(key)
        if path:
            prefixes.add(os.path.normpath(path))
    for attr in ("base_prefix", "base_exec_prefix", "exec_prefix"):
        value = getattr(sys, attr, None)
        if value:
            prefixes.add(os.path.normpath(value))
    return prefixes

_STD_PREFIXES = _stdlib_prefixes()
_PX_ALLOWED = os.environ.get("PX_ALLOWED_PATHS", "")
_ALLOWED = [p for p in _PX_ALLOWED.split(os.pathsep) if p]
if not _ALLOWED:
    _ALLOWED = _collect_allowed_from_pythonpath()
else:
    for entry in _collect_allowed_from_pythonpath():
        if entry not in _ALLOWED:
            _ALLOWED.append(entry)
_ALLOWED_ENV = os.pathsep.join(_ALLOWED)

_FILTER_PATHS = True
_target_exe = os.environ.get("PX_PYTHON")
if _target_exe:
    try:
        target_real = os.path.realpath(_target_exe)
        current_real = os.path.realpath(sys.executable)
        if os.path.normpath(target_real) != os.path.normpath(current_real):
            _FILTER_PATHS = False
    except Exception:
        _FILTER_PATHS = False

def _allow(path):
    if not path:
        return False
    norm = os.path.normpath(path)
    if os.environ.get("NO_SITE_PACKAGES") and ("site-packages" in norm or "dist-packages" in norm):
        return False
    if "__pypackages__" in norm:
        return True
    for allowed in _ALLOWED:
        try:
            allowed_norm = os.path.normpath(allowed)
        except Exception:
            continue
        if norm == allowed_norm or norm.startswith(allowed_norm + os.sep):
            return True
    for prefix in _STD_PREFIXES:
        if norm == prefix or norm.startswith(prefix + os.sep):
            return True
    return False

if _FILTER_PATHS:
    _new_path = []
    _seen = set()
    _original = list(sys.path)
    _script_dir = sys.path[0] if sys.path else ""
    try:
        _cwd = os.getcwd()
    except Exception:
        _cwd = ""
    if not _script_dir:
        _script_dir = _cwd
    _argv_dir = ""
    try:
        _argv0 = sys.argv[0] if sys.argv else ""
        if _argv0:
            _argv_path = _argv0
            if not os.path.isabs(_argv_path):
                _argv_path = os.path.abspath(_argv_path)
            if os.path.isfile(_argv_path):
                _argv_dir = os.path.dirname(_argv_path)
    except Exception:
        _argv_dir = ""

    def _push(path):
        if not path:
            return
        if path in _seen:
            return
        _seen.add(path)
        _new_path.append(path)

    for path in _ALLOWED:
        _push(path)

    for path in sys.path:
        if _allow(path):
            _push(path)

    if _script_dir:
        _push(_script_dir)
    if _argv_dir:
        _push(_argv_dir)
    if _cwd and _cwd not in _seen:
        _push(_cwd)

    sys.path[:] = _new_path
    # Ensure child processes inherit the px path set instead of a mutated sys.path
    os.environ["PYTHONPATH"] = _ALLOWED_ENV

    _SITE_BIN = Path(__file__).resolve().parent / "bin"
    if not _SITE_BIN.exists():
        current = Path(__file__).resolve().parent
        for _ in range(4):
            candidate = current.parent / "bin"
            if candidate.exists():
                _SITE_BIN = candidate
                break
            current = current.parent
    if _SITE_BIN.exists():
        try:
            import sysconfig as _sysconfig
            _orig_get_path = _sysconfig.get_path
            def _px_get_path(name, scheme=None, vars=None, expand=True):
                if name == "scripts" and scheme is None:
                    return str(_SITE_BIN)
                resolved_scheme = scheme or _sysconfig.get_default_scheme()
                return _orig_get_path(name, scheme=resolved_scheme, vars=vars, expand=expand)
            _sysconfig.get_path = _px_get_path
        except Exception:
            pass
        try:
            current = os.environ.get("PATH", "")
            entries = [str(_SITE_BIN)] + [p for p in current.split(os.pathsep) if p]
            os.environ["PATH"] = os.pathsep.join(entries)
        except Exception:
            pass
else:
    px_allowed = set(_ALLOWED)
    sys.path[:] = [path for path in sys.path if path not in px_allowed]

if "" in sys.path:
    try:
        sys.path.remove("")
    except Exception:
        pass

_debug_dump = os.environ.get("PX_DEBUG_SITE_PATHS")
if _debug_dump:
    try:
        Path(_debug_dump).write_text("\n".join(sys.path))
    except Exception:
        pass

try:
    _perf_baseline = os.environ.get("PX_PYTEST_PERF_BASELINE")
    if _perf_baseline:
        import pytest_perf.runner as _perf_runner
        def _px_perf_upstream_url(extras="", control=None):
            spec = _perf_baseline.replace("{extras}", extras)
            if control and "git+" in spec:
                return spec + f"@{control}"
            return spec
        _perf_runner.upstream_url = _px_perf_upstream_url
except Exception:
    pass

"#;

const SETUPTOOLS_SEED_VERSION: &str = "80.9.0";
const UV_SEED_VERSION: &str = "0.9.15";

pub(crate) type ManifestSnapshot = ProjectSnapshot;

fn is_inline_snapshot(ctx: &CommandContext, snapshot: &ManifestSnapshot) -> bool {
    snapshot.root.starts_with(ctx.cache().path.join("scripts"))
}

#[cfg(unix)]
fn set_exec_permissions(path: &Path) {
    use std::os::unix::fs::PermissionsExt;
    let _ = fs::set_permissions(path, fs::Permissions::from_mode(0o755));
}

#[cfg(not(unix))]
fn set_exec_permissions(_path: &Path) {
    // No-op on non-Unix; rely on defaults.
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "kebab-case")]
pub enum CommandGroup {
    Init,
    Add,
    Remove,
    Sync,
    Update,
    Run,
    Test,
    Fmt,
    Build,
    Publish,
    Migrate,
    Status,
    Why,
    Tool,
    Python,
    Completions,
}

impl fmt::Display for CommandGroup {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        let name = match self {
            CommandGroup::Init => "init",
            CommandGroup::Add => "add",
            CommandGroup::Remove => "remove",
            CommandGroup::Sync => "sync",
            CommandGroup::Update => "update",
            CommandGroup::Run => "run",
            CommandGroup::Test => "test",
            CommandGroup::Fmt => "fmt",
            CommandGroup::Build => "build",
            CommandGroup::Publish => "publish",
            CommandGroup::Migrate => "migrate",
            CommandGroup::Status => "status",
            CommandGroup::Why => "why",
            CommandGroup::Tool => "tool",
            CommandGroup::Python => "python",
            CommandGroup::Completions => "completions",
        };
        f.write_str(name)
    }
}

pub const MISSING_PROJECT_MESSAGE: &str = "No px project found.";
pub const MISSING_PROJECT_HINT: &str = "Run `px init` in your project directory first.";

pub(crate) struct InstallOutcome {
    pub(crate) state: InstallState,
    pub(crate) lockfile: String,
    pub(crate) drift: Vec<String>,
    #[allow(dead_code)]
    pub(crate) verified: bool,
}

#[derive(Clone, Copy, Debug, PartialEq)]
pub(crate) enum InstallState {
    Installed,
    UpToDate,
    Drift,
    MissingLock,
}

pub fn lock_is_fresh(snapshot: &ManifestSnapshot) -> Result<bool> {
    let marker_env = marker_env_for_snapshot(snapshot);
    match load_lockfile_optional(&snapshot.lock_path)? {
        Some(lock) => {
            if !detect_lock_drift(snapshot, &lock, marker_env.as_ref()).is_empty() {
                return Ok(false);
            }
            if let Some(fingerprint) = &lock.manifest_fingerprint {
                Ok(fingerprint == &snapshot.manifest_fingerprint)
            } else {
                Ok(true)
            }
        }
        None => Ok(false),
    }
}

pub(crate) fn relative_path_str(path: &Path, root: &Path) -> String {
    path.strip_prefix(root)
        .unwrap_or(path)
        .display()
        .to_string()
}

pub(crate) fn manifest_snapshot() -> Result<ManifestSnapshot> {
    ProjectSnapshot::read_current()
}

pub(crate) fn manifest_snapshot_at(root: &Path) -> Result<ManifestSnapshot> {
    ProjectSnapshot::read_from(root)
}

fn runtime_marker_environment(snapshot: &ManifestSnapshot) -> Result<MarkerEnvironment> {
    let runtime = prepare_project_runtime(snapshot)?;
    let resolver_env = detect_marker_environment(&runtime.record.path)?;
    resolver_env.to_marker_environment()
}

pub fn marker_env_for_snapshot(snapshot: &ManifestSnapshot) -> Option<MarkerEnvironment> {
    runtime_marker_environment(snapshot).ok().or_else(|| {
        detect_interpreter()
            .ok()
            .and_then(|python| detect_marker_environment(&python).ok())
            .and_then(|env| env.to_marker_environment().ok())
    })
}

pub(crate) fn install_snapshot(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
    frozen: bool,
    override_pins: Option<&InstallOverride>,
) -> Result<InstallOutcome> {
    let inline = is_inline_snapshot(ctx, snapshot);
    let mut snapshot = snapshot.clone();
    let lockfile = snapshot.lock_path.display().to_string();
    let _ = prepare_project_runtime(&snapshot)?;

    if frozen {
        return verify_lock(&snapshot);
    }

    if lock_is_fresh(&snapshot)? {
        Ok(InstallOutcome {
            state: InstallState::UpToDate,
            lockfile,
            drift: Vec::new(),
            verified: false,
        })
    } else {
        if let Some(parent) = snapshot.lock_path.parent() {
            fs::create_dir_all(parent)?;
        }
        let has_foreign_lock =
            snapshot.root.join("uv.lock").exists() || snapshot.root.join("poetry.lock").exists();
        let mut manifest_updated = false;
        let mut manifest_dependencies = if let Some(override_data) = override_pins {
            override_data.dependencies.clone()
        } else {
            snapshot.dependencies.clone()
        };
        let mut requirements =
            merge_requirements(&manifest_dependencies, &snapshot.group_dependencies);
        let marker_env = ctx.marker_environment()?;
        let mut resolved_override = None;
        if override_pins.is_none() {
            let resolved = resolve_dependencies(ctx, &snapshot)?;
            if !resolved.specs.is_empty() && !inline && !has_foreign_lock {
                manifest_dependencies = merge_resolved_dependencies(
                    &manifest_dependencies,
                    &resolved.specs,
                    &marker_env,
                );
                persist_resolved_dependencies(&snapshot, &manifest_dependencies)?;
                manifest_updated = true;
                requirements =
                    merge_requirements(&manifest_dependencies, &snapshot.group_dependencies);
            }
            resolved_override = Some(resolved.pins);
        }
        let pins = if let Some(override_data) = override_pins {
            let mut pins: Vec<PinSpec> = override_data
                .pins
                .iter()
                .filter(|pin| marker_applies(&pin.specifier, &marker_env))
                .cloned()
                .collect();
            if pins.is_empty() {
                for spec in &requirements {
                    if !marker_applies(spec, &marker_env) {
                        continue;
                    }
                    pins.push(parse_exact_pin(spec)?);
                }
            }
            pins
        } else {
            match resolved_override {
                Some(pins) => pins,
                None => ensure_exact_pins(&marker_env, &requirements)?,
            }
        };
        if manifest_updated {
            snapshot = manifest_snapshot_at(&snapshot.root).map_err(|err| {
                InstallUserError::new(
                    "failed to reload project manifest",
                    json!({ "error": err.to_string() }),
                )
            })?;
        }
        let resolved = resolve_pins(ctx, &pins, ctx.config().resolver.force_sdist)?;
        let contents = render_lockfile(&snapshot, &resolved, PX_VERSION)?;
        fs::write(&snapshot.lock_path, contents)?;
        Ok(InstallOutcome {
            state: InstallState::Installed,
            lockfile,
            drift: Vec::new(),
            verified: false,
        })
    }
}

fn merge_requirements(base: &[String], groups: &[String]) -> Vec<String> {
    let mut merged = base.to_vec();
    merged.extend(groups.iter().cloned());
    merged.sort();
    merged.dedup();
    merged
}

pub(crate) fn refresh_project_site(
    snapshot: &ManifestSnapshot,
    ctx: &CommandContext,
) -> Result<()> {
    let previous_env = load_project_state(ctx.fs(), &snapshot.root)
        .ok()
        .and_then(|state| state.current_env);
    let _ = prepare_project_runtime(snapshot)?;
    let lock = load_lockfile_optional(&snapshot.lock_path)?.ok_or_else(|| {
        anyhow!(
            "px sync: lockfile missing at {}",
            snapshot.lock_path.display()
        )
    })?;
    let runtime = detect_runtime_metadata(ctx, snapshot)?;
    let lock_id = match lock.lock_id.clone() {
        Some(value) => value,
        None => compute_lock_hash(&snapshot.lock_path)?,
    };
    let env_owner = OwnerId {
        owner_type: OwnerType::ProjectEnv,
        owner_id: project_env_owner_id(&snapshot.root, &lock_id, &runtime.version)?,
    };
    let cas_profile = ensure_profile_env(ctx, snapshot, &lock, &runtime, &env_owner)?;
    write_project_metadata_stub(snapshot, &cas_profile.env_path, ctx.fs())?;
    let env_python = write_python_environment_markers(
        &cas_profile.env_path,
        &runtime,
        &cas_profile.runtime_path,
        ctx.fs(),
    )?;
    ensure_project_pip(ctx, snapshot, &cas_profile.env_path, &runtime, &env_python)?;
    ensure_project_wheel_scripts(
        &ctx.cache().path,
        snapshot,
        &cas_profile.env_path,
        &runtime,
        &env_owner,
        Some(&cas_profile.profile_oid),
    )?;
    let runtime_state = StoredRuntime {
        path: cas_profile.runtime_path.display().to_string(),
        version: runtime.version.clone(),
        platform: runtime.platform.clone(),
    };
    let local_envs = snapshot.root.join(".px").join("envs");
    ctx.fs().create_dir_all(&local_envs)?;
    let current = local_envs.join("current");
    if current.exists() {
        let _ = fs::remove_file(&current).or_else(|_| fs::remove_dir_all(&current));
    }
    #[cfg(unix)]
    {
        use std::os::unix::fs::symlink;
        let _ = symlink(&cas_profile.env_path, &current);
    }
    #[cfg(not(unix))]
    {
        let _ = fs::remove_dir_all(&current);
        let _ = fs::hard_link(&cas_profile.env_path, &current);
    }
    let site_packages = site_packages_dir(&current, &runtime.version);
    let env_state = StoredEnvironment {
        id: cas_profile.profile_oid.clone(),
        lock_id,
        platform: runtime.platform.clone(),
        site_packages: site_packages.display().to_string(),
        env_path: Some(current.display().to_string()),
        profile_oid: Some(cas_profile.profile_oid.clone()),
        python: StoredPython {
            path: env_python.display().to_string(),
            version: runtime.version.clone(),
        },
    };
    persist_project_state(ctx.fs(), &snapshot.root, env_state, runtime_state)?;

    if let Some(prev) = previous_env {
        if let Some(prev_profile) = prev.profile_oid.as_deref() {
            if prev_profile != cas_profile.profile_oid {
                let store = global_store();
                if let Ok(prev_owner_id) =
                    project_env_owner_id(&snapshot.root, &prev.lock_id, &prev.python.version)
                {
                    let prev_owner = OwnerId {
                        owner_type: OwnerType::ProjectEnv,
                        owner_id: prev_owner_id,
                    };
                    if store.remove_ref(&prev_owner, prev_profile)?
                        && store.refs_for(prev_profile)?.is_empty()
                    {
                        let profile_owner = OwnerId {
                            owner_type: OwnerType::Profile,
                            owner_id: prev_profile.to_string(),
                        };
                        let _ = store.remove_owner_refs(&profile_owner)?;
                        let _ = store.remove_env_materialization(prev_profile);
                    }
                }
            }
        }
    }

    let _ = run_gc_with_env_policy(global_store());
    Ok(())
}

fn project_site_env(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
    site_dir: &Path,
    env_python: &Path,
) -> Result<Vec<(String, String)>> {
    let paths = build_pythonpath(ctx.fs(), &snapshot.root, Some(site_dir.to_path_buf()))?;
    let allowed = env::join_paths(&paths.allowed_paths)
        .context("allowed path contains invalid UTF-8")?
        .into_string()
        .map_err(|_| anyhow!("allowed path contains non-utf8 data"))?;
    let mut envs = vec![
        ("PYTHONPATH".into(), paths.pythonpath.clone()),
        ("PYTHONUNBUFFERED".into(), "1".into()),
        ("PYTHONDONTWRITEBYTECODE".into(), "1".into()),
        ("PYTHONUSERBASE".into(), site_dir.display().to_string()),
        ("PYTHONNOUSERSITE".into(), "1".into()),
        ("PX_ALLOWED_PATHS".into(), allowed),
        (
            "PX_PROJECT_ROOT".into(),
            snapshot.root.display().to_string(),
        ),
        ("PX_PYTHON".into(), env_python.display().to_string()),
    ];
    if let Some(bin) = &paths.site_bin {
        let mut path_entries = vec![bin.clone()];
        if let Some(site_root) = bin.parent() {
            envs.push(("VIRTUAL_ENV".into(), site_root.display().to_string()));
        }
        if let Ok(existing) = env::var("PATH") {
            path_entries.extend(env::split_paths(&existing));
        }
        if let Ok(joined) = env::join_paths(path_entries) {
            if let Ok(value) = joined.into_string() {
                envs.push(("PATH".into(), value));
            }
        }
    }
    disable_proxy_env(&mut envs);
    Ok(envs)
}

fn ensure_project_pip(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
    site_dir: &Path,
    runtime: &RuntimeMetadata,
    env_python: &Path,
) -> Result<()> {
    let debug_pip = std::env::var("PX_DEBUG_PIP").is_ok();
    let skip_ensurepip = std::env::var("PX_NO_ENSUREPIP")
        .map(|v| v == "1" || v.eq_ignore_ascii_case("true"))
        .unwrap_or(false);
    let site_packages = site_packages_dir(site_dir, &runtime.version);
    let pip_installed = has_pip_in_site(&site_packages);
    let pip_editable = has_px_editable_stub(site_dir, &normalize_project_name("pip"));
    let pip_entrypoints =
        site_dir.join("bin").join("pip").exists() || site_dir.join("bin").join("pip3").exists();
    if debug_pip {
        eprintln!(
            "pip bootstrap: installed={pip_installed} editable={pip_editable} entrypoints={pip_entrypoints} site={} root={}",
            site_packages.display(),
            site_dir.display()
        );
    }

    if pip_editable {
        return Ok(());
    }

    let envs = project_site_env(ctx, snapshot, site_dir, env_python)?;
    let mut pip_main_available =
        module_available(ctx, snapshot, env_python, &envs, "pip.__main__")?;

    if skip_ensurepip {
        if !(pip_installed || pip_editable) || !pip_entrypoints || !pip_main_available {
            link_runtime_pip(
                &site_packages,
                &site_dir.join("bin"),
                Path::new(&runtime.path),
                &runtime.version,
            )?;
            pip_main_available =
                module_available(ctx, snapshot, env_python, &envs, "pip.__main__")?;
        }
        if !module_available(ctx, snapshot, env_python, &envs, "pip")? || !pip_main_available {
            return Err(InstallUserError::new(
                "environment missing baseline packaging support",
                json!({
                    "missing": ["pip"],
                    "reason": "missing_pip",
                    "hint": "unset PX_NO_ENSUREPIP or ensure the runtime provides pip so px can seed setuptools",
                    "code": diagnostics::cas::MISSING_OR_CORRUPT,
                }),
            )
            .into());
        }
        ensure_setuptools_seed(ctx, snapshot, &site_packages, env_python, &envs)?;
        ensure_uv_seed(ctx, snapshot, site_dir, env_python, &envs)?;
        return Ok(());
    }

    if !(pip_installed || pip_editable) || !pip_entrypoints || !pip_main_available {
        let output = ctx.python_runtime().run_command(
            env_python
                .to_str()
                .ok_or_else(|| anyhow!("invalid python path"))?,
            &[
                "-m".to_string(),
                "ensurepip".to_string(),
                "--default-pip".to_string(),
                "--upgrade".to_string(),
                "--user".to_string(),
            ],
            &envs,
            &snapshot.root,
        )?;
        if output.code != 0 {
            let mut message = String::from("failed to bootstrap pip in the px environment");
            if !output.stderr.trim().is_empty() {
                message.push_str(": ");
                message.push_str(output.stderr.trim());
            }
            if output.stderr.trim().is_empty() && !output.stdout.trim().is_empty() {
                message.push_str(": ");
                message.push_str(output.stdout.trim());
            }
            if debug_pip {
                eprintln!(
                    "ensurepip failed stdout={}, stderr={}",
                    output.stdout, output.stderr
                );
            }
            bail!(message);
        }
        if debug_pip {
            eprintln!(
                "ensurepip ok stdout={}, stderr={}",
                output.stdout.trim(),
                output.stderr.trim()
            );
        }
        link_runtime_pip(
            &site_packages,
            &site_dir.join("bin"),
            Path::new(&runtime.path),
            &runtime.version,
        )?;
        if debug_pip {
            let after_link = has_pip_in_site(&site_packages);
            eprintln!(
                "post-ensurepip pip_present={} entries={:?}",
                after_link,
                fs::read_dir(&site_packages).ok().map(|iter| {
                    iter.flatten()
                        .map(|e| e.file_name().to_string_lossy().to_string())
                        .collect::<Vec<_>>()
                })
            );
        }
        if !has_pip_in_site(&site_packages) {
            bail!("failed to bootstrap pip in the px environment: pip not installed");
        }
    }
    ensure_setuptools_seed(ctx, snapshot, &site_packages, env_python, &envs)?;
    ensure_uv_seed(ctx, snapshot, site_dir, env_python, &envs)?;

    Ok(())
}

fn module_available(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
    env_python: &Path,
    envs: &[(String, String)],
    module: &str,
) -> Result<bool> {
    let script = format!(
        "import importlib.util, sys; sys.exit(0 if importlib.util.find_spec({module:?}) else 1)"
    );
    let output = ctx.python_runtime().run_command(
        env_python
            .to_str()
            .ok_or_else(|| anyhow!("invalid python path"))?,
        &["-c".to_string(), script],
        envs,
        &snapshot.root,
    )?;
    Ok(output.code == 0)
}

fn ensure_setuptools_seed(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
    site_packages: &Path,
    env_python: &Path,
    envs: &[(String, String)],
) -> Result<()> {
    if module_available(ctx, snapshot, env_python, envs, "setuptools")? {
        return Ok(());
    }

    let release = ctx
        .pypi()
        .fetch_release(
            "setuptools",
            SETUPTOOLS_SEED_VERSION,
            &format!("setuptools=={SETUPTOOLS_SEED_VERSION}"),
        )
        .map_err(|err| {
            InstallUserError::new(
                "failed to locate setuptools for the px environment",
                json!({
                    "package": "setuptools",
                    "version": SETUPTOOLS_SEED_VERSION,
                    "error": err.to_string(),
                    "reason": "missing_artifacts",
                    "hint": "ensure network access or prefetch artifacts, then rerun `px sync`",
                }),
            )
        })?;
    let wheel = release
        .urls
        .iter()
        .filter(|file| file.packagetype == "bdist_wheel" && !file.yanked.unwrap_or(false))
        .find(|file| file.filename.ends_with("py3-none-any.whl"))
        .or_else(|| {
            release
                .urls
                .iter()
                .find(|file| file.packagetype == "bdist_wheel" && !file.yanked.unwrap_or(false))
        })
        .cloned()
        .ok_or_else(|| {
            InstallUserError::new(
                "setuptools wheel unavailable for the px environment",
                json!({
                    "package": "setuptools",
                    "version": SETUPTOOLS_SEED_VERSION,
                    "reason": "missing_artifacts",
                    "hint": "rerun with network access to refresh the wheel cache",
                }),
            )
        })?;
    let filename = wheel.filename.clone();
    let url = wheel.url.clone();
    let sha256 = wheel.digests.sha256.clone();
    let request = ArtifactRequest {
        name: "setuptools",
        version: SETUPTOOLS_SEED_VERSION,
        filename: &filename,
        url: &url,
        sha256: &sha256,
    };
    let cached = ctx
        .cache_store()
        .cache_wheel(&ctx.cache().path, &request)
        .map_err(|err| {
            InstallUserError::new(
                "failed to cache setuptools for the px environment",
                json!({
                    "package": "setuptools",
                    "version": SETUPTOOLS_SEED_VERSION,
                    "error": err.to_string(),
                    "reason": "missing_artifacts",
                    "hint": "rerun with network access to refresh the cache",
                }),
            )
        })?;

    let output = ctx.python_runtime().run_command(
        env_python
            .to_str()
            .ok_or_else(|| anyhow!("invalid python path"))?,
        &[
            "-m".to_string(),
            "pip".to_string(),
            "install".to_string(),
            "--no-deps".to_string(),
            "--no-index".to_string(),
            "--disable-pip-version-check".to_string(),
            "--no-compile".to_string(),
            "--no-warn-script-location".to_string(),
            "--target".to_string(),
            site_packages.display().to_string(),
            cached.wheel_path.display().to_string(),
        ],
        envs,
        &snapshot.root,
    )?;
    if output.code != 0 {
        let mut message = String::from("failed to seed setuptools in the px environment");
        if !output.stderr.trim().is_empty() {
            message.push_str(": ");
            message.push_str(output.stderr.trim());
        }
        if output.stderr.trim().is_empty() && !output.stdout.trim().is_empty() {
            message.push_str(": ");
            message.push_str(output.stdout.trim());
        }
        return Err(InstallUserError::new(
            message,
            json!({
                "package": "setuptools",
                "version": SETUPTOOLS_SEED_VERSION,
                "reason": "missing_artifacts",
            }),
        )
        .into());
    }

    if !module_available(ctx, snapshot, env_python, envs, "setuptools")? {
        return Err(InstallUserError::new(
            "setuptools seed did not install correctly",
            json!({
                "package": "setuptools",
                "version": SETUPTOOLS_SEED_VERSION,
                "reason": "missing_artifacts",
                "hint": "rerun `px sync` to refresh the environment",
            }),
        )
        .into());
    }

    Ok(())
}

fn uv_seed_required(snapshot: &ManifestSnapshot) -> bool {
    snapshot.root.join("uv.lock").exists()
}

fn uv_cli_candidates(site_dir: &Path) -> Vec<PathBuf> {
    vec![
        site_dir.join("bin").join("uv"),
        site_dir.join("bin").join("uvx"),
        site_dir.join("Scripts").join("uv.exe"),
        site_dir.join("Scripts").join("uvx.exe"),
    ]
}

fn has_uv_cli(site_dir: &Path) -> bool {
    uv_cli_candidates(site_dir)
        .into_iter()
        .any(|path| path.exists())
}

fn ensure_uv_seed(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
    site_dir: &Path,
    env_python: &Path,
    envs: &[(String, String)],
) -> Result<()> {
    if !uv_seed_required(snapshot) {
        return Ok(());
    }
    if has_uv_cli(site_dir)
        || module_available(ctx, snapshot, env_python, envs, "uv").unwrap_or(false)
    {
        return Ok(());
    }

    let release = ctx
        .pypi()
        .fetch_release("uv", UV_SEED_VERSION, &format!("uv=={UV_SEED_VERSION}"))
        .map_err(|err| {
            InstallUserError::new(
                "failed to locate uv for the px environment",
                json!({
                    "package": "uv",
                    "version": UV_SEED_VERSION,
                    "error": err.to_string(),
                    "reason": "missing_artifacts",
                    "hint": "ensure network access or prefetch artifacts, then rerun `px sync`",
                }),
            )
        })?;
    let tags = detect_interpreter_tags(
        env_python
            .to_str()
            .ok_or_else(|| anyhow!("invalid python path"))?,
    )?;
    let wheel = select_wheel(&release.urls, &tags, &format!("uv=={UV_SEED_VERSION}"))?;
    let request = ArtifactRequest {
        name: "uv",
        version: UV_SEED_VERSION,
        filename: &wheel.filename,
        url: &wheel.url,
        sha256: &wheel.sha256,
    };
    let cached = ctx
        .cache_store()
        .cache_wheel(&ctx.cache().path, &request)
        .map_err(|err| {
            InstallUserError::new(
                "failed to cache uv for the px environment",
                json!({
                    "package": "uv",
                    "version": UV_SEED_VERSION,
                    "error": err.to_string(),
                    "reason": "missing_artifacts",
                    "hint": "ensure network access or prefetch artifacts, then rerun `px sync`",
                }),
            )
        })?;

    let output = ctx.python_runtime().run_command(
        env_python
            .to_str()
            .ok_or_else(|| anyhow!("invalid python path"))?,
        &[
            "-m".into(),
            "pip".into(),
            "install".into(),
            "--no-deps".into(),
            "--no-index".into(),
            "--disable-pip-version-check".into(),
            "--no-compile".into(),
            "--no-warn-script-location".into(),
            "--prefix".into(),
            site_dir.display().to_string(),
            cached.wheel_path.display().to_string(),
        ],
        envs,
        &snapshot.root,
    )?;
    if output.code != 0 {
        let mut message = String::from("failed to seed uv in the px environment");
        if !output.stderr.trim().is_empty() {
            message.push_str(": ");
            message.push_str(output.stderr.trim());
        }
        if output.stderr.trim().is_empty() && !output.stdout.trim().is_empty() {
            message.push_str(": ");
            message.push_str(output.stdout.trim());
        }
        return Err(InstallUserError::new(
            message,
            json!({
                "package": "uv",
                "version": UV_SEED_VERSION,
                "reason": "missing_artifacts",
            }),
        )
        .into());
    }

    if !has_uv_cli(site_dir) {
        return Err(InstallUserError::new(
            "uv seed did not install correctly",
            json!({
                "package": "uv",
                "version": UV_SEED_VERSION,
                "reason": "missing_artifacts",
                "hint": "rerun `px sync` to refresh the environment",
            }),
        )
        .into());
    }

    Ok(())
}

fn has_pip_in_site(site_packages: &Path) -> bool {
    if site_packages.join("pip").exists() {
        return true;
    }
    if let Ok(entries) = fs::read_dir(site_packages) {
        for entry in entries.flatten() {
            let name = entry.file_name();
            if let Some(name) = name.to_str() {
                if name.starts_with("pip-") && name.ends_with(".dist-info") {
                    return true;
                }
            }
        }
    }
    false
}

fn has_px_editable_stub(site_root: &Path, normalized_name: &str) -> bool {
    let prefix = format!("{normalized_name}-");
    if let Ok(entries) = fs::read_dir(site_root) {
        for entry in entries.flatten() {
            let path = entry.path();
            let Some(name) = path.file_name().and_then(|value| value.to_str()) else {
                continue;
            };
            if !name.starts_with(&prefix) || !name.ends_with(".dist-info") {
                continue;
            }
            if path.join("PX-EDITABLE").exists() {
                return true;
            }
        }
    }
    false
}

fn link_runtime_pip(
    env_site: &Path,
    env_bin: &Path,
    runtime_path: &Path,
    runtime_version: &str,
) -> Result<()> {
    let runtime_root = match runtime_path.parent().and_then(|bin| bin.parent()) {
        Some(root) => root.to_path_buf(),
        None => return Ok(()),
    };
    let Some((major, minor)) = parse_python_version(runtime_version) else {
        return Ok(());
    };
    let runtime_site = runtime_root
        .join("lib")
        .join(format!("python{major}.{minor}"))
        .join("site-packages");
    if runtime_site.exists() {
        let pip_src = runtime_site.join("pip");
        let pip_dest = env_site.join("pip");
        if pip_src.exists() && !pip_dest.exists() {
            symlink_or_copy_dir(&pip_src, &pip_dest)?;
        }

        for entry in fs::read_dir(&runtime_site)? {
            let entry = entry?;
            let name = entry.file_name();
            let Some(name_str) = name.to_str() else {
                continue;
            };
            if !name_str.starts_with("pip") {
                continue;
            }
            let src = entry.path();
            let dest = env_site.join(name);
            if entry.file_type()?.is_dir() && !dest.exists() {
                symlink_or_copy_dir(&src, &dest)?;
            }
        }
    }

    let runtime_bin = runtime_root.join("bin");
    let mut bin_names = vec!["pip".to_string(), "pip3".to_string()];
    bin_names.push(format!("pip{major}"));
    bin_names.push(format!("pip{major}.{minor}"));
    for name in bin_names {
        let src = runtime_bin.join(&name);
        if !src.exists() {
            continue;
        }
        let dest = env_bin.join(&name);
        let _ = install_python_link(&src, &dest);
    }

    Ok(())
}

fn symlink_or_copy_dir(src: &Path, dest: &Path) -> Result<()> {
    if dest.exists() {
        return Ok(());
    }
    #[cfg(unix)]
    {
        use std::os::unix::fs::symlink;
        if symlink(src, dest).is_ok() {
            return Ok(());
        }
    }
    copy_tree(src, dest)
}

#[cfg(test)]
pub fn materialize_project_site(
    site_dir: &Path,
    site_packages: &Path,
    lock: &LockSnapshot,
    python: Option<&Path>,
    fs: &dyn effects::FileSystem,
) -> Result<()> {
    fs.create_dir_all(site_dir)?;
    fs.create_dir_all(site_packages)?;
    let pth_path = site_dir.join("px.pth");
    let pth_copy_path = site_packages.join("px.pth");
    let bin_dir = site_dir.join("bin");
    fs.create_dir_all(&bin_dir)?;
    let mut entries = Vec::new();
    for dep in &lock.resolved {
        let Some(artifact) = &dep.artifact else {
            continue;
        };
        if artifact.cached_path.is_empty() {
            continue;
        }
        let wheel_path = PathBuf::from(&artifact.cached_path);
        if !wheel_path.exists() {
            continue;
        }
        let dist_path = wheel_path.with_extension("dist");
        let entry_path = if dist_path.exists() {
            dist_path
        } else {
            wheel_path
        };
        let _ = materialize_wheel_scripts(&entry_path, &bin_dir, python);
        let canonical = entry_path.canonicalize().unwrap_or(entry_path);
        entries.push(canonical);
    }

    entries.sort();
    entries.dedup();

    let mut contents = entries
        .iter()
        .map(|path| path.display().to_string())
        .collect::<Vec<_>>()
        .join("\n");
    if !contents.is_empty() {
        contents.push('\n');
    }
    fs.write(&pth_path, contents.as_bytes())?;
    fs.write(&pth_copy_path, contents.as_bytes())?;
    write_sitecustomize(site_dir, Some(site_packages), fs)?;
    Ok(())
}

#[derive(Clone, Debug)]
struct EditableProjectMetadata {
    name: String,
    normalized_name: String,
    version: String,
    requires_python: Option<String>,
    requires_dist: Vec<String>,
    optional_requires: BTreeMap<String, Vec<String>>,
    summary: Option<String>,
    entry_points: BTreeMap<String, BTreeMap<String, String>>,
    top_level: Vec<String>,
}

fn write_project_metadata_stub(
    snapshot: &ManifestSnapshot,
    site_dir: &Path,
    fs_ops: &dyn effects::FileSystem,
) -> Result<()> {
    let metadata = match load_editable_project_metadata(&snapshot.manifest_path, fs_ops) {
        Ok(meta) => meta,
        Err(err) => {
            warn!(
                error = %err,
                path = %snapshot.manifest_path.display(),
                "skipping editable metadata stub"
            );
            return Ok(());
        }
    };

    cleanup_editable_metadata(site_dir, &metadata.normalized_name, fs_ops)?;
    if let Some(site_packages) = detect_local_site_packages(fs_ops, site_dir) {
        let prefix = format!("{}-", metadata.normalized_name);
        let mut installed = false;
        if let Ok(entries) = fs_ops.read_dir(&site_packages) {
            for entry in entries.flatten() {
                let file_name = entry.file_name();
                let name = file_name.to_str().unwrap_or_default();
                if name.starts_with(&prefix) && name.ends_with(".dist-info") {
                    installed = true;
                    break;
                }
            }
        }
        if installed {
            if let Ok(entries) = fs_ops.read_dir(site_dir) {
                for entry in entries.flatten() {
                    let file_name = entry.file_name();
                    let name = file_name.to_str().unwrap_or_default();
                    if name.starts_with(&prefix) && name.ends_with(".dist-info") {
                        let _ = fs_ops.remove_dir_all(&entry.path());
                    }
                }
            }
            return Ok(());
        }
    }
    let dist_dir = site_dir.join(format!(
        "{}-{}.dist-info",
        metadata.normalized_name, metadata.version
    ));
    fs_ops.create_dir_all(&dist_dir)?;

    let mut record_paths = Vec::new();

    let metadata_body = render_editable_metadata(&metadata);
    fs_ops.write(&dist_dir.join("METADATA"), metadata_body.as_bytes())?;
    record_paths.push(dist_dir.join("METADATA"));
    if let Some(entry_points) = render_editable_entry_points(&metadata) {
        fs_ops.write(&dist_dir.join("entry_points.txt"), entry_points.as_bytes())?;
        record_paths.push(dist_dir.join("entry_points.txt"));
    }
    let bin_dir = site_dir.join("bin");
    let python_path = bin_dir.join("python");
    let python = Some(python_path.as_path());
    let install_entrypoints = |entries: &BTreeMap<String, String>,
                               record_paths: &mut Vec<PathBuf>| {
        for (name, target) in entries {
            let _ = fs::remove_file(bin_dir.join(name));
            let target_value = target.split_whitespace().next().unwrap_or(target).trim();
            if let Some((module, callable)) = target_value.split_once(':') {
                if let Ok(script_path) =
                    write_entrypoint_script(&bin_dir, name, module.trim(), callable.trim(), python)
                {
                    record_paths.push(script_path);
                }
            }
        }
    };
    if let Some(entries) = metadata.entry_points.get("console_scripts") {
        install_entrypoints(entries, &mut record_paths);
    }
    if let Some(entries) = metadata.entry_points.get("gui_scripts") {
        install_entrypoints(entries, &mut record_paths);
    }

    let project_root = fs_ops
        .canonicalize(&snapshot.root)
        .unwrap_or_else(|_| snapshot.root.clone());
    let direct_url = Url::from_file_path(&project_root)
        .ok()
        .map(|url| url.to_string())
        .unwrap_or_else(|| format!("file://{}", project_root.display()));
    let direct_url = serde_json::to_string_pretty(&json!({
        "dir_info": { "editable": true },
        "url": direct_url,
    }))?;
    fs_ops.write(&dist_dir.join("direct_url.json"), direct_url.as_bytes())?;
    record_paths.push(dist_dir.join("direct_url.json"));
    fs_ops.write(&dist_dir.join("INSTALLER"), b"px\n")?;
    record_paths.push(dist_dir.join("INSTALLER"));
    fs_ops.write(&dist_dir.join("PX-EDITABLE"), b"px\n")?;
    record_paths.push(dist_dir.join("PX-EDITABLE"));

    if !metadata.top_level.is_empty() {
        let mut body = metadata.top_level.join("\n");
        body.push('\n');
        fs_ops.write(&dist_dir.join("top_level.txt"), body.as_bytes())?;
        record_paths.push(dist_dir.join("top_level.txt"));
    }
    write_record_file(site_dir, &dist_dir, record_paths, fs_ops)?;
    Ok(())
}

fn uses_maturin_backend(manifest_path: &Path) -> Result<bool> {
    let contents = fs::read_to_string(manifest_path)?;
    let doc: DocumentMut = contents.parse()?;
    let mut uses_maturin = doc
        .get("build-system")
        .and_then(Item::as_table)
        .and_then(|table| table.get("requires"))
        .and_then(Item::as_array)
        .map(|requires| {
            requires
                .iter()
                .filter_map(|value| value.as_str())
                .any(|entry| entry.to_ascii_lowercase().contains("maturin"))
        })
        .unwrap_or(false);

    if !uses_maturin {
        uses_maturin = doc
            .get("tool")
            .and_then(Item::as_table)
            .and_then(|tool| tool.get("maturin"))
            .and_then(Item::as_table)
            .map(|table| !table.is_empty())
            .unwrap_or(false);
    }

    Ok(uses_maturin)
}

#[derive(Default, Deserialize, Serialize)]
#[serde(default)]
struct WheelCacheMeta {
    wheel: String,
    sha256: String,
    name: Option<String>,
    version: Option<String>,
}

fn project_wheel_cache_dir(
    cache_root: &Path,
    snapshot: &ManifestSnapshot,
    runtime: &RuntimeMetadata,
    python: &Path,
    keep_proxies: bool,
    build_hash: &str,
) -> PathBuf {
    let cache_key = format!(
        "{}:{}:{}:{}:{}:{}",
        snapshot.manifest_fingerprint,
        runtime.version,
        runtime.platform,
        python.display(),
        keep_proxies,
        build_hash
    );
    let key_hash = hex::encode(Sha256::digest(cache_key.as_bytes()));
    cache_root
        .join("project-wheels")
        .join(normalize_project_name(&snapshot.name))
        .join(key_hash)
}

fn cached_project_wheel(dir: &Path) -> Result<Option<PathBuf>> {
    let meta_path = dir.join("wheel.json");
    if meta_path.exists() {
        let contents = fs::read_to_string(&meta_path)?;
        let meta: WheelCacheMeta = serde_json::from_str(&contents).unwrap_or_default();
        if !meta.wheel.is_empty() && !meta.sha256.is_empty() {
            let wheel_path = dir.join(&meta.wheel);
            if wheel_path.exists()
                && compute_file_sha256(&wheel_path).ok().as_deref() == Some(meta.sha256.as_str())
            {
                ensure_nonempty_wheel(&wheel_path)?;
                return Ok(Some(wheel_path));
            }
        }
    }

    let Ok(entries) = fs::read_dir(dir) else {
        return Ok(None);
    };
    for entry in entries.flatten() {
        let path = entry.path();
        if !path
            .extension()
            .and_then(|ext| ext.to_str())
            .is_some_and(|ext| ext.eq_ignore_ascii_case("whl"))
        {
            continue;
        }
        ensure_nonempty_wheel(&path)?;
        let sha = compute_file_sha256(&path)?;
        if let Ok(dist_dir) = ensure_wheel_dist(&path, &sha) {
            if let Ok((name, version)) = wheel_metadata(&dist_dir) {
                let _ = persist_wheel_metadata(dir, &path, &sha, &name, &version);
            }
        }
        return Ok(Some(path));
    }
    Ok(None)
}

fn reuse_cached_project_wheel(
    cache_root: &Path,
    snapshot: &ManifestSnapshot,
    target_dir: &Path,
) -> Result<Option<PathBuf>> {
    let project_dir = cache_root
        .join("project-wheels")
        .join(normalize_project_name(&snapshot.name));
    let mut candidates = match fs::read_dir(project_dir) {
        Ok(entries) => entries
            .flatten()
            .map(|entry| entry.path())
            .collect::<Vec<_>>(),
        Err(_) => Vec::new(),
    };
    candidates.sort();

    for candidate in candidates {
        if candidate == target_dir || !candidate.is_dir() {
            continue;
        }
        if let Some(existing) = cached_project_wheel(&candidate)? {
            let Some(filename) = existing.file_name() else {
                continue;
            };
            fs::create_dir_all(target_dir)?;
            let dest = target_dir.join(filename);
            fs::copy(&existing, &dest)?;
            let sha256 = compute_file_sha256(&dest)?;
            let dist_dir = ensure_wheel_dist(&dest, &sha256)?;
            let (name, version) = wheel_metadata(&dist_dir)?;
            persist_wheel_metadata(target_dir, &dest, &sha256, &name, &version)?;
            return Ok(Some(dest));
        }
    }

    Ok(None)
}

fn ensure_project_wheel_scripts(
    cache_root: &Path,
    snapshot: &ManifestSnapshot,
    env_root: &Path,
    runtime: &RuntimeMetadata,
    env_owner: &OwnerId,
    profile_oid: Option<&str>,
) -> Result<bool> {
    if !uses_maturin_backend(&snapshot.manifest_path)? {
        return Ok(false);
    }

    let python = env_root.join("bin").join("python");
    let python_path = if python.exists() {
        python
    } else {
        PathBuf::from(&runtime.path)
    };
    let keep_proxies = env::var("PX_KEEP_PROXIES")
        .map(|v| v == "1" || v.eq_ignore_ascii_case("true"))
        .unwrap_or(false);
    let build_hash = project_build_hash(runtime, snapshot, &python_path, keep_proxies)?;
    let cache_dir = project_wheel_cache_dir(
        cache_root,
        snapshot,
        runtime,
        &python_path,
        keep_proxies,
        &build_hash,
    );
    fs::create_dir_all(&cache_dir)?;

    let store = global_store();
    let lock_id = format!(
        "project-wheel:{}:{}",
        snapshot.name,
        cache_dir
            .file_name()
            .and_then(|name| name.to_str())
            .unwrap_or("cache")
    );
    let _lock = store.acquire_lock(&lock_id)?;

    let wheel_path = match cached_project_wheel(&cache_dir)? {
        Some(path) => path,
        None => match reuse_cached_project_wheel(cache_root, snapshot, &cache_dir)? {
            Some(path) => path,
            None => build_project_wheel(&python_path, &snapshot.root, &cache_dir, keep_proxies)?,
        },
    };

    let bin_dir = env_root.join("bin");
    let shebang_python = bin_dir.join("python");
    let python_for_scripts = shebang_python.exists().then_some(shebang_python.as_path());
    let sha256 = compute_file_sha256(&wheel_path)?;
    let dist_dir = ensure_wheel_dist(&wheel_path, &sha256)?;
    let (pkg_name, pkg_version) = wheel_metadata(&dist_dir)?;
    let pkg_oid =
        store_project_wheel_in_cas(&wheel_path, &sha256, &dist_dir, &python_path, &build_hash)?;

    materialize_wheel_scripts(&dist_dir, &bin_dir, python_for_scripts)
        .with_context(|| format!("installing project scripts from {}", wheel_path.display()))?;
    persist_wheel_metadata(&cache_dir, &wheel_path, &sha256, &pkg_name, &pkg_version)?;
    let _ = store.add_ref(env_owner, &pkg_oid);
    if let Some(profile) = profile_oid {
        let profile_owner = OwnerId {
            owner_type: OwnerType::Profile,
            owner_id: profile.to_string(),
        };
        let _ = store.add_ref(&profile_owner, &pkg_oid);
    }
    Ok(true)
}

fn strip_proxy_env(cmd: &mut Command) {
    for key in [
        "HTTP_PROXY",
        "http_proxy",
        "HTTPS_PROXY",
        "https_proxy",
        "ALL_PROXY",
        "all_proxy",
    ] {
        cmd.env_remove(key);
    }
}

fn compute_file_sha256(path: &Path) -> Result<String> {
    let mut file = File::open(path)?;
    let mut hasher = Sha256::new();
    let mut buf = [0u8; 8192];
    loop {
        let read = file.read(&mut buf)?;
        if read == 0 {
            break;
        }
        hasher.update(&buf[..read]);
    }
    Ok(hex::encode(hasher.finalize()))
}

fn ensure_nonempty_wheel(path: &Path) -> Result<()> {
    let file = File::open(path)?;
    let archive = zip::ZipArchive::new(file)?;
    if archive.is_empty() {
        bail!(
            "project wheel build produced an empty archive at {}",
            path.display()
        );
    }
    Ok(())
}

fn build_project_wheel(
    python: &Path,
    project_root: &Path,
    out_dir: &Path,
    keep_proxies: bool,
) -> Result<PathBuf> {
    fs::create_dir_all(out_dir)?;
    let staging = out_dir.join("build");
    if staging.exists() {
        let _ = fs::remove_dir_all(&staging);
    }
    fs::create_dir_all(&staging)?;

    let mut pip_cmd = Command::new(python);
    pip_cmd
        .arg("-m")
        .arg("pip")
        .arg("wheel")
        .arg("--no-deps")
        .arg("--wheel-dir")
        .arg(&staging)
        .arg(project_root);
    pip_cmd.current_dir(project_root);
    if !keep_proxies {
        strip_proxy_env(&mut pip_cmd);
    }
    let pip_output = pip_cmd
        .output()
        .with_context(|| format!("running python -m pip wheel in {}", project_root.display()))?;
    if pip_output.status.success() {
        let wheel = find_wheel_in_dir(&staging)?;
        let final_path = out_dir.join(
            wheel
                .file_name()
                .unwrap_or_default()
                .to_string_lossy()
                .to_string(),
        );
        fs::rename(&wheel, &final_path)?;
        let _ = fs::remove_dir_all(&staging);
        return Ok(final_path);
    }

    let mut build_cmd = Command::new(python);
    build_cmd
        .arg("-m")
        .arg("build")
        .arg("--wheel")
        .arg("--outdir")
        .arg(&staging)
        .arg(project_root);
    build_cmd.current_dir(project_root);
    if !keep_proxies {
        strip_proxy_env(&mut build_cmd);
    }
    let build_output = build_cmd.output().with_context(|| {
        format!(
            "running python -m build --wheel in {}",
            project_root.display()
        )
    })?;
    if build_output.status.success() {
        let wheel = find_wheel_in_dir(&staging)?;
        let final_path = out_dir.join(
            wheel
                .file_name()
                .unwrap_or_default()
                .to_string_lossy()
                .to_string(),
        );
        fs::rename(&wheel, &final_path)?;
        let _ = fs::remove_dir_all(&staging);
        return Ok(final_path);
    }

    let pip_stderr = String::from_utf8_lossy(&pip_output.stderr);
    let build_stderr = String::from_utf8_lossy(&build_output.stderr);
    bail!(
        "failed to build project wheel via pip and python -m build\npip stderr:\n{}\npython -m build stderr:\n{}",
        pip_stderr,
        build_stderr
    );
}

fn find_wheel_in_dir(dir: &Path) -> Result<PathBuf> {
    let wheel = fs::read_dir(dir)?
        .flatten()
        .map(|entry| entry.path())
        .find(|path| {
            path.extension()
                .and_then(|ext| ext.to_str())
                .is_some_and(|ext| ext.eq_ignore_ascii_case("whl"))
        })
        .ok_or_else(|| {
            anyhow!(
                "project wheel build did not produce a wheel in {}",
                dir.display()
            )
        })?;
    ensure_nonempty_wheel(&wheel)?;
    Ok(wheel)
}

fn wheel_metadata(dist_dir: &Path) -> Result<(String, String)> {
    let meta = fs::read_dir(dist_dir)?
        .flatten()
        .map(|entry| entry.path())
        .find(|path| {
            path.file_name()
                .and_then(|name| name.to_str())
                .is_some_and(|name| name.ends_with(".dist-info"))
        })
        .ok_or_else(|| anyhow!("wheel dist-info missing in {}", dist_dir.display()))?;
    let metadata = meta.join("METADATA");
    let contents = fs::read_to_string(&metadata)
        .with_context(|| format!("reading wheel metadata at {}", metadata.display()))?;
    let mut name = String::new();
    let mut version = String::new();
    for line in contents.lines() {
        if let Some(value) = line.strip_prefix("Name:") {
            name = value.trim().to_string();
        }
        if let Some(value) = line.strip_prefix("Version:") {
            version = value.trim().to_string();
        }
        if !name.is_empty() && !version.is_empty() {
            break;
        }
    }
    if name.is_empty() || version.is_empty() {
        bail!(
            "wheel metadata missing name/version in {}",
            metadata.display()
        );
    }
    Ok((name, version))
}

fn persist_wheel_metadata(
    cache_dir: &Path,
    wheel_path: &Path,
    sha256: &str,
    name: &str,
    version: &str,
) -> Result<()> {
    let meta = WheelCacheMeta {
        wheel: wheel_path
            .file_name()
            .map(|name| name.to_string_lossy().to_string())
            .unwrap_or_default(),
        sha256: sha256.to_string(),
        name: Some(name.to_string()),
        version: Some(version.to_string()),
    };
    let body = serde_json::to_string_pretty(&meta)?;
    fs::write(cache_dir.join("wheel.json"), body)?;
    Ok(())
}

fn runtime_abi_tag(python: &str) -> Result<String> {
    let tags = crate::python_sys::detect_interpreter_tags(python)?;
    let py = tags
        .python
        .first()
        .cloned()
        .unwrap_or_else(|| "py3".to_string());
    let abi = tags
        .abi
        .first()
        .cloned()
        .unwrap_or_else(|| "abi3".to_string());
    let platform = tags
        .platform
        .first()
        .cloned()
        .unwrap_or_else(|| "any".to_string());
    Ok(format!("{py}-{abi}-{platform}"))
}

fn project_build_hash(
    runtime: &RuntimeMetadata,
    snapshot: &ManifestSnapshot,
    python: &Path,
    keep_proxies: bool,
) -> Result<String> {
    let build_env_hash = wheel_build_options_hash(&python.display().to_string())?;
    let payload = json!({
        "runtime": runtime.version,
        "platform": runtime.platform,
        "manifest": snapshot.manifest_fingerprint,
        "python": python.display().to_string(),
        "keep_proxies": keep_proxies,
        "build_env": build_env_hash,
    });
    Ok(hex::encode(Sha256::digest(
        serde_json::to_vec(&payload).unwrap_or_default(),
    )))
}

fn store_project_wheel_in_cas(
    wheel_path: &Path,
    sha256: &str,
    dist_dir: &Path,
    python: &Path,
    build_options_hash: &str,
) -> Result<String> {
    let (name, version) = wheel_metadata(dist_dir)?;
    let bytes = fs::read(wheel_path)?;
    let header = SourceHeader {
        name: name.clone(),
        version: version.clone(),
        filename: wheel_path
            .file_name()
            .map(|v| v.to_string_lossy().to_string())
            .unwrap_or_else(|| "wheel.whl".into()),
        index_url: format!("file://{}", wheel_path.display()),
        sha256: sha256.to_string(),
    };
    let store = global_store();
    let source_key = source_lookup_key(&header);
    let source_oid = match store.lookup_key(ObjectKind::Source, &source_key)? {
        Some(existing) => existing,
        None => {
            let payload = ObjectPayload::Source {
                header: header.clone(),
                bytes: Cow::Owned(bytes),
            };
            let stored = store.store(&payload)?;
            store.record_key(ObjectKind::Source, &source_key, &stored.oid)?;
            stored.oid
        }
    };

    let runtime_abi = runtime_abi_tag(&python.display().to_string())?;
    let pkg_header = PkgBuildHeader {
        source_oid,
        runtime_abi,
        build_options_hash: build_options_hash.to_string(),
    };
    let pkg_key = pkg_build_lookup_key(&pkg_header);
    let pkg_oid = match store.lookup_key(ObjectKind::PkgBuild, &pkg_key)? {
        Some(existing) => existing,
        None => {
            let archive = archive_dir_canonical(dist_dir)?;
            let payload = ObjectPayload::PkgBuild {
                header: pkg_header,
                archive: Cow::Owned(archive),
            };
            let stored = store.store(&payload)?;
            store.record_key(ObjectKind::PkgBuild, &pkg_key, &stored.oid)?;
            stored.oid
        }
    };
    Ok(pkg_oid)
}

fn cleanup_editable_metadata(
    site_dir: &Path,
    normalized_name: &str,
    fs_ops: &dyn effects::FileSystem,
) -> Result<()> {
    if let Ok(entries) = fs_ops.read_dir(site_dir) {
        for entry in entries.flatten() {
            let path = entry.path();
            let Some(name) = path.file_name().and_then(|value| value.to_str()) else {
                continue;
            };
            if !name.starts_with(&format!("{normalized_name}-")) || !name.ends_with(".dist-info") {
                continue;
            }
            let marker = path.join("PX-EDITABLE");
            if marker.exists() {
                let _ = fs_ops.remove_dir_all(&path);
            }
        }
    }
    Ok(())
}

fn write_record_file(
    site_dir: &Path,
    dist_dir: &Path,
    mut record_paths: Vec<PathBuf>,
    fs_ops: &dyn effects::FileSystem,
) -> Result<()> {
    let record_path = dist_dir.join("RECORD");
    record_paths.push(record_path.clone());
    let mut seen = HashSet::new();
    let mut lines = Vec::new();
    for path in record_paths {
        if !path.exists() {
            continue;
        }
        let rel = path.strip_prefix(site_dir).unwrap_or(path.as_path());
        let rel_str = rel.to_string_lossy().replace('\\', "/");
        if !seen.insert(rel_str.clone()) {
            continue;
        }
        lines.push(format!("{rel_str},,"));
    }
    lines.sort();
    fs_ops.write(&record_path, lines.join("\n").as_bytes())?;
    Ok(())
}

fn load_editable_project_metadata(
    manifest_path: &Path,
    fs_ops: &dyn effects::FileSystem,
) -> Result<EditableProjectMetadata> {
    let contents = fs_ops.read_to_string(manifest_path)?;
    let doc: DocumentMut = contents.parse()?;
    let project = project_table(&doc)?;
    let name = project
        .get("name")
        .and_then(Item::as_str)
        .ok_or_else(|| anyhow!("pyproject missing [project].name"))?
        .to_string();
    let normalized_name = normalize_project_name(&name);
    let root = manifest_path
        .parent()
        .map(Path::to_path_buf)
        .unwrap_or_else(|| PathBuf::from("."));
    let version = project
        .get("version")
        .and_then(Item::as_str)
        .map(std::string::ToString::to_string)
        .or_else(|| infer_version_from_version_file(&root, &doc, fs_ops))
        .or_else(|| infer_version_from_versioneer(&root, &normalized_name, fs_ops))
        .or_else(|| infer_version_from_hatch_vcs(&root, &doc))
        .or_else(|| infer_version_from_sources(&root, &normalized_name, fs_ops))
        .unwrap_or_else(|| "0.0.0+unknown".to_string());
    let requires_python = project
        .get("requires-python")
        .and_then(Item::as_str)
        .map(std::string::ToString::to_string);
    let requires_dist = project
        .get("dependencies")
        .and_then(Item::as_array)
        .map(|array| {
            array
                .iter()
                .filter_map(|value| value.as_str().map(std::string::ToString::to_string))
                .collect::<Vec<_>>()
        })
        .unwrap_or_default();
    let optional_requires = collect_optional_dependencies(project);
    let summary = project
        .get("description")
        .and_then(Item::as_str)
        .map(std::string::ToString::to_string);
    let entry_points = collect_entry_points(project);
    let top_level = discover_top_level_modules(&root, &normalized_name, fs_ops);

    Ok(EditableProjectMetadata {
        name,
        normalized_name,
        version,
        requires_python,
        requires_dist,
        optional_requires,
        summary,
        entry_points,
        top_level,
    })
}

fn infer_version_from_version_file(
    manifest_root: &Path,
    doc: &DocumentMut,
    fs_ops: &dyn effects::FileSystem,
) -> Option<String> {
    let candidates = [
        hatch_version_file(doc),
        setuptools_scm_version_file(doc),
        pdm_version_file(doc),
    ];
    for relative in candidates.into_iter().flatten() {
        let path = manifest_root.join(relative);
        if fs_ops.metadata(&path).is_err() {
            continue;
        }
        if let Ok(contents) = fs_ops.read_to_string(&path) {
            let trimmed = contents.trim();
            if !trimmed.is_empty()
                && !trimmed.contains('=')
                && !trimmed.contains("__version__")
                && !trimmed.contains('\n')
            {
                return Some(trimmed.to_string());
            }
            for line in contents.lines() {
                let trimmed = line.trim_start();
                if let Some(raw) = trimmed.strip_prefix("version =") {
                    let value = raw.trim().trim_matches('"');
                    if !value.is_empty() {
                        return Some(value.to_string());
                    }
                }
                if trimmed.starts_with("__version__") {
                    if let Some((_, raw_value)) = trimmed.split_once('=') {
                        let value = raw_value.trim();
                        if value.starts_with('"') || value.starts_with('\'') {
                            let clean = value
                                .trim_matches(|ch| matches!(ch, '"' | '\''))
                                .to_string();
                            if !clean.is_empty() {
                                return Some(clean);
                            }
                        }
                    }
                }
            }
        }
    }
    None
}

fn infer_version_from_versioneer(
    project_root: &Path,
    normalized_name: &str,
    fs_ops: &dyn effects::FileSystem,
) -> Option<String> {
    let module = normalized_name.replace(['-', '.'], "_").to_lowercase();
    let candidates = [
        project_root.join("src").join(&module).join("_version.py"),
        project_root.join(&module).join("_version.py"),
    ];
    let path = candidates
        .iter()
        .find(|path| fs_ops.metadata(path).is_ok())?;

    let python = detect_interpreter().ok()?;
    let script = format!(
        r#"import importlib.util, json, pathlib
path = pathlib.Path({path:?})
spec = importlib.util.spec_from_file_location("px_versioneer", path)
if spec is None or spec.loader is None:
    print(json.dumps({{}}))
    raise SystemExit(0)
mod = importlib.util.module_from_spec(spec)
spec.loader.exec_module(mod)
getter = getattr(mod, "get_versions", None) or getattr(mod, "get_version", None)
version = None
if callable(getter):
    value = getter()
    if isinstance(value, dict):
        version = value.get("version") or value.get("closest-tag") or value.get("closest_tag")
    else:
        version = value
print(json.dumps({{"version": version}}))
"#
    );
    let output = Command::new(python)
        .args(["-c", &script])
        .current_dir(project_root)
        .output()
        .ok()?;
    if !output.status.success() {
        return None;
    }
    let payload: Value = serde_json::from_slice(&output.stdout).ok()?;
    payload
        .get("version")
        .and_then(Value::as_str)
        .map(std::string::ToString::to_string)
        .filter(|value| !value.is_empty())
}

fn infer_version_from_hatch_vcs(manifest_root: &Path, doc: &DocumentMut) -> Option<String> {
    if !uses_hatch_vcs(doc) {
        return None;
    }
    let describe = hatch_git_describe_command(doc);
    let simplify = hatch_prefers_simplified_semver(doc);
    let drop_local = hatch_drops_local_version(doc);
    derive_vcs_version(
        manifest_root,
        &VersionDeriveOptions {
            git_describe_command: describe.as_deref(),
            simplified_semver: simplify,
            drop_local,
        },
    )
    .ok()
}

fn infer_version_from_sources(
    project_root: &Path,
    normalized_name: &str,
    fs_ops: &dyn effects::FileSystem,
) -> Option<String> {
    let module_name = normalized_name.replace(['-', '.'], "_").to_lowercase();
    let candidates = [
        project_root
            .join("src")
            .join(&module_name)
            .join("__init__.py"),
        project_root.join(&module_name).join("__init__.py"),
    ];
    for candidate in candidates {
        if fs_ops.metadata(&candidate).is_err() {
            continue;
        }
        if let Ok(contents) = fs_ops.read_to_string(&candidate) {
            for line in contents.lines() {
                let trimmed = line.trim_start();
                if !trimmed.starts_with("__version__") {
                    continue;
                }
                if let Some((_, raw_value)) = trimmed.split_once('=') {
                    let value = raw_value.trim();
                    let quoted = (value.starts_with('"') && value.ends_with('"'))
                        || (value.starts_with('\'') && value.ends_with('\''));
                    if !quoted {
                        continue;
                    }
                    let cleaned = value.trim_matches(|ch| ch == '"' || ch == '\'');
                    if !cleaned.is_empty() {
                        return Some(cleaned.to_string());
                    }
                }
            }
        }
    }
    None
}

fn discover_top_level_modules(
    project_root: &Path,
    normalized_name: &str,
    fs_ops: &dyn effects::FileSystem,
) -> Vec<String> {
    let mut names = Vec::new();
    let mut push_name = |value: &str| {
        if !value.is_empty() && !value.starts_with('.') && value != "__pycache__" {
            names.push(value.to_string());
        }
    };
    for base in [project_root.join("src"), project_root.to_path_buf()] {
        if let Ok(entries) = fs_ops.read_dir(&base) {
            for entry in entries.flatten() {
                let path = entry.path();
                if path.is_dir() {
                    if fs_ops.metadata(&path.join("__init__.py")).is_ok() {
                        if let Some(value) = path.file_name().and_then(|name| name.to_str()) {
                            push_name(value);
                        }
                    }
                } else if path.extension().is_some_and(|ext| ext == "py") {
                    if let Some(stem) = path.file_stem().and_then(|name| name.to_str()) {
                        push_name(stem);
                    }
                }
            }
        }
    }
    if names.is_empty() {
        names.push(normalized_name.replace(['-', '.'], "_").to_lowercase());
    }
    names.sort();
    names.dedup();
    names
}

fn collect_optional_dependencies(project: &Table) -> BTreeMap<String, Vec<String>> {
    let mut extras = BTreeMap::new();
    if let Some(optional) = project
        .get("optional-dependencies")
        .and_then(toml_edit::Item::as_table)
    {
        for (name, array) in optional.iter() {
            if let Some(values) = array.as_array() {
                let mut deps = Vec::new();
                for value in values {
                    if let Some(spec) = value.as_str() {
                        deps.push(spec.to_string());
                    }
                }
                if !deps.is_empty() {
                    extras.insert(name.to_string(), deps);
                }
            }
        }
    }
    extras
}

fn collect_entry_points(project: &Table) -> BTreeMap<String, BTreeMap<String, String>> {
    let mut groups = BTreeMap::new();
    collect_entry_point_group(project, "scripts", "console_scripts", &mut groups);
    collect_entry_point_group(project, "gui-scripts", "gui_scripts", &mut groups);
    if let Some(ep_table) = project
        .get("entry-points")
        .and_then(toml_edit::Item::as_table)
    {
        for (group, table) in ep_table.iter() {
            if let Some(entries) = table.as_table() {
                let mut mapped = BTreeMap::new();
                for (name, value) in entries.iter() {
                    if let Some(target) = value.as_str() {
                        mapped.insert(name.to_string(), target.to_string());
                    }
                }
                if !mapped.is_empty() {
                    groups.insert(group.to_string(), mapped);
                }
            }
        }
    }
    groups
}

fn collect_entry_point_group(
    project: &Table,
    project_key: &str,
    entry_point_group: &str,
    groups: &mut BTreeMap<String, BTreeMap<String, String>>,
) {
    if let Some(scripts) = project.get(project_key).and_then(toml_edit::Item::as_table) {
        let mut mapped = BTreeMap::new();
        for (name, value) in scripts.iter() {
            if let Some(target) = value.as_str() {
                mapped.insert(name.to_string(), target.to_string());
            }
        }
        if !mapped.is_empty() {
            groups.insert(entry_point_group.to_string(), mapped);
        }
    }
}

fn render_editable_entry_points(metadata: &EditableProjectMetadata) -> Option<String> {
    if metadata.entry_points.is_empty() {
        return None;
    }
    let mut sections = Vec::new();
    for (group, entries) in &metadata.entry_points {
        sections.push(format!("[{group}]"));
        for (name, target) in entries {
            sections.push(format!("{name} = {target}"));
        }
        sections.push(String::new());
    }
    Some(sections.join("\n"))
}

fn render_editable_metadata(metadata: &EditableProjectMetadata) -> String {
    let mut lines = Vec::new();
    lines.push("Metadata-Version: 2.1".to_string());
    lines.push(format!("Name: {}", metadata.name));
    lines.push(format!("Version: {}", metadata.version));
    if let Some(summary) = &metadata.summary {
        lines.push(format!("Summary: {summary}"));
    }
    if let Some(rp) = &metadata.requires_python {
        lines.push(format!("Requires-Python: {rp}"));
    }
    for extra in metadata.optional_requires.keys() {
        lines.push(format!("Provides-Extra: {extra}"));
    }
    for req in &metadata.requires_dist {
        lines.push(format!("Requires-Dist: {req}"));
    }
    for (extra, reqs) in &metadata.optional_requires {
        for req in reqs {
            lines.push(format!(r#"Requires-Dist: {req} ; extra == "{extra}""#));
        }
    }
    lines.push(String::new());
    lines.join("\n")
}

fn normalize_project_name(name: &str) -> String {
    let mut result = String::new();
    for ch in name.chars() {
        if matches!(ch, '-' | '.' | ' ') {
            result.push('_');
        } else {
            result.push(ch);
        }
    }
    result
}

fn write_entrypoint_script(
    bin_dir: &Path,
    name: &str,
    module: &str,
    callable: &str,
    python: Option<&Path>,
) -> Result<PathBuf> {
    fs::create_dir_all(bin_dir)?;
    let python_shebang = python
        .map(|path| path.display().to_string())
        .unwrap_or_else(|| "/usr/bin/env python3".to_string());
    let parts: Vec<String> = callable
        .split('.')
        .filter(|part| !part.is_empty())
        .map(ToString::to_string)
        .collect();
    let parts_repr = format!("{parts:?}");
    let contents = format!(
        "#!{python_shebang}\nimport importlib\nimport sys\n\ndef _load():\n    module = importlib.import_module({module:?})\n    target = module\n    for attr in {parts_repr}:\n        target = getattr(target, attr)\n    return target\n\nif __name__ == '__main__':\n    sys.exit(_load()())\n"
    );
    let script_path = bin_dir.join(name);
    fs::write(&script_path, contents)?;
    set_exec_permissions(&script_path);
    Ok(script_path)
}

fn materialize_wheel_scripts(
    artifact_path: &Path,
    bin_dir: &Path,
    python: Option<&Path>,
) -> Result<()> {
    fs::create_dir_all(bin_dir)?;
    if artifact_path.extension().is_some_and(|ext| ext == "dist") && artifact_path.is_dir() {
        let entry_points = fs::read_dir(artifact_path)?
            .filter_map(|entry| entry.ok())
            .map(|entry| entry.path())
            .find(|path| path.extension().is_some_and(|ext| ext == "dist-info"))
            .and_then(|dist_info| {
                let ep = dist_info.join("entry_points.txt");
                ep.exists().then_some(ep)
            });
        if let Some(ep_path) = entry_points {
            if let Ok(contents) = fs::read_to_string(&ep_path) {
                let mut section = String::new();
                for line in contents.lines() {
                    let trimmed = line.trim();
                    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with(';') {
                        continue;
                    }
                    if trimmed.starts_with('[') && trimmed.ends_with(']') {
                        section = trimmed
                            .trim_start_matches('[')
                            .trim_end_matches(']')
                            .to_string();
                        continue;
                    }
                    if section != "console_scripts" && section != "gui_scripts" {
                        continue;
                    }
                    if let Some((name, target)) = trimmed.split_once('=') {
                        let entry_name = name.trim();
                        let raw_target = target.trim();
                        let target_value = raw_target
                            .split_whitespace()
                            .next()
                            .unwrap_or(raw_target)
                            .trim();
                        if let Some((module, callable)) = target_value.split_once(':') {
                            let _ = write_entrypoint_script(
                                bin_dir,
                                entry_name,
                                module.trim(),
                                callable.trim(),
                                python,
                            );
                        }
                    }
                }
            }
        }

        let script_dirs: Vec<PathBuf> = fs::read_dir(artifact_path)?
            .filter_map(|entry| entry.ok())
            .map(|entry| entry.path())
            .filter(|path| {
                path.file_name()
                    .and_then(|name| name.to_str())
                    .map(|name| name.ends_with(".data"))
                    .unwrap_or(false)
            })
            .map(|data_dir| data_dir.join("scripts"))
            .filter(|path| path.exists())
            .collect();
        for dir in script_dirs {
            for entry in fs::read_dir(&dir)? {
                let entry = entry?;
                if entry.file_type()?.is_file() {
                    let dest = bin_dir.join(entry.file_name());
                    fs::copy(entry.path(), &dest)?;
                    set_exec_permissions(&dest);
                }
            }
        }
        return Ok(());
    }

    if artifact_path.extension().is_some_and(|ext| ext == "whl") && artifact_path.is_file() {
        let file = File::open(artifact_path)?;
        let mut archive = zip::ZipArchive::new(file)?;

        if let Some(idx) = (0..archive.len()).find(|i| {
            archive
                .by_index(*i)
                .ok()
                .map(|file| file.name().ends_with("entry_points.txt"))
                .unwrap_or(false)
        }) {
            if let Ok(mut ep_file) = archive.by_index(idx) {
                let mut contents = String::new();
                ep_file.read_to_string(&mut contents)?;
                let mut section = String::new();
                for line in contents.lines() {
                    let trimmed = line.trim();
                    if trimmed.is_empty() || trimmed.starts_with('#') || trimmed.starts_with(';') {
                        continue;
                    }
                    if trimmed.starts_with('[') && trimmed.ends_with(']') {
                        section = trimmed
                            .trim_start_matches('[')
                            .trim_end_matches(']')
                            .to_string();
                        continue;
                    }
                    if section != "console_scripts" && section != "gui_scripts" {
                        continue;
                    }
                    if let Some((name, target)) = trimmed.split_once('=') {
                        let entry_name = name.trim();
                        let raw_target = target.trim();
                        let target_value = raw_target
                            .split_whitespace()
                            .next()
                            .unwrap_or(raw_target)
                            .trim();
                        if let Some((module, callable)) = target_value.split_once(':') {
                            let _ = write_entrypoint_script(
                                bin_dir,
                                entry_name,
                                module.trim(),
                                callable.trim(),
                                python,
                            );
                        }
                    }
                }
            }
        }

        for i in 0..archive.len() {
            let mut file = archive.by_index(i)?;
            let name = file.name().to_string();
            if !name.contains(".data/scripts/") || name.ends_with('/') {
                continue;
            }
            if let Some((_, script_name)) = name.rsplit_once(".data/scripts/") {
                let dest = bin_dir.join(script_name);
                let mut contents = Vec::new();
                file.read_to_end(&mut contents)?;
                fs::write(&dest, contents)?;
                set_exec_permissions(&dest);
            }
        }
    }

    Ok(())
}

#[cfg(test)]
fn write_sitecustomize(
    site_dir: &Path,
    extra_dir: Option<&Path>,
    fs: &dyn effects::FileSystem,
) -> Result<()> {
    let path = site_dir.join("sitecustomize.py");
    fs.write(&path, SITE_CUSTOMIZE.as_bytes())?;
    if let Some(extra) = extra_dir {
        fs.create_dir_all(extra)?;
        fs.write(&extra.join("sitecustomize.py"), SITE_CUSTOMIZE.as_bytes())?;
    }
    Ok(())
}

pub(crate) fn write_python_environment_markers(
    site_dir: &Path,
    runtime: &RuntimeMetadata,
    runtime_path: &Path,
    fs: &dyn effects::FileSystem,
) -> Result<PathBuf> {
    let bin_dir = site_dir.join("bin");
    fs.create_dir_all(&bin_dir)?;

    let canonical_runtime = fs
        .canonicalize(runtime_path)
        .unwrap_or_else(|_| runtime_path.to_path_buf());
    let site_packages = site_packages_dir(site_dir, &runtime.version);
    write_python_shim(
        &bin_dir,
        &canonical_runtime,
        &site_packages,
        &BTreeMap::new(),
    )?;

    let home = canonical_runtime
        .parent()
        .and_then(|parent| parent.parent())
        .unwrap_or_else(|| canonical_runtime.parent().unwrap_or(Path::new("")));
    let pyvenv_cfg = format!(
        "home = {}\ninclude-system-site-packages = false\nversion = {}\n",
        home.display(),
        runtime.version
    );
    fs.write(&site_dir.join("pyvenv.cfg"), pyvenv_cfg.as_bytes())?;

    let primary = bin_dir.join("python");
    let mut names = vec!["python3".to_string()];
    if let Some((major, minor)) = parse_python_version(&runtime.version) {
        names.push(format!("python{major}"));
        names.push(format!("python{major}.{minor}"));
    }
    for name in names {
        let dest = bin_dir.join(&name);
        install_python_link(&primary, &dest)?;
    }
    Ok(primary)
}

fn parse_python_version(version: &str) -> Option<(String, String)> {
    let mut parts = version.split('.');
    let major = parts.next()?.to_string();
    let minor = parts.next().unwrap_or_default().to_string();
    if major.is_empty() || minor.is_empty() {
        None
    } else {
        Some((major, minor))
    }
}

pub(crate) fn site_packages_dir(site_dir: &Path, runtime_version: &str) -> PathBuf {
    if let Some((major, minor)) = parse_python_version(runtime_version) {
        site_dir
            .join("lib")
            .join(format!("python{major}.{minor}"))
            .join("site-packages")
    } else {
        site_dir.join("site-packages")
    }
}

fn install_python_link(source: &Path, dest: &Path) -> Result<()> {
    if dest.symlink_metadata().is_ok() {
        let _ = fs::remove_file(dest);
    }
    if let Some(parent) = dest.parent() {
        fs::create_dir_all(parent)?;
    }
    #[cfg(unix)]
    {
        use std::os::unix::fs::symlink;
        if symlink(source, dest).is_ok() {
            return Ok(());
        }
    }
    fs::copy(source, dest).with_context(|| {
        format!(
            "failed to link python from {} to {}",
            source.display(),
            dest.display()
        )
    })?;
    set_exec_permissions(dest);
    Ok(())
}

pub(crate) fn select_python_from_site(
    site_bin: &Option<PathBuf>,
    runtime_path: &str,
    runtime_version: &str,
) -> String {
    if let Some(bin) = site_bin {
        let mut candidates = vec![bin.join("python"), bin.join("python3")];
        if let Some((major, minor)) = parse_python_version(runtime_version) {
            candidates.push(bin.join(format!("python{major}")));
            candidates.push(bin.join(format!("python{major}.{minor}")));
        }
        if let Some(found) = candidates.into_iter().find(|path| path.exists()) {
            return found.display().to_string();
        }
    }
    runtime_path.to_string()
}

fn persist_project_state(
    filesystem: &dyn effects::FileSystem,
    project_root: &Path,
    env: StoredEnvironment,
    runtime: StoredRuntime,
) -> Result<()> {
    let mut state = load_project_state(filesystem, project_root)?;
    state.current_env = Some(env);
    state.runtime = Some(runtime);
    write_project_state(filesystem, project_root, &state)
}

pub(crate) fn load_project_state(
    filesystem: &dyn effects::FileSystem,
    project_root: &Path,
) -> Result<ProjectState> {
    let path = project_root.join(".px").join("state.json");
    match filesystem.read_to_string(&path) {
        Ok(contents) => {
            let state: ProjectState = serde_json::from_str(&contents)
                .with_context(|| format!("failed to parse {}", path.display()))?;
            validate_project_state(&state)?;
            Ok(state)
        }
        Err(err) => {
            if filesystem.metadata(&path).is_ok() {
                Err(err)
            } else {
                Ok(ProjectState::default())
            }
        }
    }
}

fn write_project_state(
    filesystem: &dyn effects::FileSystem,
    project_root: &Path,
    state: &ProjectState,
) -> Result<()> {
    let path = project_root.join(".px").join("state.json");
    let mut contents = serde_json::to_vec_pretty(state)?;
    contents.push(b'\n');
    if let Some(dir) = path.parent() {
        filesystem.create_dir_all(dir)?;
    }
    let tmp_path = path.with_extension("json.tmp");
    filesystem.write(&tmp_path, &contents)?;
    std::fs::rename(&tmp_path, &path).with_context(|| format!("writing {}", path.display()))?;
    Ok(())
}

fn validate_project_state(state: &ProjectState) -> Result<()> {
    if let Some(env) = &state.current_env {
        if env.id.trim().is_empty() || env.lock_id.trim().is_empty() {
            bail!("invalid project state: missing environment identity");
        }
        let has_site = !env.site_packages.trim().is_empty()
            || env
                .env_path
                .as_ref()
                .is_some_and(|path| !path.trim().is_empty());
        if !has_site {
            bail!("invalid project state: missing site-packages path");
        }
        if env.python.path.trim().is_empty() || env.python.version.trim().is_empty() {
            bail!("invalid project state: missing python metadata");
        }
    }
    if let Some(runtime) = &state.runtime {
        if runtime.path.trim().is_empty()
            || runtime.version.trim().is_empty()
            || runtime.platform.trim().is_empty()
        {
            bail!("invalid project runtime metadata");
        }
    }
    Ok(())
}

fn resolve_project_site(
    filesystem: &dyn effects::FileSystem,
    project_root: &Path,
) -> Result<PathBuf> {
    let state = load_project_state(filesystem, project_root)?;
    let env = state.current_env.ok_or_else(|| {
        InstallUserError::new(
            "project environment missing",
            json!({
                "project_root": project_root.display().to_string(),
                "reason": "missing_env",
                "hint": "run `px sync` to rebuild the environment",
            }),
        )
    })?;
    let env_root = env.env_path.ok_or_else(|| {
        InstallUserError::new(
            "project environment missing",
            json!({
                "project_root": project_root.display().to_string(),
                "reason": "missing_env",
                "hint": "run `px sync` to rebuild the environment",
            }),
        )
    })?;
    let root = PathBuf::from(env_root);
    if !root.exists() {
        return Err(InstallUserError::new(
            "project environment missing",
            json!({
                "project_root": project_root.display().to_string(),
                "env_path": root.display().to_string(),
                "reason": "missing_env",
                "hint": "run `px sync` to rebuild the environment",
            }),
        )
        .into());
    }
    Ok(root)
}

#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub(crate) struct ProjectState {
    #[serde(default)]
    pub(crate) current_env: Option<StoredEnvironment>,
    #[serde(default)]
    pub(crate) runtime: Option<StoredRuntime>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub(crate) struct StoredEnvironment {
    pub(crate) id: String,
    #[serde(alias = "lock_hash")]
    pub(crate) lock_id: String,
    pub(crate) platform: String,
    pub(crate) site_packages: String,
    #[serde(default)]
    pub(crate) env_path: Option<String>,
    #[serde(default)]
    pub(crate) profile_oid: Option<String>,
    pub(crate) python: StoredPython,
}

#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub(crate) struct StoredRuntime {
    pub(crate) path: String,
    pub(crate) version: String,
    pub(crate) platform: String,
}
#[derive(Debug, Clone, Serialize, Deserialize)]
pub(crate) struct StoredPython {
    pub(crate) path: String,
    pub(crate) version: String,
}

#[derive(Clone, Debug)]
pub(crate) struct RuntimeMetadata {
    pub(crate) path: String,
    pub(crate) version: String,
    pub(crate) platform: String,
}

pub(crate) fn prepare_project_runtime(
    snapshot: &ManifestSnapshot,
) -> Result<runtime_manager::RuntimeSelection> {
    if let Ok(explicit) = env::var("PX_RUNTIME_PYTHON") {
        if let Ok(details) = runtime_manager::inspect_python(Path::new(&explicit)) {
            let requirement = snapshot
                .python_override
                .as_deref()
                .unwrap_or(&snapshot.python_requirement);
            if let (Ok(specs), Ok(version)) = (
                pep440_rs::VersionSpecifiers::from_str(requirement),
                pep440_rs::Version::from_str(&details.full_version),
            ) {
                if specs.contains(&version) {
                    let channel = runtime_manager::format_channel(&details.full_version)
                        .unwrap_or_else(|_| requirement.to_string());
                    let record = runtime_manager::RuntimeRecord {
                        version: channel,
                        full_version: details.full_version,
                        path: details.executable,
                        default: false,
                    };
                    let selection = runtime_manager::RuntimeSelection {
                        record,
                        source: runtime_manager::RuntimeSource::Explicit,
                    };
                    env::set_var("PX_RUNTIME_PYTHON", &selection.record.path);
                    return Ok(selection);
                }
            }
        }
    }

    let selection = runtime_manager::resolve_runtime(
        snapshot.python_override.as_deref(),
        &snapshot.python_requirement,
    )
    .map_err(|err| {
        InstallUserError::new(
            "python runtime unavailable",
            json!({
                "hint": err.to_string(),
                "reason": "missing_runtime",
            }),
        )
    })?;
    env::set_var("PX_RUNTIME_PYTHON", &selection.record.path);
    Ok(selection)
}

pub(crate) fn detect_runtime_metadata(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
) -> Result<RuntimeMetadata> {
    let path = ctx.python_runtime().detect_interpreter()?;
    let version = probe_python_version(ctx, snapshot, &path)?;
    let tags = detect_interpreter_tags(&path)?;
    let platform = tags
        .platform
        .first()
        .cloned()
        .unwrap_or_else(|| "any".to_string());
    Ok(RuntimeMetadata {
        path,
        version,
        platform,
    })
}

pub(crate) fn compute_lock_hash(lock_path: &Path) -> Result<String> {
    let contents = fs::read(lock_path)?;
    Ok(compute_lock_hash_bytes(&contents))
}

pub(crate) fn compute_lock_hash_bytes(contents: &[u8]) -> String {
    let mut hasher = Sha256::new();
    hasher.update(contents);
    format!("{:x}", hasher.finalize())
}

fn probe_python_version(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
    python: &str,
) -> Result<String> {
    const SCRIPT: &str =
        "import json, platform; print(json.dumps({'version': platform.python_version()}))";
    let args = vec!["-c".to_string(), SCRIPT.to_string()];
    let output = ctx
        .python_runtime()
        .run_command(python, &args, &[], &snapshot.root)?;
    if output.code != 0 {
        return Err(anyhow!("python exited with {}", output.code));
    }
    let payload: RuntimeProbe =
        serde_json::from_str(output.stdout.trim()).context("invalid runtime probe payload")?;
    Ok(payload.version)
}

#[derive(Deserialize)]
struct RuntimeProbe {
    version: String,
}

fn verify_lock(snapshot: &ManifestSnapshot) -> Result<InstallOutcome> {
    let lockfile = snapshot.lock_path.display().to_string();
    let marker_env = marker_env_for_snapshot(snapshot);
    match load_lockfile_optional(&snapshot.lock_path)? {
        Some(lock) => {
            let report = analyze_lock_diff(snapshot, &lock, marker_env.as_ref());
            let mut drift = report.to_messages();
            if drift.is_empty() {
                drift = verify_locked_artifacts(&lock);
            }
            if drift.is_empty() {
                Ok(InstallOutcome {
                    state: InstallState::UpToDate,
                    lockfile,
                    drift,
                    verified: true,
                })
            } else {
                Ok(InstallOutcome {
                    state: InstallState::Drift,
                    lockfile,
                    drift,
                    verified: true,
                })
            }
        }
        None => Ok(InstallOutcome {
            state: InstallState::MissingLock,
            lockfile,
            drift: Vec::new(),
            verified: true,
        }),
    }
}

pub(crate) struct ResolvedSpecOutput {
    pub(crate) specs: Vec<String>,
    pub(crate) pins: Vec<PinSpec>,
}

fn resolve_dependencies(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
) -> Result<ResolvedSpecOutput> {
    resolve_dependencies_with_effects(ctx.effects(), snapshot, true)
}

pub(crate) fn resolve_dependencies_with_effects(
    effects: &dyn Effects,
    snapshot: &ManifestSnapshot,
    show_progress: bool,
) -> Result<ResolvedSpecOutput> {
    let spinner = show_progress.then(|| ProgressReporter::spinner("Resolving dependencies"));
    let python = effects.python().detect_interpreter()?;
    let tags = detect_interpreter_tags(&python)?;
    let resolver_env = detect_marker_environment(&python)?;
    let marker_env = resolver_env
        .to_marker_environment()
        .map_err(|err| anyhow!("invalid marker environment: {err}"))?;
    let cache_dir = effects.cache().resolve_store_path()?.path;
    let requirements: Vec<String> = snapshot
        .requirements
        .iter()
        .filter(|spec| marker_applies(spec, &marker_env))
        .cloned()
        .collect();
    tracing::debug!(?requirements, "resolver_requirements");
    let request = ResolverRequest {
        project: snapshot.name.clone(),
        requirements,
        tags: ResolverTags {
            python: tags.python.clone(),
            abi: tags.abi.clone(),
            platform: tags.platform.clone(),
        },
        env: resolver_env.clone(),
        indexes: resolver_indexes(),
        cache_dir,
        python: python.clone(),
    };
    let resolved = resolve(&request).map_err(|err| {
        InstallUserError::new(
            "dependency resolution failed",
            resolver_failure_details(&err),
        )
    })?;
    let mut pins = Vec::new();
    let mut autopin_lookup = HashMap::new();
    let mut seen = HashSet::new();
    for spec in resolved {
        let formatted = format_specifier(
            &spec.normalized,
            &spec.extras,
            &spec.selected_version,
            spec.marker.as_deref(),
        );
        let pin = PinSpec {
            name: spec.name,
            specifier: formatted.clone(),
            version: spec.selected_version,
            normalized: spec.normalized,
            extras: spec.extras,
            marker: spec.marker,
            direct: spec.direct,
            requires: spec.requires,
        };
        autopin_lookup.insert(autopin_pin_key(&pin), formatted);
        if seen.insert(pin.normalized.clone()) {
            pins.push(pin);
        }
    }

    let mut autopin_specs = Vec::new();
    for spec in &snapshot.dependencies {
        if spec_requires_pin(spec) && marker_applies(spec, &marker_env) {
            let key = autopin_spec_key(spec);
            if let Some(pinned) = autopin_lookup.get(&key) {
                autopin_specs.push(pinned.clone());
            } else {
                autopin_specs.push(spec.clone());
            }
        }
    }
    if let Some(spinner) = spinner {
        spinner.finish(format!("Resolved {} dependencies", pins.len()));
    }
    Ok(ResolvedSpecOutput {
        specs: autopin_specs,
        pins,
    })
}

fn resolver_indexes() -> Vec<String> {
    let mut indexes = Vec::new();
    if let Ok(primary) = env::var("PX_INDEX_URL")
        .or_else(|_| env::var("PIP_INDEX_URL"))
        .map(|value| value.trim().to_string())
    {
        if !primary.is_empty() {
            indexes.push(normalize_index_url(&primary));
        }
    }
    if let Ok(extra) = env::var("PIP_EXTRA_INDEX_URL") {
        for entry in extra.split_whitespace() {
            let trimmed = entry.trim();
            if !trimmed.is_empty() {
                indexes.push(normalize_index_url(trimmed));
            }
        }
    }
    if indexes.is_empty() {
        indexes.push("https://pypi.org/simple".to_string());
    }
    indexes
}

fn normalize_index_url(raw: &str) -> String {
    let mut url = raw.trim_end_matches('/').to_string();
    if url.ends_with("/simple") {
        return url;
    }
    if let Some(stripped) = url.strip_suffix("/pypi") {
        url = stripped.to_string();
    } else if let Some(stripped) = url.strip_suffix("/json") {
        url = stripped.to_string();
    }
    url.push_str("/simple");
    url
}

fn resolver_failure_details(err: &anyhow::Error) -> Value {
    let message = err.to_string();
    let mut issues = vec![message.clone()];
    issues.extend(err.chain().skip(1).map(std::string::ToString::to_string));
    let details = json!({
        "reason": "resolve_failed",
        "issues": issues,
        "hint": "Inspect dependency constraints and rerun `px sync`.",
        "code": diag_commands::SYNC,
    });
    if let Some(req) = extract_quoted_requirement(&message) {
        if message.contains("unable to resolve") {
            return json!({
                "reason": "resolve_no_match",
                "issues": issues,
                "requirement": req,
                "hint": format!("Relax or remove `{}` in pyproject.toml, then rerun `px sync`.", req),
                "code": diag_commands::SYNC,
            });
        }
        if message.contains("failed to parse requirement")
            || message.contains("failed to parse specifiers")
        {
            return json!({
                "reason": "invalid_requirement",
                "issues": issues,
                "requirement": req,
                "hint": format!("Fix `{}` to a valid PEP 508 requirement, then rerun `px sync`.", req),
                "code": diag_commands::SYNC,
            });
        }
    }
    if message.contains("failed to query PyPI") || message.contains("PyPI error") {
        return json!({
            "reason": "pypi_unreachable",
            "issues": issues,
            "hint": "Check your network connection (PX_ONLINE=1) and rerun `px sync`.",
            "code": diag_commands::SYNC,
        });
    }
    details
}

fn extract_quoted_requirement(message: &str) -> Option<String> {
    let start = message.find('`')?;
    let rest = &message[start + 1..];
    let end = rest.find('`')?;
    Some(rest[..end].to_string())
}

pub(crate) fn persist_resolved_dependencies(
    snapshot: &ManifestSnapshot,
    specs: &[String],
) -> Result<()> {
    let contents = fs::read_to_string(&snapshot.manifest_path)?;
    let mut doc: DocumentMut = contents.parse()?;
    write_dependencies(&mut doc, specs)?;
    fs::write(&snapshot.manifest_path, doc.to_string())?;
    Ok(())
}

pub(crate) fn summarize_autopins(entries: &[AutopinEntry]) -> Option<String> {
    if entries.is_empty() {
        return None;
    }
    let mut labels = Vec::new();
    for entry in entries.iter().take(3) {
        labels.push(entry.short_label());
    }
    let mut summary = format!(
        "Pinned {} package{} automatically",
        entries.len(),
        if entries.len() == 1 { "" } else { "s" }
    );
    if !labels.is_empty() {
        summary.push_str(" (");
        summary.push_str(&labels.join(", "));
        if entries.len() > 3 {
            let _ = write!(&mut summary, ", +{} more", entries.len() - 3);
        }
        summary.push(')');
    }
    Some(summary)
}

fn write_dependencies(doc: &mut DocumentMut, specs: &[String]) -> Result<()> {
    let table = project_table_mut(doc)?;
    let mut array = Array::new();
    for spec in specs {
        array.push_formatted(TomlValue::from(spec.clone()));
    }
    table.insert("dependencies", Item::Value(TomlValue::Array(array)));
    Ok(())
}

pub(crate) fn project_table(doc: &DocumentMut) -> Result<&Table> {
    doc.get("project")
        .and_then(Item::as_table)
        .ok_or_else(|| anyhow!("[project] must be a table"))
}

fn project_table_mut(doc: &mut DocumentMut) -> Result<&mut Table> {
    doc.entry("project")
        .or_insert(Item::Table(Table::new()))
        .as_table_mut()
        .ok_or_else(|| anyhow!("[project] must be a table"))
}

pub(crate) fn outcome_from_output(
    command_name: &str,
    target: &str,
    output: &RunOutput,
    prefix: &str,
    extra: Option<Value>,
) -> ExecutionOutcome {
    let mut extra_details = extra;
    let context = TracebackContext::new(command_name, target, extra_details.as_ref());
    let mut details = json!({
        "stdout": output.stdout.clone(),
        "stderr": output.stderr.clone(),
        "code": output.code,
        "target": target,
    });

    if let Some(extra_value) = extra_details.take() {
        if let Value::Object(map) = extra_value {
            if let Some(details_map) = details.as_object_mut() {
                for (key, value) in map {
                    details_map.insert(key, value);
                }
            }
        } else {
            details["extra"] = extra_value;
        }
    }

    let mut has_traceback = false;
    if output.code != 0 {
        if let Some(report) = analyze_python_traceback(&output.stderr, &context) {
            has_traceback = true;
            let recommendation = report.recommendation.clone();
            let trace_value = serde_json::to_value(&report).expect("traceback serialization");
            if let Some(map) = details.as_object_mut() {
                map.insert("traceback".to_string(), trace_value);
            }
            if let Some(rec) = recommendation {
                let hint_text = rec.hint.clone();
                let rec_value = serde_json::to_value(&rec).expect("traceback recommendation");
                if let Some(map) = details.as_object_mut() {
                    map.insert("recommendation".to_string(), rec_value);
                    if !map.contains_key("hint") {
                        map.insert("hint".to_string(), Value::String(hint_text));
                    }
                }
            }
        }
    }

    if output.code == 0 {
        let stdout = output.stdout.trim_end();
        if !stdout.is_empty() {
            details["passthrough"] = Value::Bool(true);
            return ExecutionOutcome::success(stdout.to_string(), details);
        }
        let stderr = output.stderr.trim_end();
        if !stderr.is_empty() {
            details["passthrough"] = Value::Bool(true);
            return ExecutionOutcome::success(stderr.to_string(), details);
        }
        let message = format!("{prefix} {command_name}({target}) succeeded");
        ExecutionOutcome::success(message, details)
    } else {
        let trimmed_stderr = output.stderr.trim();
        let message = if trimmed_stderr.is_empty() || has_traceback {
            format!(
                "{prefix} {command_name}({target}) exited with {}",
                output.code
            )
        } else {
            details["passthrough"] = Value::Bool(true);
            output.stderr.trim_end().to_string()
        };
        ExecutionOutcome::failure(message, details)
    }
}

pub(crate) struct PythonContext {
    pub(crate) project_root: PathBuf,
    pub(crate) project_name: String,
    pub(crate) python: String,
    pub(crate) pythonpath: String,
    pub(crate) allowed_paths: Vec<PathBuf>,
    pub(crate) site_bin: Option<PathBuf>,
    pub(crate) pep582_bin: Vec<PathBuf>,
    pub(crate) px_options: PxOptions,
}

#[derive(Clone, Copy, Debug)]
pub(crate) enum EnvGuard {
    Strict,
    AutoSync,
}

#[derive(Clone, Debug)]
pub(crate) struct EnvironmentSyncReport {
    action: &'static str,
    note: String,
}

impl EnvironmentSyncReport {
    pub(crate) fn new(issue: EnvironmentIssue) -> Self {
        Self {
            action: issue.action_key(),
            note: issue.note().to_string(),
        }
    }

    pub(crate) fn action(&self) -> &str {
        self.action
    }

    fn to_json(&self) -> Value {
        json!({
            "action": self.action,
            "note": self.note,
        })
    }
}

#[derive(Clone, Copy, Debug)]
pub(crate) enum EnvironmentIssue {
    MissingLock,
    LockDrift,
    MissingArtifacts,
    MissingEnv,
    EnvOutdated,
    RuntimeMismatch,
}

impl EnvironmentIssue {
    fn from_details(details: &Value) -> Option<Self> {
        let reason = details
            .as_object()
            .and_then(|map| map.get("reason"))
            .and_then(Value::as_str)?;
        match reason {
            "missing_lock" => Some(EnvironmentIssue::MissingLock),
            "lock_drift" => Some(EnvironmentIssue::LockDrift),
            "missing_artifacts" => Some(EnvironmentIssue::MissingArtifacts),
            "missing_env" => Some(EnvironmentIssue::MissingEnv),
            "env_outdated" => Some(EnvironmentIssue::EnvOutdated),
            "runtime_mismatch" => Some(EnvironmentIssue::RuntimeMismatch),
            _ => None,
        }
    }

    fn note(self) -> &'static str {
        self.lock_message().unwrap_or_else(|| self.env_message())
    }

    fn lock_message(self) -> Option<&'static str> {
        match self {
            EnvironmentIssue::MissingLock => Some("Updating px.lock (missing lock)"),
            EnvironmentIssue::LockDrift => Some("Updating px.lock (manifest changed)"),
            _ => None,
        }
    }

    fn env_message(self) -> &'static str {
        match self {
            EnvironmentIssue::MissingLock | EnvironmentIssue::LockDrift => "Syncing environment",
            EnvironmentIssue::MissingArtifacts => "Syncing environment (rehydrating cache)",
            EnvironmentIssue::MissingEnv => "Syncing environment",
            EnvironmentIssue::EnvOutdated => "Syncing environment",
            EnvironmentIssue::RuntimeMismatch => "Syncing environment (runtime changed)",
        }
    }

    fn needs_lock_resolution(self) -> bool {
        self.lock_message().is_some()
    }

    fn action_key(self) -> &'static str {
        match self {
            EnvironmentIssue::MissingLock => "lock-bootstrap",
            EnvironmentIssue::LockDrift => "lock-sync",
            EnvironmentIssue::MissingArtifacts => "env-rehydrate",
            EnvironmentIssue::MissingEnv => "env-recreate",
            EnvironmentIssue::EnvOutdated => "env-refresh",
            EnvironmentIssue::RuntimeMismatch => "env-runtime",
        }
    }

    fn auto_fixable(self) -> bool {
        matches!(
            self,
            EnvironmentIssue::MissingLock
                | EnvironmentIssue::LockDrift
                | EnvironmentIssue::MissingArtifacts
                | EnvironmentIssue::MissingEnv
                | EnvironmentIssue::EnvOutdated
                | EnvironmentIssue::RuntimeMismatch
        )
    }
}
#[allow(dead_code)]
pub(crate) fn issue_from_details(details: &Value) -> Option<EnvironmentIssue> {
    EnvironmentIssue::from_details(details)
}

impl PythonContext {
    fn new_with_guard(
        ctx: &CommandContext,
        guard: EnvGuard,
    ) -> Result<(Self, Option<EnvironmentSyncReport>)> {
        let project_root = ctx.project_root()?;
        let manifest_path = project_root.join("pyproject.toml");
        if !manifest_path.exists() {
            return Err(InstallUserError::new(
                format!("pyproject.toml not found in {}", project_root.display()),
                json!({
                    "pyproject": manifest_path.display().to_string(),
                    "hint": "run `px migrate --apply` or create pyproject.toml first",
                    "reason": "missing_manifest",
                }),
            )
            .into());
        }
        ensure_version_file(&manifest_path)?;
        let snapshot = manifest_snapshot_at(&project_root)?;
        let runtime = prepare_project_runtime(&snapshot)?;
        let sync_report = ensure_environment_with_guard(ctx, &snapshot, guard)?;
        let paths = build_pythonpath(ctx.fs(), &project_root, None)?;
        let python = select_python_from_site(
            &paths.site_bin,
            &runtime.record.path,
            &runtime.record.full_version,
        );
        Ok((
            Self {
                project_root,
                project_name: snapshot.name.clone(),
                python,
                pythonpath: paths.pythonpath,
                allowed_paths: paths.allowed_paths,
                site_bin: paths.site_bin,
                pep582_bin: paths.pep582_bin,
                px_options: snapshot.px_options.clone(),
            },
            sync_report,
        ))
    }

    pub(crate) fn base_env(&self, command_args: &Value) -> Result<Vec<(String, String)>> {
        let allowed =
            env::join_paths(&self.allowed_paths).context("allowed path contains invalid UTF-8")?;
        let allowed = allowed
            .into_string()
            .map_err(|_| anyhow!("allowed path contains non-utf8 data"))?;
        let mut python_paths: Vec<_> = env::split_paths(&allowed).collect();
        if !self.pythonpath.is_empty() {
            python_paths.extend(env::split_paths(&self.pythonpath));
        }
        let pythonpath = env::join_paths(&python_paths)
            .context("failed to assemble PYTHONPATH")?
            .into_string()
            .map_err(|_| anyhow!("pythonpath contains non-utf8 data"))?;
        let mut envs = vec![
            ("PYTHONPATH".into(), pythonpath),
            ("PYTHONUNBUFFERED".into(), "1".into()),
            ("PYTHONDONTWRITEBYTECODE".into(), "1".into()),
            ("PYTHONSAFEPATH".into(), "1".into()),
        ];
        envs.push(("PX_ALLOWED_PATHS".into(), allowed));
        envs.push((
            "PX_PROJECT_ROOT".into(),
            self.project_root.display().to_string(),
        ));
        envs.push(("PX_PYTHON".into(), self.python.clone()));
        envs.push(("PX_COMMAND_JSON".into(), command_args.to_string()));
        if let Ok(debug_site) = env::var("PX_DEBUG_SITE_PATHS") {
            envs.push(("PX_DEBUG_SITE_PATHS".into(), debug_site));
        }
        if let Some(alias) = self.px_options.manage_command.as_ref() {
            let trimmed = alias.trim();
            if !trimmed.is_empty() {
                envs.push(("PYAPP_COMMAND_NAME".into(), trimmed.to_string()));
            }
        }
        if let Some(bin) = &self.site_bin {
            if let Some(site_dir) = bin.parent() {
                let virtual_env = site_dir
                    .canonicalize()
                    .unwrap_or_else(|_| site_dir.to_path_buf());
                envs.push(("VIRTUAL_ENV".into(), virtual_env.display().to_string()));
            }
        }
        let mut path_entries = Vec::new();
        if let Some(bin) = &self.site_bin {
            path_entries.push(bin.clone());
        }
        path_entries.extend(self.pep582_bin.iter().cloned());
        if let Some(python_dir) = Path::new(&self.python).parent() {
            path_entries.push(python_dir.to_path_buf());
        }
        if let Ok(existing) = env::var("PATH") {
            path_entries.extend(env::split_paths(&existing));
        }
        let mut unique = Vec::new();
        let mut seen = std::collections::HashSet::new();
        for entry in path_entries.into_iter().filter(|p| p.exists()) {
            if seen.insert(entry.clone()) {
                unique.push(entry);
            }
        }
        if !unique.is_empty() {
            if let Ok(joined) = env::join_paths(&unique) {
                if let Ok(value) = joined.into_string() {
                    envs.push(("PATH".into(), value));
                }
            }
        }
        disable_proxy_env(&mut envs);
        Ok(envs)
    }
}

pub(crate) fn ensure_version_file(manifest_path: &Path) -> Result<()> {
    let contents = fs::read_to_string(manifest_path)?;
    let doc: toml_edit::DocumentMut = contents.parse()?;
    let manifest_dir = manifest_path
        .parent()
        .unwrap_or_else(|| Path::new("."))
        .to_path_buf();

    let hatch_describe = hatch_git_describe_command(&doc);
    let hatch_simplified_semver = hatch_prefers_simplified_semver(&doc);
    let hatch_drop_local = hatch_drops_local_version(&doc);
    if let Some(version_file) = hatch_version_file(&doc) {
        ensure_version_stub(
            &manifest_dir,
            &version_file,
            VersionFileStyle::HatchVcsHook,
            VersionDeriveOptions {
                git_describe_command: hatch_describe.as_deref(),
                simplified_semver: hatch_simplified_semver,
                drop_local: hatch_drop_local,
            },
        )?;
    }

    if let Some(version_file) = setuptools_scm_version_file(&doc) {
        ensure_version_stub(
            &manifest_dir,
            &version_file,
            VersionFileStyle::SetuptoolsScm,
            VersionDeriveOptions::default(),
        )?;
    }

    if let Some(version_file) = pdm_version_file(&doc) {
        ensure_version_stub(
            &manifest_dir,
            &version_file,
            VersionFileStyle::Plain,
            VersionDeriveOptions::default(),
        )?;
    }

    ensure_inline_version_module(&manifest_dir, &doc)?;

    Ok(())
}

fn uses_hatch_vcs(doc: &toml_edit::DocumentMut) -> bool {
    doc.get("tool")
        .and_then(|tool| tool.get("hatch"))
        .and_then(|hatch| hatch.get("version"))
        .and_then(|version| version.get("source"))
        .and_then(|value| value.as_str())
        .map(|value| value.eq_ignore_ascii_case("vcs"))
        .unwrap_or(false)
}

fn hatch_version_file(doc: &toml_edit::DocumentMut) -> Option<PathBuf> {
    doc.get("tool")
        .and_then(|tool| tool.get("hatch"))
        .and_then(|hatch| hatch.get("build"))
        .and_then(|build| build.get("hooks"))
        .and_then(|hooks| hooks.get("vcs"))
        .and_then(|vcs| vcs.get("version-file"))
        .and_then(|item| item.as_str())
        .map(PathBuf::from)
}

fn hatch_git_describe_command(doc: &toml_edit::DocumentMut) -> Option<Vec<String>> {
    doc.get("tool")
        .and_then(|tool| tool.get("hatch"))
        .and_then(|hatch| hatch.get("version"))
        .and_then(|version| version.get("raw-options"))
        .and_then(|raw| raw.get("git_describe_command"))
        .and_then(string_vec_from_item)
}

fn hatch_prefers_simplified_semver(doc: &toml_edit::DocumentMut) -> bool {
    hatch_version_raw_option(doc, "version_scheme")
        .map(|value| value == "python-simplified-semver")
        .unwrap_or(false)
}

fn hatch_drops_local_version(doc: &toml_edit::DocumentMut) -> bool {
    hatch_version_raw_option(doc, "local_scheme")
        .map(|value| value == "no-local-version")
        .unwrap_or(false)
}

fn hatch_version_raw_option(doc: &toml_edit::DocumentMut, key: &str) -> Option<String> {
    doc.get("tool")
        .and_then(|tool| tool.get("hatch"))
        .and_then(|hatch| hatch.get("version"))
        .and_then(|version| version.get("raw-options"))
        .and_then(|raw| raw.get(key))
        .and_then(|item| item.as_str())
        .map(str::to_string)
}

fn string_vec_from_item(item: &Item) -> Option<Vec<String>> {
    match item {
        Item::Value(TomlValue::Array(items)) => {
            let mut values = Vec::new();
            for entry in items.iter() {
                let value = entry.as_str()?.to_string();
                values.push(value);
            }
            if values.is_empty() {
                None
            } else {
                Some(values)
            }
        }
        Item::Value(TomlValue::String(value)) => {
            let values: Vec<String> = value
                .value()
                .split_whitespace()
                .map(|entry| entry.to_string())
                .collect();
            if values.is_empty() {
                None
            } else {
                Some(values)
            }
        }
        _ => None,
    }
}

fn setuptools_scm_version_file(doc: &toml_edit::DocumentMut) -> Option<PathBuf> {
    doc.get("tool")
        .and_then(|tool| tool.get("setuptools_scm"))
        .and_then(|cfg| cfg.get("write_to").or_else(|| cfg.get("version_file")))
        .and_then(|item| item.as_str())
        .map(PathBuf::from)
}

fn pdm_version_file(doc: &toml_edit::DocumentMut) -> Option<PathBuf> {
    doc.get("tool")
        .and_then(|tool| tool.get("pdm"))
        .and_then(|pdm| pdm.get("version"))
        .and_then(|version| version.get("write_to"))
        .and_then(|item| item.as_str())
        .map(PathBuf::from)
}

fn ensure_inline_version_module(manifest_dir: &Path, doc: &toml_edit::DocumentMut) -> Result<()> {
    let Some(project) = doc.get("project").and_then(Item::as_table) else {
        return Ok(());
    };
    if project
        .get("dynamic")
        .and_then(Item::as_array)
        .is_some_and(|items| {
            items
                .iter()
                .any(|item| item.as_str().is_some_and(|value| value == "version"))
        })
    {
        return Ok(());
    }

    let Some(name) = project.get("name").and_then(Item::as_str) else {
        return Ok(());
    };
    let Some(version) = project.get("version").and_then(Item::as_str) else {
        return Ok(());
    };

    let module = name.replace(['-', '.'], "_").to_lowercase();
    let candidates = [
        manifest_dir.join("src").join(&module),
        manifest_dir.join("python").join(&module),
        manifest_dir.join(&module),
    ];
    let Some(package_dir) = candidates.iter().find(|path| path.exists()) else {
        return Ok(());
    };
    let version_pyi = package_dir.join("version.pyi");
    if !version_pyi.exists() {
        return Ok(());
    }
    let version_py = package_dir.join("version.py");

    let (version_value, git_revision) = inline_version_values(manifest_dir, version);
    let release_flag = if !version_value.contains("dev") && !version_value.contains('+') {
        "True"
    } else {
        "False"
    };
    let contents = format!(
        "\"\"\"\nModule to expose more detailed version info for the installed `{name}`\n\"\"\"\n\
version = \"{version_value}\"\n\
__version__ = version\n\
full_version = version\n\n\
git_revision = \"{git_revision}\"\n\
release = {release_flag}\n\
short_version = version.split(\"+\")[0]\n"
    );

    if let Some(parent) = version_py.parent() {
        fs::create_dir_all(parent)?;
    }
    if version_py.exists() {
        if let Ok(current) = fs::read_to_string(&version_py) {
            if current == contents {
                return Ok(());
            }
        }
    }
    fs::write(&version_py, contents)?;
    Ok(())
}

fn inline_version_values(manifest_dir: &Path, version: &str) -> (String, String) {
    let mut version_value = version.to_string();
    let mut git_revision = String::new();

    if let Some((hash, date)) = latest_git_commit(manifest_dir) {
        git_revision = hash.clone();
        if version_value.contains("dev") && !date.is_empty() {
            let short = hash.chars().take(7).collect::<String>();
            if !short.is_empty() {
                version_value = format!("{version_value}+git{date}.{short}");
            }
        }
    }

    (version_value, git_revision)
}

fn latest_git_commit(manifest_dir: &Path) -> Option<(String, String)> {
    let output = Command::new("git")
        .args([
            "-c",
            "log.showSignature=false",
            "log",
            "-1",
            "--format=\"%H %aI\"",
        ])
        .current_dir(manifest_dir)
        .output()
        .ok()?;
    if !output.status.success() {
        return None;
    }

    let stdout = String::from_utf8_lossy(&output.stdout);
    let mut parts = stdout.trim().trim_matches('"').split_whitespace();
    let hash = parts.next().unwrap_or_default();
    if hash.is_empty() {
        return None;
    }
    let timestamp = parts.next().unwrap_or_default();
    let date = timestamp
        .split('T')
        .next()
        .unwrap_or_default()
        .replace('-', "");
    Some((hash.to_string(), date))
}

#[derive(Clone, Copy)]
enum VersionFileStyle {
    HatchVcsHook,
    SetuptoolsScm,
    Plain,
}

#[derive(Default)]
struct VersionDeriveOptions<'a> {
    git_describe_command: Option<&'a [String]>,
    simplified_semver: bool,
    drop_local: bool,
}

fn ensure_version_stub(
    root: &Path,
    target: &Path,
    style: VersionFileStyle,
    derive_opts: VersionDeriveOptions<'_>,
) -> Result<()> {
    let version_path = root.join(target);
    let mut rewrite = false;
    if version_path.exists() {
        match style {
            VersionFileStyle::HatchVcsHook => {
                if let Ok(contents) = fs::read_to_string(&version_path) {
                    let has_version = contents.contains("version =");
                    let has_alias = contents.contains("__version__");
                    let fallback_version = contents.lines().find_map(|line| {
                        let trimmed = line.trim_start();
                        if !trimmed.starts_with("version =") {
                            return None;
                        }
                        let value = trimmed
                            .split_once('=')
                            .map(|(_, rhs)| rhs.trim().trim_matches('"'))
                            .unwrap_or_default();
                        Some(
                            value == "unknown"
                                || value.starts_with("0.0.0+")
                                || value.starts_with("0+"),
                        )
                    });
                    let needs_upgrade = fallback_version.unwrap_or(false);
                    if !(has_version && has_alias) || needs_upgrade {
                        rewrite = true;
                    }
                } else {
                    rewrite = true;
                }
            }
            VersionFileStyle::SetuptoolsScm => {
                if let Ok(contents) = fs::read_to_string(&version_path) {
                    let has_version = contents.contains("version =");
                    let has_alias = contents.contains("__version__");
                    let has_tuple = contents.contains("version_tuple = tuple(_v.release)");
                    let has_packaging =
                        contents.contains("from packaging.version import Version as _Version");
                    let fallback_version = contents.lines().find_map(|line| {
                        let trimmed = line.trim_start();
                        if !trimmed.starts_with("version =") {
                            return None;
                        }
                        let value = trimmed
                            .split_once('=')
                            .map(|(_, rhs)| rhs.trim().trim_matches('"'))
                            .unwrap_or_default();
                        Some(
                            value == "unknown"
                                || value.starts_with("0.0.0+")
                                || value.starts_with("0+"),
                        )
                    });
                    let needs_upgrade = fallback_version.unwrap_or(false);
                    if !(has_version && has_alias && has_tuple && has_packaging) || needs_upgrade {
                        rewrite = true;
                    }
                } else {
                    rewrite = true;
                }
            }
            VersionFileStyle::Plain => {
                if let Ok(contents) = fs::read_to_string(&version_path) {
                    let trimmed = contents.trim();
                    if trimmed.is_empty()
                        || trimmed == "unknown"
                        || trimmed.starts_with("0.0.0+")
                        || trimmed.starts_with("0+")
                    {
                        rewrite = true;
                    }
                } else {
                    rewrite = true;
                }
            }
        }
        if !rewrite {
            return Ok(());
        }
    }
    if !version_path.exists() || rewrite {
        if let Some(parent) = version_path.parent() {
            fs::create_dir_all(parent)?;
        }
    }

    let derived = match derive_vcs_version(root, &derive_opts) {
        Ok(version) => version,
        Err(err) => {
            warn!(
                error = %err,
                path = %root.display(),
                "git metadata unavailable; writing fallback vcs version"
            );
            if derive_opts.drop_local {
                "0.0.0".to_string()
            } else {
                "0.0.0+unknown".to_string()
            }
        }
    };

    let contents = match style {
        VersionFileStyle::HatchVcsHook => format!(
            "version = \"{derived}\"\n\
__version__ = version\n\
__all__ = [\"__version__\", \"version\"]\n"
        ),
        VersionFileStyle::SetuptoolsScm => format!(
            "from packaging.version import Version as _Version\n\
version = \"{derived}\"\n\
__version__ = version\n\
_v = _Version(version)\n\
version_tuple = tuple(_v.release)\n\
__all__ = [\"__version__\", \"version\", \"version_tuple\"]\n"
        ),
        VersionFileStyle::Plain => format!("{derived}\n"),
    };
    if rewrite || !version_path.exists() {
        fs::write(&version_path, contents)?;
    }
    Ok(())
}

fn derive_vcs_version(
    manifest_dir: &Path,
    derive_opts: &VersionDeriveOptions<'_>,
) -> Result<String> {
    if let Some(command) = derive_opts.git_describe_command {
        if let Some(info) = describe_with_command(command, manifest_dir) {
            if let Some(version) = format_version_from_describe(&info, derive_opts) {
                return Ok(version);
            }
        }
    }

    let default_describe = [
        "git".to_string(),
        "describe".to_string(),
        "--tags".to_string(),
        "--dirty".to_string(),
        "--long".to_string(),
    ];
    if let Some(info) = describe_with_command(&default_describe, manifest_dir) {
        if let Some(version) = format_version_from_describe(&info, derive_opts) {
            return Ok(version);
        }
    }

    if let Ok(output) = Command::new("git")
        .args(["rev-parse", "--short", "HEAD"])
        .current_dir(manifest_dir)
        .output()
    {
        if output.status.success() {
            let hash = String::from_utf8_lossy(&output.stdout)
                .trim()
                .trim_start_matches('g')
                .to_string();
            if !hash.is_empty() {
                if derive_opts.drop_local {
                    return Ok("0.0.0".to_string());
                }
                return Ok(format!("0.0.0+g{hash}"));
            }
        }
    }

    Err(anyhow!(
        "unable to derive version from git; add tags or version-file"
    ))
}

fn describe_with_command(command: &[String], manifest_dir: &Path) -> Option<GitDescribeInfo> {
    let (program, args) = command.split_first()?;
    if program.trim().is_empty() {
        return None;
    }
    let output = Command::new(program)
        .args(args)
        .current_dir(manifest_dir)
        .output()
        .ok()?;
    if !output.status.success() {
        return None;
    }
    parse_git_describe(String::from_utf8_lossy(&output.stdout).trim())
}

fn format_version_from_describe(
    info: &GitDescribeInfo,
    derive_opts: &VersionDeriveOptions<'_>,
) -> Option<String> {
    if derive_opts.simplified_semver {
        if let Some(version) = simplified_semver_from_describe(info, derive_opts.drop_local) {
            return Some(version);
        }
    }
    pep440_from_info(info, derive_opts.drop_local)
}

#[cfg(test)]
fn pep440_from_describe(desc: &str) -> Option<String> {
    parse_git_describe(desc).and_then(|info| pep440_from_info(&info, false))
}

fn pep440_from_info(info: &GitDescribeInfo, drop_local: bool) -> Option<String> {
    let tag = info.tag.trim_start_matches('v');
    let mut version = tag.to_string();
    if !drop_local {
        version.push_str(&format!("+{}.g{}", info.commits_since_tag, info.sha));
        if info.dirty {
            version.push_str(".dirty");
        }
    }
    Some(version)
}

fn simplified_semver_from_describe(info: &GitDescribeInfo, drop_local: bool) -> Option<String> {
    let numeric_start = info
        .tag
        .find(|ch: char| ch.is_ascii_digit())
        .or_else(|| info.tag.find('v').map(|index| index + 1))?;
    let base = info.tag[numeric_start..]
        .trim_start_matches('v')
        .to_string();
    if base.is_empty() {
        return None;
    }
    let mut release_parts: Vec<u64> = base
        .split('.')
        .map(|part| part.parse::<u64>().ok())
        .collect::<Option<Vec<_>>>()?;
    if release_parts.is_empty() {
        return None;
    }
    if info.commits_since_tag > 0 {
        if let Some(last) = release_parts.last_mut() {
            *last += 1;
        }
    }
    let mut version = release_parts
        .iter()
        .map(|part| part.to_string())
        .collect::<Vec<_>>()
        .join(".");
    if info.commits_since_tag > 0 {
        version.push_str(&format!(".dev{}", info.commits_since_tag));
    }
    let has_local = !drop_local && (info.commits_since_tag > 0 || info.dirty);
    if has_local {
        version.push_str(&format!("+g{}", info.sha));
        if info.dirty {
            version.push_str(".dirty");
        }
    }
    Some(version)
}

fn parse_git_describe(desc: &str) -> Option<GitDescribeInfo> {
    let trimmed = desc.trim();
    if trimmed.is_empty() {
        return None;
    }
    let mut dirty = false;
    let mut core = trimmed.to_string();
    if core.ends_with("-dirty") {
        dirty = true;
        core = core.trim_end_matches("-dirty").to_string();
    }
    let mut iter = core.rsplitn(3, '-');
    let sha_part = iter.next()?;
    let commits_part = iter.next()?;
    let tag_part = iter.next()?;

    Some(GitDescribeInfo {
        tag: tag_part.to_string(),
        commits_since_tag: commits_part.parse::<usize>().ok()?,
        sha: sha_part.trim_start_matches('g').to_string(),
        dirty,
    })
}

struct GitDescribeInfo {
    tag: String,
    commits_since_tag: usize,
    sha: String,
    dirty: bool,
}

pub(crate) struct PythonPathInfo {
    pub(crate) pythonpath: String,
    pub(crate) allowed_paths: Vec<PathBuf>,
    pub(crate) site_bin: Option<PathBuf>,
    pub(crate) pep582_bin: Vec<PathBuf>,
}

fn detect_local_site_packages(fs: &dyn effects::FileSystem, site_dir: &Path) -> Option<PathBuf> {
    let lib_dir = site_dir.join("lib");
    if let Ok(entries) = fs.read_dir(&lib_dir) {
        for entry in entries.flatten() {
            let path = entry.path();
            if !path.is_dir() {
                continue;
            }
            if let Some(name) = path.file_name().and_then(|value| value.to_str()) {
                if !name.starts_with("python") {
                    continue;
                }
            }
            let candidate = path.join("site-packages");
            if fs.metadata(&candidate).is_ok() {
                return Some(candidate);
            }
        }
    }
    let fallback = site_dir.join("site-packages");
    fs.metadata(&fallback).ok().map(|_| fallback)
}

fn discover_code_generator_paths(
    fs: &dyn effects::FileSystem,
    project_root: &Path,
    max_depth: usize,
) -> Vec<PathBuf> {
    let mut extras = Vec::new();
    let mut stack = vec![(project_root.to_path_buf(), 0usize)];
    while let Some((dir, depth)) = stack.pop() {
        let Ok(entries) = fs.read_dir(&dir) else {
            continue;
        };
        for entry in entries.flatten() {
            let path = entry.path();
            if !path.is_dir() {
                continue;
            }
            let name = entry.file_name();
            if name
                .to_str()
                .is_some_and(|value| value == "code_generators")
            {
                extras.push(path.clone());
                continue;
            }
            if depth < max_depth {
                stack.push((path, depth + 1));
            }
        }
    }
    extras
}

pub(crate) fn build_pythonpath(
    fs: &dyn effects::FileSystem,
    project_root: &Path,
    site_override: Option<PathBuf>,
) -> Result<PythonPathInfo> {
    let site_dir = match site_override {
        Some(dir) => dir,
        None => resolve_project_site(fs, project_root)?,
    };

    let mut site_paths = Vec::new();
    let mut site_packages_used = None;
    let code_paths = discover_code_generator_paths(fs, project_root, 3);

    let canonical = fs.canonicalize(&site_dir).unwrap_or(site_dir.clone());
    let site_dir_used = Some(canonical.clone());
    site_paths.push(canonical.clone());
    if let Some(site_packages) = detect_local_site_packages(fs, &canonical) {
        site_packages_used = Some(site_packages.clone());
        site_paths.push(site_packages);
    }
    let pth = canonical.join("px.pth");
    if pth.exists() {
        if let Ok(contents) = fs.read_to_string(&pth) {
            for line in contents.lines() {
                let trimmed = line.trim();
                if trimmed.is_empty() {
                    continue;
                }
                let entry_path = PathBuf::from(trimmed);
                if entry_path.exists() {
                    site_paths.push(entry_path);
                }
            }
        }
    }

    let mut project_paths = Vec::new();
    let src = project_root.join("src");
    if src.exists() {
        project_paths.push(src);
    }
    let python_dir = project_root.join("python");
    if python_dir.exists() {
        project_paths.push(python_dir);
    }
    let mut child_projects = Vec::new();
    if let Ok(entries) = fs.read_dir(project_root) {
        for entry in entries.flatten() {
            let path = entry.path();
            if !path.is_dir() {
                continue;
            }
            let manifest = path.join("pyproject.toml");
            if fs.metadata(&manifest).is_ok() {
                child_projects.push(path);
            }
        }
    }
    child_projects.sort();
    for path in child_projects {
        if path != project_root {
            project_paths.push(path);
        }
    }
    project_paths.push(project_root.to_path_buf());

    let mut pep582_libs = Vec::new();
    let mut pep582_bins = Vec::new();
    let pep582_root = project_root.join("__pypackages__");
    if pep582_root.exists() {
        if let Ok(entries) = fs.read_dir(&pep582_root) {
            for entry in entries.flatten() {
                let path = entry.path();
                if !path.is_dir() {
                    continue;
                }
                let lib = path.join("lib");
                if lib.exists() {
                    pep582_libs.push(lib);
                } else {
                    pep582_libs.push(path.clone());
                }
                let bin = path.join("bin");
                if bin.exists() {
                    pep582_bins.push(bin);
                }
            }
        }
    }

    let mut paths = Vec::new();
    if let Some(dir) = site_dir_used.as_ref() {
        paths.push(dir.clone());
    }
    paths.extend(code_paths.clone());
    paths.extend(project_paths.clone());
    if let Some(pkgs) = site_packages_used.as_ref() {
        paths.push(pkgs.clone());
    }
    for path in site_paths {
        if Some(&path) == site_dir_used.as_ref() {
            continue;
        }
        if site_packages_used
            .as_ref()
            .is_some_and(|pkgs| pkgs == &path)
        {
            continue;
        }
        if project_paths.iter().any(|pkg| pkg == &path) {
            continue;
        }
        if code_paths.iter().any(|extra| extra == &path) {
            continue;
        }
        paths.push(path);
    }
    paths.extend(pep582_libs);
    paths.retain(|p| p.exists());
    if paths.is_empty() {
        paths.push(project_root.to_path_buf());
    }

    let joined = env::join_paths(&paths).context("failed to build PYTHONPATH")?;
    let pythonpath = joined
        .into_string()
        .map_err(|_| anyhow!("pythonpath contains non-UTF paths"))?;
    let site_bin = site_dir_used
        .map(|dir| dir.join("bin"))
        .filter(|bin| bin.exists());
    Ok(PythonPathInfo {
        pythonpath,
        allowed_paths: paths,
        site_bin,
        pep582_bin: pep582_bins,
    })
}

pub(crate) fn ensure_project_environment_synced(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
) -> Result<()> {
    if !snapshot.manifest_path.exists() {
        return Err(InstallUserError::new(
            format!("pyproject.toml not found in {}", snapshot.root.display()),
            json!({
                "hint": "run `px migrate --apply` or pass ENTRY explicitly",
                "project_root": snapshot.root.display().to_string(),
                "manifest": snapshot.manifest_path.display().to_string(),
                "reason": "missing_manifest",
            }),
        )
        .into());
    }
    let lock_path = snapshot.lock_path.clone();
    let Some(lock) = load_lockfile_optional(&lock_path)? else {
        return Err(InstallUserError::new(
            "missing px.lock (run `px sync`)",
            json!({
                "lockfile": lock_path.display().to_string(),
                "hint": "run `px sync` to generate px.lock before running this command",
                "reason": "missing_lock",
            }),
        )
        .into());
    };

    let runtime = prepare_project_runtime(snapshot)?;
    let marker_env = detect_marker_environment(&runtime.record.path)?.to_marker_environment()?;

    let drift = detect_lock_drift(snapshot, &lock, Some(&marker_env));
    if !drift.is_empty() {
        return Err(InstallUserError::new(
            "px.lock is out of date",
            json!({
                "lockfile": lock_path.display().to_string(),
                "drift": drift,
                "hint": "run `px sync` to refresh px.lock",
                "reason": "lock_drift",
            }),
        )
        .into());
    }

    let missing = verify_locked_artifacts(&lock);
    if !missing.is_empty() {
        return Err(InstallUserError::new(
            "cached artifacts missing",
            json!({
                "lockfile": lock_path.display().to_string(),
                "missing": missing,
                "hint": "run `px sync` to rehydrate the environment",
                "reason": "missing_artifacts",
            }),
        )
        .into());
    }

    let lock_id = match lock.lock_id.clone() {
        Some(value) => value,
        None => compute_lock_hash(&lock_path)?,
    };
    ensure_env_matches_lock(ctx, snapshot, &lock_id)
}

#[derive(Deserialize)]
struct EnvManifest {
    profile_oid: String,
    runtime_oid: String,
    packages: Vec<ProfilePackage>,
    #[serde(default)]
    sys_path_order: Vec<String>,
}

fn expected_pxpth_entries(manifest: &EnvManifest, store_root: &Path) -> Vec<PathBuf> {
    let mut expected = Vec::new();
    let mut seen = HashSet::new();
    let ordered: Vec<String> = if manifest.sys_path_order.is_empty() {
        manifest
            .packages
            .iter()
            .map(|pkg| pkg.pkg_build_oid.clone())
            .collect()
    } else {
        manifest.sys_path_order.clone()
    };
    for oid in ordered {
        if seen.insert(oid.clone()) {
            let path = store_root
                .join(MATERIALIZED_PKG_BUILDS_DIR)
                .join(&oid)
                .join("site-packages");
            if path.exists() {
                expected.push(path);
            }
        }
    }
    for pkg in &manifest.packages {
        if seen.insert(pkg.pkg_build_oid.clone()) {
            let path = store_root
                .join(MATERIALIZED_PKG_BUILDS_DIR)
                .join(&pkg.pkg_build_oid)
                .join("site-packages");
            if path.exists() {
                expected.push(path);
            }
        }
    }
    expected
}

fn matches_versioned_entry(name: &str, base: &str) -> bool {
    let Some(mut suffix) = name.strip_prefix(base) else {
        return false;
    };
    if suffix.is_empty() {
        return true;
    }
    if let Some(rest) = suffix.strip_prefix('-') {
        suffix = rest;
    }
    if let Some(rest) = suffix
        .strip_suffix(".dist-info")
        .or_else(|| suffix.strip_suffix(".data"))
        .or_else(|| suffix.strip_suffix(".egg-info"))
    {
        suffix = rest;
    }
    suffix
        .chars()
        .all(|ch| ch.is_ascii_digit() || ch == '.' || ch == '-')
}

fn is_allowed_site_entry(name: &str) -> bool {
    matches!(
        name,
        "px.pth"
            | "sitecustomize.py"
            | "__pycache__"
            | "distutils-precedence.pth"
            | "pkg_resources"
    ) || matches_versioned_entry(name, "pip")
        || matches_versioned_entry(name, "setuptools")
        || matches_versioned_entry(name, "_distutils_hack")
        || matches_versioned_entry(name, "pipx")
        || matches_versioned_entry(name, "uv")
}

fn validate_env_site_packages(
    site_packages: &Path,
    manifest: &EnvManifest,
    store_root: &Path,
) -> Result<(), InstallUserError> {
    let entries = fs::read_dir(site_packages).map_err(|err| {
        InstallUserError::new(
            "unable to read environment site-packages",
            json!({
                "site": site_packages.display().to_string(),
                "error": err.to_string(),
                "reason": "missing_env",
                "code": diagnostics::cas::MISSING_OR_CORRUPT,
                "hint": "run `px sync` to refresh the environment",
            }),
        )
    })?;
    let mut unexpected = Vec::new();
    for entry in entries.flatten() {
        let name = entry.file_name();
        let Some(name) = name.to_str() else {
            continue;
        };
        if !is_allowed_site_entry(name) {
            unexpected.push(name.to_string());
        }
    }
    if !unexpected.is_empty() {
        return Err(InstallUserError::new(
            "environment site-packages drifted from CAS profile",
            json!({
                "site": site_packages.display().to_string(),
                "unexpected": unexpected,
                "reason": "env_outdated",
                "code": diagnostics::cas::MISSING_OR_CORRUPT,
                "hint": "run `px sync` to refresh the environment",
            }),
        ));
    }

    let pth_path = site_packages.join("px.pth");
    let contents = fs::read_to_string(&pth_path).map_err(|err| {
        InstallUserError::new(
            "environment px.pth missing or unreadable",
            json!({
                "site": site_packages.display().to_string(),
                "pth": pth_path.display().to_string(),
                "error": err.to_string(),
                "reason": "missing_env",
                "code": diagnostics::cas::MISSING_OR_CORRUPT,
                "hint": "run `px sync` to refresh the environment",
            }),
        )
    })?;
    let actual_paths: HashSet<PathBuf> = contents
        .lines()
        .filter_map(|line| {
            let trimmed = line.trim();
            if trimmed.is_empty() {
                None
            } else {
                Some(PathBuf::from(trimmed))
            }
        })
        .collect();
    let expected_paths = expected_pxpth_entries(manifest, store_root);
    let expected_set: HashSet<PathBuf> = expected_paths.iter().cloned().collect();
    if actual_paths != expected_set {
        return Err(InstallUserError::new(
            "environment px.pth drifted from CAS profile",
            json!({
                "site": site_packages.display().to_string(),
                "expected_px_pth": expected_paths
                    .iter()
                    .map(|path| path.display().to_string())
                    .collect::<Vec<_>>(),
                "px_pth": actual_paths
                    .iter()
                    .map(|path| path.display().to_string())
                    .collect::<Vec<_>>(),
                "reason": "env_outdated",
                "code": diagnostics::cas::MISSING_OR_CORRUPT,
                "hint": "run `px sync` to refresh the environment",
            }),
        ));
    }

    Ok(())
}

pub(crate) fn validate_cas_environment(env: &StoredEnvironment) -> Result<()> {
    if let Some(profile_oid) = env.profile_oid.as_deref() {
        let store = global_store();
        let profile = match store.load(profile_oid) {
            Ok(LoadedObject::Profile { header, .. }) => header,
            Ok(_) => {
                return Err(InstallUserError::new(
                    "environment CAS profile is corrupted",
                    json!({
                        "profile_oid": profile_oid,
                        "reason": "missing_env",
                        "code": diagnostics::cas::MISSING_OR_CORRUPT,
                        "hint": "run `px sync` to rebuild the environment",
                    }),
                )
                .into());
            }
            Err(err) => {
                return Err(InstallUserError::new(
                    "environment CAS profile missing",
                    json!({
                        "profile_oid": profile_oid,
                        "error": err.to_string(),
                        "reason": "missing_env",
                        "code": diagnostics::cas::MISSING_OR_CORRUPT,
                        "hint": "run `px sync` to rebuild the environment",
                    }),
                )
                .into());
            }
        };

        let env_root = env
            .env_path
            .as_ref()
            .map(PathBuf::from)
            .unwrap_or(default_envs_root()?.join(profile_oid));
        let manifest_path = env_root.join("manifest.json");
        let manifest: EnvManifest = match fs::read_to_string(&manifest_path)
            .ok()
            .and_then(|contents| serde_json::from_str(&contents).ok())
        {
            Some(parsed) => parsed,
            None => {
                return Err(InstallUserError::new(
                    "environment manifest missing",
                    json!({
                        "profile_oid": profile_oid,
                        "manifest": manifest_path.display().to_string(),
                        "reason": "missing_env",
                        "code": diagnostics::cas::MISSING_OR_CORRUPT,
                        "hint": "run `px sync` to rebuild the environment",
                    }),
                )
                .into());
            }
        };

        if manifest.profile_oid != profile_oid {
            return Err(InstallUserError::new(
                "environment profile drifted",
                json!({
                    "expected": profile_oid,
                    "found": manifest.profile_oid,
                    "reason": "env_outdated",
                    "code": diagnostics::cas::MISSING_OR_CORRUPT,
                    "hint": "run `px sync` to refresh the environment",
                }),
            )
            .into());
        }
        if manifest.runtime_oid != profile.runtime_oid {
            return Err(InstallUserError::new(
                "environment runtime no longer matches profile",
                json!({
                    "expected": profile.runtime_oid,
                    "found": manifest.runtime_oid,
                    "reason": "env_outdated",
                    "code": diagnostics::cas::MISSING_OR_CORRUPT,
                    "hint": "run `px sync` to refresh the environment",
                }),
            )
            .into());
        }

        validate_env_site_packages(&PathBuf::from(&env.site_packages), &manifest, store.root())
            .map_err(anyhow::Error::from)?;

        let mut expected = profile.packages.clone();
        expected.sort_by(|a, b| {
            a.name
                .cmp(&b.name)
                .then(a.version.cmp(&b.version))
                .then(a.pkg_build_oid.cmp(&b.pkg_build_oid))
        });
        let mut materialized = manifest.packages.clone();
        materialized.sort_by(|a, b| {
            a.name
                .cmp(&b.name)
                .then(a.version.cmp(&b.version))
                .then(a.pkg_build_oid.cmp(&b.pkg_build_oid))
        });
        if expected != materialized {
            return Err(InstallUserError::new(
                "environment packages drifted from CAS profile",
                json!({
                    "reason": "env_outdated",
                    "code": diagnostics::cas::MISSING_OR_CORRUPT,
                    "hint": "run `px sync` to refresh the environment",
                }),
            )
            .into());
        }

        let expected_sys_path: Vec<String> = if profile.sys_path_order.is_empty() {
            expected
                .iter()
                .map(|pkg| pkg.pkg_build_oid.clone())
                .collect()
        } else {
            profile.sys_path_order.clone()
        };
        let materialized_sys_path: Vec<String> = if manifest.sys_path_order.is_empty() {
            materialized
                .iter()
                .map(|pkg| pkg.pkg_build_oid.clone())
                .collect()
        } else {
            manifest.sys_path_order.clone()
        };
        if expected_sys_path != materialized_sys_path {
            return Err(InstallUserError::new(
                "environment sys.path ordering drifted from CAS profile",
                json!({
                    "reason": "env_outdated",
                    "code": diagnostics::cas::MISSING_OR_CORRUPT,
                    "hint": "run `px sync` to refresh the environment",
                }),
            )
            .into());
        }

        if let Err(err) = store.load(&manifest.runtime_oid) {
            return Err(InstallUserError::new(
                "runtime CAS object missing or corrupt",
                json!({
                    "runtime_oid": manifest.runtime_oid,
                    "error": err.to_string(),
                    "reason": "missing_env",
                    "code": diagnostics::cas::MISSING_OR_CORRUPT,
                    "hint": "run `px sync` to rebuild the environment",
                }),
            )
            .into());
        }
        for pkg in &materialized {
            if let Err(err) = store.load(&pkg.pkg_build_oid) {
                return Err(InstallUserError::new(
                    "package CAS object missing or corrupt",
                    json!({
                        "package": pkg.name,
                        "pkg_build_oid": pkg.pkg_build_oid,
                        "error": err.to_string(),
                        "reason": "missing_env",
                        "code": diagnostics::cas::MISSING_OR_CORRUPT,
                        "hint": "run `px sync` to rebuild the environment",
                    }),
                )
                .into());
            }
        }
    }

    Ok(())
}

pub fn ensure_env_matches_lock(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
    lock_id: &str,
) -> Result<()> {
    let state = match load_project_state(ctx.fs(), &snapshot.root) {
        Ok(state) => state,
        Err(err) => {
            return Err(InstallUserError::new(
                "px state file is unreadable",
                json!({
                    "error": err.to_string(),
                    "state": snapshot.root.join(".px").join("state.json"),
                    "hint": "Repair or delete the corrupted .px/state.json file, then rerun the command.",
                    "reason": "invalid_state",
                }),
            )
            .into());
        }
    };
    let Some(env) = state.current_env else {
        return Err(InstallUserError::new(
            "project environment missing",
            json!({
                "hint": "run `px sync` to build the environment",
                "reason": "missing_env",
            }),
        )
        .into());
    };
    if env.lock_id != lock_id {
        return Err(InstallUserError::new(
            "environment is out of date",
            json!({
                "expected_lock_id": lock_id,
                "current_lock_id": env.lock_id,
                "hint": "run `px sync` to rebuild the environment",
                "reason": "env_outdated",
            }),
        )
        .into());
    }
    let site_dir = PathBuf::from(&env.site_packages);
    if !site_dir.exists() {
        return Err(InstallUserError::new(
            "environment files missing",
            json!({
                "site": env.site_packages,
                "hint": "run `px sync` to rebuild the environment",
                "reason": "missing_env",
            }),
        )
        .into());
    }

    let runtime = detect_runtime_metadata(ctx, snapshot)?;
    if runtime.version != env.python.version || runtime.platform != env.platform {
        return Err(InstallUserError::new(
            format!(
                "environment targets Python {} ({}) but {} ({}) is active",
                env.python.version, env.platform, runtime.version, runtime.platform
            ),
            json!({
                "expected_python": env.python.version,
                "current_python": runtime.version,
                "expected_platform": env.platform,
                "current_platform": runtime.platform,
                "hint": "run `px sync` to rebuild for the current runtime",
                "reason": "runtime_mismatch",
            }),
        )
        .into());
    }

    if env.profile_oid.is_none() {
        return Err(InstallUserError::new(
            "environment CAS profile missing",
            json!({
                "reason": "missing_env",
                "code": diagnostics::cas::MISSING_OR_CORRUPT,
                "hint": "run `px sync` to rebuild the environment",
            }),
        )
        .into());
    }

    validate_cas_environment(&env)?;
    ensure_packaging_seeds_present(ctx, snapshot, &env)?;

    Ok(())
}

fn env_root_from_site_packages(site_packages: &Path) -> Option<PathBuf> {
    site_packages
        .parent()
        .and_then(Path::parent)
        .and_then(Path::parent)
        .map(PathBuf::from)
}

fn ensure_packaging_seeds_present(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
    env: &StoredEnvironment,
) -> Result<()> {
    let env_root = env
        .env_path
        .as_ref()
        .map(PathBuf::from)
        .or_else(|| env_root_from_site_packages(Path::new(&env.site_packages)));
    let Some(site_dir) = env_root else {
        return Ok(());
    };
    let env_python = PathBuf::from(&env.python.path);
    let envs = project_site_env(ctx, snapshot, &site_dir, &env_python)?;
    let setuptools_ok = module_available(ctx, snapshot, &env_python, &envs, "setuptools")?;
    let uv_needed = uv_seed_required(snapshot);
    let uv_ok = !uv_needed
        || has_uv_cli(&site_dir)
        || module_available(ctx, snapshot, &env_python, &envs, "uv")?;

    if setuptools_ok && uv_ok {
        return Ok(());
    }
    if !setuptools_ok {
        return Err(InstallUserError::new(
            "environment missing baseline packaging support",
            json!({
                "missing": ["setuptools"],
                "reason": "env_outdated",
                "code": diagnostics::cas::MISSING_OR_CORRUPT,
                "hint": "run `px sync` to refresh the environment",
            }),
        )
        .into());
    }

    ensure_uv_seed(ctx, snapshot, &site_dir, &env_python, &envs)
}

pub(crate) fn ensure_environment_with_guard(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
    guard: EnvGuard,
) -> Result<Option<EnvironmentSyncReport>> {
    match ensure_project_environment_synced(ctx, snapshot) {
        Ok(()) => Ok(None),
        Err(err) => match err.downcast::<InstallUserError>() {
            Ok(user) => match guard {
                EnvGuard::Strict => Err(user.into()),
                EnvGuard::AutoSync => {
                    if let Some(issue) = EnvironmentIssue::from_details(&user.details) {
                        if issue.auto_fixable() {
                            auto_sync_environment(ctx, snapshot, issue)
                        } else {
                            Err(user.into())
                        }
                    } else {
                        Err(user.into())
                    }
                }
            },
            Err(err) => Err(err),
        },
    }
}

fn log_autosync_step(message: &str) {
    eprintln!("px  {message}");
}

pub(crate) fn auto_sync_environment(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
    issue: EnvironmentIssue,
) -> Result<Option<EnvironmentSyncReport>> {
    if issue.needs_lock_resolution() {
        if let Some(message) = issue.lock_message() {
            log_autosync_step(message);
        }
        install_snapshot(ctx, snapshot, false, None)?;
    }
    log_autosync_step(issue.env_message());
    refresh_project_site(snapshot, ctx)?;
    Ok(Some(EnvironmentSyncReport::new(issue)))
}

pub(crate) fn attach_autosync_details(
    outcome: &mut ExecutionOutcome,
    report: Option<EnvironmentSyncReport>,
) {
    let Some(report) = report else {
        return;
    };
    let autosync = report.to_json();
    match outcome.details {
        Value::Object(ref mut map) => {
            map.insert("autosync".to_string(), autosync);
        }
        Value::Null => {
            outcome.details = json!({ "autosync": autosync });
        }
        ref mut other => {
            let previous = other.take();
            outcome.details = json!({
                "value": previous,
                "autosync": autosync,
            });
        }
    }
}

pub(crate) fn python_context(ctx: &CommandContext) -> Result<PythonContext, ExecutionOutcome> {
    python_context_with_mode(ctx, EnvGuard::Strict).map(|(py, _)| py)
}

pub(crate) fn python_context_with_mode(
    ctx: &CommandContext,
    guard: EnvGuard,
) -> Result<(PythonContext, Option<EnvironmentSyncReport>), ExecutionOutcome> {
    match PythonContext::new_with_guard(ctx, guard) {
        Ok(result) => Ok(result),
        Err(err) => {
            if is_missing_project_error(&err) {
                return Err(missing_project_outcome());
            }
            match err.downcast::<InstallUserError>() {
                Ok(user) => Err(ExecutionOutcome::user_error(user.message, user.details)),
                Err(err) => Err(ExecutionOutcome::failure(
                    "failed to prepare python environment",
                    json!({ "error": err.to_string() }),
                )),
            }
        }
    }
}

pub fn missing_project_outcome() -> ExecutionOutcome {
    let guidance = missing_project_guidance().unwrap_or_else(|_| MissingProjectGuidance {
        message: MISSING_PROJECT_MESSAGE.to_string(),
        hint: MISSING_PROJECT_HINT.to_string(),
    });
    ExecutionOutcome::user_error(
        guidance.message.clone(),
        json!({
            "reason": "missing_project",
            "hint": guidance.hint,
        }),
    )
}

pub fn is_missing_project_error(err: &anyhow::Error) -> bool {
    err.chain()
        .any(|cause| cause.to_string().contains("No px project found"))
}

pub fn manifest_error_outcome(err: &anyhow::Error) -> Option<ExecutionOutcome> {
    if err
        .chain()
        .any(|cause| cause.to_string().contains("pyproject.toml not found"))
    {
        return Some(ExecutionOutcome::user_error(
            "pyproject.toml not found",
            json!({
                "reason": "missing_manifest",
                "hint": "Run `px init` to create pyproject.toml, or restore it from version control.",
            }),
        ));
    }

    let parse_error = err
        .chain()
        .find_map(|cause| cause.downcast_ref::<TomlError>().map(ToString::to_string))?;

    let mut target = "pyproject.toml";
    for cause in err.chain() {
        let msg = cause.to_string();
        if msg.contains("px.lock") {
            target = "px.lock";
            break;
        }
        if msg.contains("pyproject.toml") {
            target = "pyproject.toml";
            break;
        }
    }

    let (reason, hint) = if target == "px.lock" {
        (
            "invalid_lock",
            "Delete or fix px.lock, then run `px sync` to regenerate it.",
        )
    } else {
        (
            "invalid_manifest",
            "Fix pyproject.toml syntax and rerun the command.",
        )
    };

    Some(ExecutionOutcome::user_error(
        format!("{target} is not valid TOML"),
        json!({
            "reason": reason,
            "target": target,
            "error": parse_error,
            "hint": hint,
        }),
    ))
}

#[must_use]
pub fn to_json_response(info: CommandInfo, outcome: &ExecutionOutcome, _code: i32) -> Value {
    let status = match outcome.status {
        CommandStatus::Ok => "ok",
        CommandStatus::UserError => "user-error",
        CommandStatus::Failure => "error",
    };
    let details = match &outcome.details {
        Value::Object(_) => outcome.details.clone(),
        Value::Null => json!({}),
        other => json!({ "value": other }),
    };
    json!({
        "status": status,
        "message": format_status_message(info, &outcome.message),
        "details": details,
    })
}

#[must_use]
pub fn format_status_message(info: CommandInfo, message: &str) -> String {
    let group_name = info.group.to_string();
    let prefix = if group_name == info.name {
        format!("px {}", info.name)
    } else {
        format!("px {} {}", group_name, info.name)
    };
    if message.is_empty() {
        prefix
    } else if message.starts_with(&prefix) {
        message.to_string()
    } else {
        format!("{prefix}: {message}")
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::{GlobalOptions, SystemEffects};
    use anyhow::Result;
    use px_domain::ResolvedDependency;
    use serde_json::Value;
    use std::env;
    use std::fs;
    use std::io::Write;
    use std::path::{Path, PathBuf};
    use std::process::Command;
    use std::sync::{Arc, Mutex, OnceLock};
    use tempfile::tempdir;
    use zip::write::FileOptions;

    static PIP_ENV_LOCK: OnceLock<Mutex<()>> = OnceLock::new();

    #[test]
    fn base_env_disables_pyc_writes() -> Result<()> {
        let temp = tempdir()?;
        let ctx = PythonContext {
            project_root: temp.path().to_path_buf(),
            project_name: "demo".to_string(),
            python: "python".into(),
            pythonpath: temp.path().display().to_string(),
            allowed_paths: vec![temp.path().to_path_buf()],
            site_bin: None,
            pep582_bin: Vec::new(),
            px_options: PxOptions::default(),
        };
        let envs = ctx.base_env(&json!({}))?;
        let flag = envs
            .iter()
            .find(|(key, _)| key == "PYTHONDONTWRITEBYTECODE")
            .map(|(_, value)| value.as_str());
        assert_eq!(flag, Some("1"));
        Ok(())
    }

    #[test]
    fn materialize_scripts_from_dist_directory() -> Result<()> {
        let temp = tempdir()?;
        let artifact = temp.path().join("demo-0.1.0.dist");
        let dist_info = artifact.join("demo-0.1.0.dist-info");
        let data_scripts = artifact.join("demo-0.1.0.data").join("scripts");
        fs::create_dir_all(&dist_info)?;
        fs::create_dir_all(&data_scripts)?;
        fs::write(
            dist_info.join("entry_points.txt"),
            "[console_scripts]\nalpha = demo.cli:main\n[gui_scripts]\nbeta = demo.gui:run\n",
        )?;
        fs::write(data_scripts.join("copied.sh"), "echo copied\n")?;

        let bin_dir = temp.path().join("bin");
        materialize_wheel_scripts(&artifact, &bin_dir, Some(Path::new("/custom/python")))?;

        let alpha = fs::read_to_string(bin_dir.join("alpha"))?;
        assert!(
            alpha.starts_with("#!/custom/python"),
            "shebang honors python"
        );
        assert!(alpha.contains("demo.cli"));
        let beta = fs::read_to_string(bin_dir.join("beta"))?;
        assert!(beta.contains("demo.gui"));
        let copied = fs::read_to_string(bin_dir.join("copied.sh"))?;
        assert!(copied.contains("copied"));
        Ok(())
    }

    #[test]
    fn materialize_scripts_from_wheel_file() -> Result<()> {
        let temp = tempdir()?;
        let wheel_path = temp.path().join("demo-0.2.0-py3-none-any.whl");
        let file = fs::File::create(&wheel_path)?;
        let mut zip = zip::ZipWriter::new(file);
        let opts = FileOptions::default();
        zip.start_file("demo-0.2.0.dist-info/entry_points.txt", opts)?;
        zip.write_all(b"[console_scripts]\ngamma = demo.core:run\n")?;
        zip.start_file("demo-0.2.0.data/scripts/helper.sh", opts)?;
        zip.write_all(b"echo helper\n")?;
        zip.finish()?;

        let bin_dir = temp.path().join("wheel-bin");
        materialize_wheel_scripts(&wheel_path, &bin_dir, None)?;

        let gamma = fs::read_to_string(bin_dir.join("gamma"))?;
        assert!(gamma.starts_with("#!/usr/bin/env python3"));
        assert!(gamma.contains("demo.core"));
        let helper = fs::read_to_string(bin_dir.join("helper.sh"))?;
        assert!(helper.contains("helper"));
        Ok(())
    }

    #[test]
    fn detects_maturin_backend() -> Result<()> {
        let temp = tempdir()?;
        let manifest = temp.path().join("pyproject.toml");
        fs::write(
            &manifest,
            r#"[project]
name = "demo"
version = "0.1.0"

[build-system]
requires = ["maturin>=1.0"]
build-backend = "maturin"
"#,
        )?;
        assert!(uses_maturin_backend(&manifest)?);

        fs::write(
            &manifest,
            r#"[project]
name = "demo"
version = "0.1.0"

[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"

[tool.maturin]
features = []
"#,
        )?;
        assert!(uses_maturin_backend(&manifest)?);
        Ok(())
    }

    #[test]
    fn project_wheel_cache_dir_varies_with_build_env() -> Result<()> {
        let key = "RUSTFLAGS";
        let original = env::var(key).ok();
        env::set_var(key, "value-a");

        let temp = tempdir()?;
        let project_root = temp.path().join("maturin-fingerprint");
        fs::create_dir_all(&project_root)?;
        fs::write(
            project_root.join("pyproject.toml"),
            r#"[project]
name = "fingerprint"
version = "0.1.0"

[build-system]
requires = ["maturin>=1.0"]
build-backend = "maturin"
"#,
        )?;

        let snapshot = ProjectSnapshot::read_from(&project_root)?;
        let runtime = RuntimeMetadata {
            path: "/usr/bin/python".into(),
            version: "3.12.0".into(),
            platform: "test-platform".into(),
        };
        let cache_root = temp.path().join("cache");

        let first_hash =
            project_build_hash(&runtime, &snapshot, Path::new("/usr/bin/python"), false)?;
        env::set_var(key, "value-b");
        let second_hash =
            project_build_hash(&runtime, &snapshot, Path::new("/usr/bin/python"), false)?;
        match original {
            Some(value) => env::set_var(key, value),
            None => env::remove_var(key),
        }

        assert_ne!(
            first_hash, second_hash,
            "build hash should reflect build env"
        );

        let first_dir = project_wheel_cache_dir(
            &cache_root,
            &snapshot,
            &runtime,
            Path::new("/usr/bin/python"),
            false,
            &first_hash,
        );
        let second_dir = project_wheel_cache_dir(
            &cache_root,
            &snapshot,
            &runtime,
            Path::new("/usr/bin/python"),
            false,
            &second_hash,
        );
        assert_ne!(
            first_dir, second_dir,
            "cache dir should vary when build hash changes"
        );
        Ok(())
    }

    #[test]
    fn reuses_cached_wheel_and_installs_scripts() -> Result<()> {
        let effects = SystemEffects::new();
        let python = match effects.python().detect_interpreter() {
            Ok(path) => path,
            Err(_) => return Ok(()),
        };

        let temp = tempdir()?;
        let project_root = temp.path().join("cached");
        fs::create_dir_all(&project_root)?;
        fs::write(
            project_root.join("pyproject.toml"),
            r#"[project]
name = "demo-wheel"
version = "0.1.0"
requires-python = ">=3.11"

[build-system]
requires = ["maturin>=1.0"]
build-backend = "maturin"
"#,
        )?;

        let snapshot = ProjectSnapshot::read_from(&project_root)?;
        let runtime = RuntimeMetadata {
            path: python.clone(),
            version: "3.12.0".into(),
            platform: "test-platform".into(),
        };
        let build_hash = project_build_hash(&runtime, &snapshot, Path::new(&python), false)?;
        let cache_root = temp.path().join("cache");
        let cache_dir = project_wheel_cache_dir(
            &cache_root,
            &snapshot,
            &runtime,
            Path::new(&python),
            false,
            &build_hash,
        );
        let ensure_dir = project_wheel_cache_dir(
            &cache_root,
            &snapshot,
            &runtime,
            Path::new(&runtime.path),
            false,
            &build_hash,
        );
        assert_eq!(cache_dir, ensure_dir, "cache dir should be stable");
        fs::create_dir_all(&cache_dir)?;
        let wheel_path = cache_dir.join("demo_wheel-0.1.0-py3-none-any.whl");
        let file = File::create(&wheel_path)?;
        let mut zip = zip::ZipWriter::new(file);
        let opts = FileOptions::default();
        zip.start_file("demo_wheel-0.1.0.dist-info/METADATA", opts)?;
        zip.write_all(b"Name: demo-wheel\nVersion: 0.1.0\n")?;
        zip.start_file("demo_wheel-0.1.0.dist-info/entry_points.txt", opts)?;
        zip.write_all(b"[console_scripts]\ndemo-wheel = demo.cli:main\n")?;
        zip.finish()?;
        let sha256 = compute_file_sha256(&wheel_path)?;
        persist_wheel_metadata(&cache_dir, &wheel_path, &sha256, "demo-wheel", "0.1.0")?;
        assert!(
            cached_project_wheel(&cache_dir)?.is_some(),
            "cached wheel should be detected"
        );

        let env_root = project_root.join(".px").join("env");
        fs::create_dir_all(env_root.join("bin"))?;
        let owner = OwnerId {
            owner_type: OwnerType::ProjectEnv,
            owner_id: "test-owner".into(),
        };
        ensure_project_wheel_scripts(&cache_root, &snapshot, &env_root, &runtime, &owner, None)?;

        let script = env_root.join("bin").join("demo-wheel");
        assert!(
            script.exists(),
            "console script should be materialized from cached wheel"
        );
        let contents = fs::read_to_string(script)?;
        assert!(
            contents.contains("demo.cli"),
            "script content should reflect entry point"
        );
        assert!(cache_dir.join("wheel.json").exists());
        Ok(())
    }

    #[test]
    fn installs_scripts_from_cached_maturin_wheel() -> Result<()> {
        use std::io::Write as _;

        let temp = tempdir()?;
        let project_root = temp.path().join("maturin-demo");
        fs::create_dir_all(&project_root)?;
        fs::write(
            project_root.join("pyproject.toml"),
            r#"[project]
name = "maturin-demo"
version = "0.1.0"
requires-python = ">=3.11"

[build-system]
requires = ["maturin>=1.0"]
build-backend = "maturin"
"#,
        )?;

        let snapshot = ProjectSnapshot::read_from(&project_root)?;
        let runtime = RuntimeMetadata {
            path: "/usr/bin/python".into(),
            version: "3.12.0".into(),
            platform: "test-platform".into(),
        };
        let build_hash =
            project_build_hash(&runtime, &snapshot, Path::new("/usr/bin/python"), false)?;
        let cache_root = temp.path().join("cache");
        let wheel_dir = project_wheel_cache_dir(
            &cache_root,
            &snapshot,
            &runtime,
            Path::new("/usr/bin/python"),
            false,
            &build_hash,
        );
        fs::create_dir_all(&wheel_dir)?;
        let wheel_path = wheel_dir.join("maturin_demo-0.1.0-py3-none-any.whl");
        let file = File::create(&wheel_path)?;
        let mut zip = zip::ZipWriter::new(file);
        let opts = FileOptions::default();
        zip.start_file("maturin_demo-0.1.0.dist-info/METADATA", opts)?;
        zip.write_all(b"Name: maturin-demo\nVersion: 0.1.0\n")?;
        zip.start_file("maturin_demo-0.1.0.data/scripts/maturin-demo", opts)?;
        zip.write_all(b"echo built\n")?;
        zip.finish()?;
        let sha256 = compute_file_sha256(&wheel_path)?;
        persist_wheel_metadata(&wheel_dir, &wheel_path, &sha256, "maturin-demo", "0.1.0")?;

        let env_root = project_root.join(".px").join("env");
        fs::create_dir_all(env_root.join("bin"))?;

        let owner = OwnerId {
            owner_type: OwnerType::ProjectEnv,
            owner_id: "test-owner".into(),
        };
        ensure_project_wheel_scripts(&cache_root, &snapshot, &env_root, &runtime, &owner, None)?;

        let script = env_root.join("bin").join("maturin-demo");
        assert!(
            script.exists(),
            "script should be installed from cached wheel"
        );
        let contents = fs::read_to_string(&script)?;
        assert!(
            contents.contains("built"),
            "wheel script should be copied into env bin"
        );
        Ok(())
    }

    #[test]
    fn reuses_cached_maturin_wheel_when_build_env_changes() -> Result<()> {
        use std::io::Write as _;

        let saved_rustflags = env::var("RUSTFLAGS").ok();
        env::set_var("RUSTFLAGS", "first-hash");

        let temp = tempdir()?;
        let project_root = temp.path().join("maturin-change");
        fs::create_dir_all(&project_root)?;
        fs::write(
            project_root.join("pyproject.toml"),
            r#"[project]
name = "maturin-change"
version = "0.1.0"
requires-python = ">=3.11"

[build-system]
requires = ["maturin>=1.0"]
build-backend = "maturin"
"#,
        )?;

        let snapshot = ProjectSnapshot::read_from(&project_root)?;
        let runtime = RuntimeMetadata {
            path: "/usr/bin/python".into(),
            version: "3.12.0".into(),
            platform: "test-platform".into(),
        };
        let cache_root = temp.path().join("cache");
        let first_hash = project_build_hash(&runtime, &snapshot, Path::new(&runtime.path), false)?;
        let first_dir = project_wheel_cache_dir(
            &cache_root,
            &snapshot,
            &runtime,
            Path::new(&runtime.path),
            false,
            &first_hash,
        );
        fs::create_dir_all(&first_dir)?;
        let wheel_path = first_dir.join("maturin_change-0.1.0-py3-none-any.whl");
        let file = File::create(&wheel_path)?;
        let mut zip = zip::ZipWriter::new(file);
        let opts = FileOptions::default();
        zip.start_file("maturin_change-0.1.0.dist-info/METADATA", opts)?;
        zip.write_all(b"Name: maturin-change\nVersion: 0.1.0\n")?;
        zip.start_file("maturin_change-0.1.0.dist-info/entry_points.txt", opts)?;
        zip.write_all(b"[console_scripts]\nmaturin-change = demo.cli:main\n")?;
        zip.finish()?;
        let sha256 = compute_file_sha256(&wheel_path)?;
        persist_wheel_metadata(&first_dir, &wheel_path, &sha256, "maturin-change", "0.1.0")?;

        env::set_var("RUSTFLAGS", "second-hash");
        let second_hash = project_build_hash(&runtime, &snapshot, Path::new(&runtime.path), false)?;
        assert_ne!(
            first_hash, second_hash,
            "build hash should vary with build env"
        );
        let second_dir = project_wheel_cache_dir(
            &cache_root,
            &snapshot,
            &runtime,
            Path::new(&runtime.path),
            false,
            &second_hash,
        );

        let env_root = project_root.join(".px").join("env");
        fs::create_dir_all(env_root.join("bin"))?;
        let owner = OwnerId {
            owner_type: OwnerType::ProjectEnv,
            owner_id: "test-owner".into(),
        };
        ensure_project_wheel_scripts(&cache_root, &snapshot, &env_root, &runtime, &owner, None)?;

        let script = env_root.join("bin").join("maturin-change");
        assert!(
            script.exists(),
            "script should be installed from cached wheel even when build env changes"
        );
        assert!(
            second_dir.join("wheel.json").exists(),
            "cached wheel should be copied into the current build cache directory"
        );

        match saved_rustflags {
            Some(prev) => env::set_var("RUSTFLAGS", prev),
            None => env::remove_var("RUSTFLAGS"),
        }

        Ok(())
    }

    #[test]
    fn refresh_project_site_bootstraps_pip() -> Result<()> {
        let _lock = PIP_ENV_LOCK.get_or_init(|| Mutex::new(())).lock().unwrap();
        if env::var("PX_ONLINE").unwrap_or_default() != "1" {
            eprintln!("skipping pip bootstrap test (PX_ONLINE!=1)");
            return Ok(());
        }
        let saved_env = vec![
            ("PX_CACHE_PATH", env::var("PX_CACHE_PATH").ok()),
            ("PX_STORE_PATH", env::var("PX_STORE_PATH").ok()),
            ("PX_ENVS_PATH", env::var("PX_ENVS_PATH").ok()),
        ];
        let temp_env = tempdir()?;
        let env_root = temp_env.path();
        env::set_var("PX_CACHE_PATH", env_root.join("cache"));
        env::set_var("PX_STORE_PATH", env_root.join("store"));
        env::set_var("PX_ENVS_PATH", env_root.join("envs"));

        let temp = tempdir()?;
        let project_root = temp.path();
        fs::write(
            project_root.join("pyproject.toml"),
            r#"[project]
name = "pip-bootstrap"
version = "0.0.0"
requires-python = ">=3.11"

[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"
"#,
        )?;
        let snapshot = px_domain::project::snapshot::ProjectSnapshot::read_from(project_root)?;
        let lock = render_lockfile(&snapshot, &Vec::<ResolvedDependency>::new(), PX_VERSION)?;
        fs::write(project_root.join("px.lock"), lock)?;

        let global = GlobalOptions::default();
        let ctx = CommandContext::new(&global, Arc::new(SystemEffects::new()))?;
        refresh_project_site(&snapshot, &ctx)?;

        let state = load_project_state(ctx.fs(), project_root)?;
        let env = state.current_env.expect("env stored");
        let site_packages = PathBuf::from(&env.site_packages);
        let env_root = env
            .env_path
            .as_ref()
            .map(PathBuf::from)
            .or_else(|| {
                site_packages
                    .parent()
                    .and_then(Path::parent)
                    .and_then(Path::parent)
                    .map(PathBuf::from)
            })
            .unwrap_or_else(|| PathBuf::from(&env.site_packages));
        assert!(
            site_packages.join("pip").exists(),
            "pip package should be installed into the px site"
        );
        assert!(
            env_root.join("bin").join("pip").exists() || env_root.join("bin").join("pip3").exists(),
            "pip entrypoint should be generated under site/bin"
        );
        validate_cas_environment(&env)
            .expect("pip bootstrap should keep CAS site in a clean state");

        for (key, value) in saved_env {
            match value {
                Some(prev) => env::set_var(key, prev),
                None => env::remove_var(key),
            }
        }

        Ok(())
    }

    #[test]
    fn refresh_project_site_bootstraps_setuptools() -> Result<()> {
        let _lock = PIP_ENV_LOCK.get_or_init(|| Mutex::new(())).lock().unwrap();
        if env::var("PX_ONLINE").unwrap_or_default() != "1" {
            eprintln!("skipping setuptools bootstrap test (PX_ONLINE!=1)");
            return Ok(());
        }
        let saved_env = vec![
            ("PX_CACHE_PATH", env::var("PX_CACHE_PATH").ok()),
            ("PX_STORE_PATH", env::var("PX_STORE_PATH").ok()),
            ("PX_ENVS_PATH", env::var("PX_ENVS_PATH").ok()),
        ];
        let temp_env = tempdir()?;
        let env_root = temp_env.path();
        env::set_var("PX_CACHE_PATH", env_root.join("cache"));
        env::set_var("PX_STORE_PATH", env_root.join("store"));
        env::set_var("PX_ENVS_PATH", env_root.join("envs"));

        let temp = tempdir()?;
        let project_root = temp.path();
        fs::write(
            project_root.join("pyproject.toml"),
            r#"[project]
name = "seed-demo"
version = "0.0.0"
requires-python = ">=3.11"

[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"
"#,
        )?;
        let snapshot = px_domain::project::snapshot::ProjectSnapshot::read_from(project_root)?;
        let lock = render_lockfile(&snapshot, &Vec::<ResolvedDependency>::new(), PX_VERSION)?;
        fs::write(project_root.join("px.lock"), lock)?;

        let global = GlobalOptions::default();
        let ctx = CommandContext::new(&global, Arc::new(SystemEffects::new()))?;
        refresh_project_site(&snapshot, &ctx)?;

        let state = load_project_state(ctx.fs(), project_root)?;
        let env = state.current_env.expect("env stored");
        let site_packages = PathBuf::from(&env.site_packages);
        let env_root = env
            .env_path
            .as_ref()
            .map(PathBuf::from)
            .or_else(|| env_root_from_site_packages(&site_packages))
            .unwrap_or_else(|| site_packages.clone());
        let env_python = PathBuf::from(&env.python.path);
        let envs = project_site_env(&ctx, &snapshot, &env_root, &env_python)?;
        let script = "import importlib.metadata, pkg_resources, setuptools; print(importlib.metadata.version('setuptools'))";
        let output = ctx.python_runtime().run_command(
            env_python
                .to_str()
                .ok_or_else(|| anyhow!("invalid python path"))?,
            &["-c".to_string(), script.to_string()],
            &envs,
            project_root,
        )?;
        assert_eq!(
            output.code, 0,
            "setuptools import should succeed: {} {}",
            output.stdout, output.stderr
        );
        assert_eq!(
            output.stdout.trim(),
            SETUPTOOLS_SEED_VERSION,
            "expected seeded setuptools version"
        );
        validate_cas_environment(&env).expect("setuptools bootstrap should leave CAS site clean");

        for (key, value) in saved_env {
            match value {
                Some(prev) => env::set_var(key, prev),
                None => env::remove_var(key),
            }
        }

        Ok(())
    }

    #[test]
    fn refresh_project_site_bootstraps_uv_when_uv_lock_present() -> Result<()> {
        let _lock = PIP_ENV_LOCK.get_or_init(|| Mutex::new(())).lock().unwrap();
        if env::var("PX_ONLINE").unwrap_or_default() != "1" {
            eprintln!("skipping uv bootstrap test (PX_ONLINE!=1)");
            return Ok(());
        }
        let saved_env = vec![
            ("PX_CACHE_PATH", env::var("PX_CACHE_PATH").ok()),
            ("PX_STORE_PATH", env::var("PX_STORE_PATH").ok()),
            ("PX_ENVS_PATH", env::var("PX_ENVS_PATH").ok()),
        ];
        let temp_env = tempdir()?;
        let env_root = temp_env.path();
        env::set_var("PX_CACHE_PATH", env_root.join("cache"));
        env::set_var("PX_STORE_PATH", env_root.join("store"));
        env::set_var("PX_ENVS_PATH", env_root.join("envs"));

        let temp = tempdir()?;
        let project_root = temp.path();
        fs::write(
            project_root.join("pyproject.toml"),
            r#"[project]
name = "uv-seed-demo"
version = "0.0.0"
requires-python = ">=3.11"

[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"
"#,
        )?;
        fs::write(project_root.join("uv.lock"), "version = 1\n")?;
        let snapshot = px_domain::project::snapshot::ProjectSnapshot::read_from(project_root)?;
        let lock = render_lockfile(&snapshot, &Vec::<ResolvedDependency>::new(), PX_VERSION)?;
        fs::write(project_root.join("px.lock"), lock)?;

        let global = GlobalOptions::default();
        let ctx = CommandContext::new(&global, Arc::new(SystemEffects::new()))?;
        refresh_project_site(&snapshot, &ctx)?;

        let state = load_project_state(ctx.fs(), project_root)?;
        let env = state.current_env.expect("env stored");
        let site_packages = PathBuf::from(&env.site_packages);
        let env_root = env
            .env_path
            .as_ref()
            .map(PathBuf::from)
            .or_else(|| env_root_from_site_packages(&site_packages))
            .unwrap_or_else(|| site_packages.clone());
        let env_python = PathBuf::from(&env.python.path);
        let envs = project_site_env(&ctx, &snapshot, &env_root, &env_python)?;
        let uv_path = uv_cli_candidates(&env_root)
            .into_iter()
            .find(|path| path.exists())
            .expect("uv cli available");
        let output = Command::new(&uv_path).arg("--version").output()?;
        assert!(
            output.status.success(),
            "uv cli should execute: stdout={} stderr={}",
            output.stdout.escape_ascii(),
            output.stderr.escape_ascii()
        );
        let stdout = String::from_utf8_lossy(&output.stdout);
        assert!(
            stdout.contains(UV_SEED_VERSION),
            "uv version should match seed; stdout={stdout}"
        );
        let script = "import importlib.metadata as im; print(im.version('uv'))";
        let probe = ctx.python_runtime().run_command(
            env_python
                .to_str()
                .ok_or_else(|| anyhow!("invalid python path"))?,
            &["-c".to_string(), script.to_string()],
            &envs,
            project_root,
        )?;
        assert_eq!(
            probe.code, 0,
            "uv module should import: {} {}",
            probe.stdout, probe.stderr
        );
        assert_eq!(
            probe.stdout.trim(),
            UV_SEED_VERSION,
            "expected uv module version from seed"
        );
        validate_cas_environment(&env).expect("uv bootstrap should leave CAS site clean");

        for (key, value) in saved_env {
            match value {
                Some(prev) => env::set_var(key, prev),
                None => env::remove_var(key),
            }
        }

        Ok(())
    }

    #[test]
    fn refresh_project_site_seeds_setuptools_with_no_ensurepip() -> Result<()> {
        let _lock = PIP_ENV_LOCK.get_or_init(|| Mutex::new(())).lock().unwrap();
        if env::var("PX_ONLINE").unwrap_or_default() != "1" {
            eprintln!("skipping setuptools bootstrap test (PX_ONLINE!=1)");
            return Ok(());
        }
        let saved_env = vec![
            ("PX_CACHE_PATH", env::var("PX_CACHE_PATH").ok()),
            ("PX_STORE_PATH", env::var("PX_STORE_PATH").ok()),
            ("PX_ENVS_PATH", env::var("PX_ENVS_PATH").ok()),
            ("PX_NO_ENSUREPIP", env::var("PX_NO_ENSUREPIP").ok()),
        ];
        let temp_env = tempdir()?;
        let env_root = temp_env.path();
        env::set_var("PX_CACHE_PATH", env_root.join("cache"));
        env::set_var("PX_STORE_PATH", env_root.join("store"));
        env::set_var("PX_ENVS_PATH", env_root.join("envs"));
        env::set_var("PX_NO_ENSUREPIP", "1");

        let temp = tempdir()?;
        let project_root = temp.path();
        fs::write(
            project_root.join("pyproject.toml"),
            r#"[project]
name = "seed-demo"
version = "0.0.0"
requires-python = ">=3.11"

[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"
"#,
        )?;
        let snapshot = px_domain::project::snapshot::ProjectSnapshot::read_from(project_root)?;
        let lock = render_lockfile(&snapshot, &Vec::<ResolvedDependency>::new(), PX_VERSION)?;
        fs::write(project_root.join("px.lock"), lock)?;

        let global = GlobalOptions::default();
        let ctx = CommandContext::new(&global, Arc::new(SystemEffects::new()))?;
        refresh_project_site(&snapshot, &ctx)?;

        let state = load_project_state(ctx.fs(), project_root)?;
        let env = state.current_env.expect("env stored");
        let site_packages = PathBuf::from(&env.site_packages);
        let env_root = env
            .env_path
            .as_ref()
            .map(PathBuf::from)
            .or_else(|| env_root_from_site_packages(&site_packages))
            .unwrap_or_else(|| site_packages.clone());
        let env_python = PathBuf::from(&env.python.path);
        let envs = project_site_env(&ctx, &snapshot, &env_root, &env_python)?;
        let script = "import importlib.metadata, pkg_resources, setuptools, pip; print(importlib.metadata.version('setuptools'))";
        let output = ctx.python_runtime().run_command(
            env_python
                .to_str()
                .ok_or_else(|| anyhow!("invalid python path"))?,
            &["-c".to_string(), script.to_string()],
            &envs,
            project_root,
        )?;
        assert_eq!(
            output.code, 0,
            "setuptools import should succeed even when PX_NO_ENSUREPIP=1: {} {}",
            output.stdout, output.stderr
        );
        assert_eq!(
            output.stdout.trim(),
            SETUPTOOLS_SEED_VERSION,
            "expected seeded setuptools version"
        );
        validate_cas_environment(&env).expect("bootstrap should leave CAS site clean");

        for (key, value) in saved_env {
            match value {
                Some(prev) => env::set_var(key, prev),
                None => env::remove_var(key),
            }
        }

        Ok(())
    }

    #[test]
    fn refresh_project_site_preserves_editable_pip_entrypoints() -> Result<()> {
        let _lock = PIP_ENV_LOCK.get_or_init(|| Mutex::new(())).lock().unwrap();
        if env::var("PX_ONLINE").unwrap_or_default() != "1" {
            eprintln!("skipping editable pip preservation test (PX_ONLINE!=1)");
            return Ok(());
        }
        let saved_env = vec![
            ("PX_CACHE_PATH", env::var("PX_CACHE_PATH").ok()),
            ("PX_STORE_PATH", env::var("PX_STORE_PATH").ok()),
            ("PX_ENVS_PATH", env::var("PX_ENVS_PATH").ok()),
        ];
        let temp_env = tempdir()?;
        let env_root = temp_env.path();
        env::set_var("PX_CACHE_PATH", env_root.join("cache"));
        env::set_var("PX_STORE_PATH", env_root.join("store"));
        env::set_var("PX_ENVS_PATH", env_root.join("envs"));

        let temp = tempdir()?;
        let project_root = temp.path();
        fs::write(
            project_root.join("pyproject.toml"),
            r#"[project]
name = "pip"
version = "0.0.0"
requires-python = ">=3.11"
dependencies = []

[project.scripts]
pip = "pip._internal.cli.main:main"
pip3 = "pip._internal.cli.main:main"

[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"

[tool.px]
"#,
        )?;
        let pkg_root = project_root
            .join("src")
            .join("pip")
            .join("_internal")
            .join("cli");
        fs::create_dir_all(&pkg_root)?;
        fs::write(pkg_root.join("__init__.py"), "")?;
        fs::write(pkg_root.join("main.py"), "def main():\n    return 0\n")?;
        let pkg_base = project_root.join("src").join("pip").join("_internal");
        fs::write(pkg_base.join("__init__.py"), "")?;
        fs::write(project_root.join("src").join("pip").join("__init__.py"), "")?;

        let snapshot = px_domain::project::snapshot::ProjectSnapshot::read_from(project_root)?;
        let lock = render_lockfile(&snapshot, &Vec::<ResolvedDependency>::new(), PX_VERSION)?;
        fs::write(project_root.join("px.lock"), lock)?;

        let global = GlobalOptions::default();
        let ctx = CommandContext::new(&global, Arc::new(SystemEffects::new()))?;
        refresh_project_site(&snapshot, &ctx)?;

        let state = load_project_state(ctx.fs(), project_root)?;
        let env = state.current_env.expect("env stored");
        let site_packages = PathBuf::from(&env.site_packages);
        let env_root = env
            .env_path
            .as_ref()
            .map(PathBuf::from)
            .or_else(|| {
                site_packages
                    .parent()
                    .and_then(Path::parent)
                    .and_then(Path::parent)
                    .map(PathBuf::from)
            })
            .unwrap_or_else(|| PathBuf::from(&env.site_packages));

        let pip_entry = env_root.join("bin").join("pip");
        let pip_contents = fs::read_to_string(&pip_entry)?;
        assert!(
            pip_contents.contains("pip._internal.cli.main"),
            "editable pip entrypoint should target project module"
        );
        assert!(
            !pip_contents.starts_with("#!/bin/sh"),
            "runtime ensurepip shim should not replace project pip script"
        );
        assert!(
            env_root
                .read_dir()?
                .flatten()
                .any(|entry| entry.path().join("PX-EDITABLE").exists()),
            "editable dist-info should be preserved for pip"
        );

        for (key, value) in saved_env {
            match value {
                Some(prev) => env::set_var(key, prev),
                None => env::remove_var(key),
            }
        }

        Ok(())
    }

    #[test]
    fn validate_env_detects_untracked_site_packages_entries() -> Result<()> {
        let _lock = PIP_ENV_LOCK.get_or_init(|| Mutex::new(())).lock().unwrap();
        if env::var("PX_ONLINE").unwrap_or_default() != "1" {
            eprintln!("skipping validate env drift test (PX_ONLINE!=1)");
            return Ok(());
        }
        let saved_env = vec![
            ("PX_CACHE_PATH", env::var("PX_CACHE_PATH").ok()),
            ("PX_STORE_PATH", env::var("PX_STORE_PATH").ok()),
            ("PX_ENVS_PATH", env::var("PX_ENVS_PATH").ok()),
        ];
        let temp_env = tempdir()?;
        let env_root = temp_env.path();
        env::set_var("PX_CACHE_PATH", env_root.join("cache"));
        env::set_var("PX_STORE_PATH", env_root.join("store"));
        env::set_var("PX_ENVS_PATH", env_root.join("envs"));

        let temp = tempdir()?;
        let project_root = temp.path();
        fs::write(
            project_root.join("pyproject.toml"),
            r#"[project]
name = "drift-demo"
version = "0.0.0"
requires-python = ">=3.11"
dependencies = []

[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"
"#,
        )?;
        let snapshot = px_domain::project::snapshot::ProjectSnapshot::read_from(project_root)?;
        let lock = render_lockfile(&snapshot, &Vec::<ResolvedDependency>::new(), PX_VERSION)?;
        fs::write(project_root.join("px.lock"), lock)?;

        let global = GlobalOptions::default();
        let ctx = CommandContext::new(&global, Arc::new(SystemEffects::new()))?;
        refresh_project_site(&snapshot, &ctx)?;

        let state = load_project_state(ctx.fs(), project_root)?;
        let env = state.current_env.expect("env stored");
        let site_packages = PathBuf::from(&env.site_packages);
        fs::create_dir_all(&site_packages)?;
        fs::write(site_packages.join("stray.py"), "print('oops')\n")?;

        let err = validate_cas_environment(&env).unwrap_err();
        let user = err
            .downcast::<InstallUserError>()
            .expect("user-facing error");
        assert_eq!(
            user.details
                .get("reason")
                .and_then(serde_json::Value::as_str),
            Some("env_outdated")
        );
        assert!(
            user.message.contains("site-packages"),
            "expected site-packages drift message, got {}",
            user.message
        );

        for (key, value) in saved_env {
            match value {
                Some(prev) => env::set_var(key, prev),
                None => env::remove_var(key),
            }
        }

        Ok(())
    }

    #[test]
    fn site_dir_precedes_project_root_in_sys_path() -> Result<()> {
        let temp = tempdir()?;
        let project_root = temp.path();
        let site_dir = project_root.join("site");
        fs::create_dir_all(&site_dir)?;
        fs::write(site_dir.join("sitecustomize.py"), SITE_CUSTOMIZE)?;

        let dep_pkg = site_dir.join("deps");
        let dep_mod = dep_pkg.join("dep");
        fs::create_dir_all(&dep_mod)?;
        fs::write(dep_mod.join("__init__.py"), "VALUE = 'site'\n")?;
        fs::write(site_dir.join("px.pth"), format!("{}\n", dep_pkg.display()))?;

        // Namespace-like directory at the project root should not shadow site packages
        fs::create_dir_all(project_root.join("dep"))?;

        let effects = SystemEffects::new();
        let paths = build_pythonpath(effects.fs(), project_root, Some(site_dir.clone()))?;
        let allowed = env::join_paths(&paths.allowed_paths)
            .expect("allowed paths")
            .into_string()
            .expect("utf8 allowed paths");
        let allowed_env = allowed.clone();
        let python = match effects.python().detect_interpreter() {
            Ok(path) => path,
            Err(_) => return Ok(()),
        };

        let mut cmd = Command::new(&python);
        cmd.current_dir(project_root);
        cmd.env("PYTHONPATH", paths.pythonpath.clone());
        cmd.env("PX_ALLOWED_PATHS", allowed_env.clone());
        cmd.arg("-c").arg(
            "import importlib, json, os, sys; mod = importlib.import_module('dep'); \
             print(json.dumps({'file': getattr(mod, '__file__', ''), 'value': getattr(mod, 'VALUE', ''), 'prefix': sys.path[:3], 'env_py': os.environ.get('PYTHONPATH')}))",
        );
        let output = cmd.output()?;
        let stdout = String::from_utf8_lossy(&output.stdout);
        assert!(
            output.status.success(),
            "python exited with {}: {}\n{}",
            output.status,
            stdout,
            String::from_utf8_lossy(&output.stderr)
        );

        let payload: Value = serde_json::from_str(stdout.trim())?;
        let prefix: Vec<String> = payload
            .get("prefix")
            .and_then(Value::as_array)
            .map(|entries| {
                entries
                    .iter()
                    .filter_map(Value::as_str)
                    .map(std::string::ToString::to_string)
                    .collect()
            })
            .unwrap_or_default();
        let canonical_site = effects.fs().canonicalize(&site_dir)?;
        let canonical_site_str = canonical_site.display().to_string();
        let first_nonempty = if prefix.first().is_some_and(|entry| entry.is_empty()) {
            prefix.get(1).map(String::as_str)
        } else {
            prefix.first().map(String::as_str)
        };
        assert_eq!(first_nonempty, Some(canonical_site_str.as_str()));
        let value = payload
            .get("value")
            .and_then(Value::as_str)
            .unwrap_or_default();
        assert_eq!(value, "site");
        let env_py = payload
            .get("env_py")
            .and_then(Value::as_str)
            .unwrap_or_default();
        assert_eq!(env_py, allowed_env);
        let file = payload.get("file").and_then(Value::as_str).unwrap_or("");
        assert!(
            file.contains(dep_mod.to_string_lossy().as_ref()),
            "expected module to load from site packages, got {file}"
        );
        Ok(())
    }

    #[test]
    fn build_pythonpath_refuses_legacy_site_fallback() -> Result<()> {
        let temp = tempdir()?;
        let project_root = temp.path();
        fs::create_dir_all(project_root.join(".px").join("site"))?;

        let err = match build_pythonpath(SystemEffects::new().fs(), project_root, None) {
            Ok(_) => panic!("missing CAS environment should be an error"),
            Err(err) => err,
        };
        let user = err
            .downcast::<InstallUserError>()
            .expect("expected user-facing error");
        assert_eq!(
            user.details
                .get("reason")
                .and_then(serde_json::Value::as_str),
            Some("missing_env"),
            "missing env should not fall back to .px/site"
        );
        Ok(())
    }

    #[test]
    fn project_paths_precede_local_site_packages() -> Result<()> {
        let temp = tempdir()?;
        let project_root = temp.path();
        let site_dir = project_root.join("site");
        let site_packages = site_dir.join("site-packages");
        fs::create_dir_all(&site_packages)?;
        fs::write(site_dir.join("sitecustomize.py"), SITE_CUSTOMIZE)?;

        let site_pkg = site_packages.join("demo");
        fs::create_dir_all(&site_pkg)?;
        fs::write(site_pkg.join("__init__.py"), "VALUE = 'site'\n")?;

        let project_pkg = project_root.join("demo");
        fs::create_dir_all(&project_pkg)?;
        fs::write(project_pkg.join("__init__.py"), "VALUE = 'project'\n")?;

        let effects = SystemEffects::new();
        let paths = build_pythonpath(effects.fs(), project_root, Some(site_dir.clone()))?;
        let allowed_env = env::join_paths(&paths.allowed_paths)?
            .into_string()
            .expect("allowed paths");
        let python = match effects.python().detect_interpreter() {
            Ok(path) => path,
            Err(_) => return Ok(()),
        };

        let mut cmd = Command::new(&python);
        cmd.current_dir(project_root);
        cmd.env("PYTHONPATH", paths.pythonpath.clone());
        cmd.env("PX_ALLOWED_PATHS", allowed_env);
        cmd.env("PYTHONSAFEPATH", "1");
        cmd.arg("-c").arg(
            "import importlib, json, sys; mod = importlib.import_module('demo'); \
             print(json.dumps({'value': getattr(mod, 'VALUE', ''), 'file': getattr(mod, '__file__', ''), 'prefix': sys.path[:4]}))",
        );
        let output = cmd.output()?;
        let stdout = String::from_utf8_lossy(&output.stdout);
        assert!(
            output.status.success(),
            "python exited with {}: {}\n{}",
            output.status,
            stdout,
            String::from_utf8_lossy(&output.stderr)
        );

        let payload: Value = serde_json::from_str(stdout.trim())?;
        let value = payload
            .get("value")
            .and_then(Value::as_str)
            .unwrap_or_default();
        assert_eq!(value, "project");
        let file = payload.get("file").and_then(Value::as_str).unwrap_or("");
        assert!(
            file.contains(project_pkg.to_string_lossy().as_ref()),
            "expected project package, got {file}"
        );
        let prefix: Vec<PathBuf> = payload
            .get("prefix")
            .and_then(Value::as_array)
            .map(|entries| {
                entries
                    .iter()
                    .filter_map(Value::as_str)
                    .map(PathBuf::from)
                    .collect()
            })
            .unwrap_or_default();
        let proj_pos = prefix
            .iter()
            .position(|entry| fs::canonicalize(entry).ok() == Some(project_root.to_path_buf()));
        let site_pos = prefix
            .iter()
            .position(|entry| fs::canonicalize(entry).ok() == Some(site_packages.clone()));
        assert!(
            proj_pos < site_pos,
            "project path should precede site-packages in sys.path, got {:?}",
            prefix
        );
        Ok(())
    }

    #[test]
    fn sitecustomize_filters_out_unallowed_paths() -> Result<()> {
        let temp = tempdir()?;
        let site_dir = temp.path().join("site");
        fs::create_dir_all(&site_dir)?;
        fs::write(site_dir.join("sitecustomize.py"), SITE_CUSTOMIZE)?;

        let effects = SystemEffects::new();
        let python = match effects.python().detect_interpreter() {
            Ok(path) => path,
            Err(_) => return Ok(()),
        };
        let version = Command::new(&python)
            .arg("-c")
            .arg("import sys; print(f\"{sys.version_info[0]}.{sys.version_info[1]}\")")
            .output()?;
        if !version.status.success() {
            return Ok(());
        }
        let version = String::from_utf8_lossy(&version.stdout).trim().to_string();

        let user_base = temp.path().join("userbase");
        let user_site = user_base
            .join("lib")
            .join(format!("python{version}"))
            .join("site-packages");
        fs::create_dir_all(&user_site)?;

        let mut cmd = Command::new(&python);
        cmd.current_dir(temp.path());
        cmd.env_clear();
        cmd.env("PYTHONPATH", site_dir.display().to_string());
        cmd.env("PX_ALLOWED_PATHS", site_dir.display().to_string());
        cmd.env("PYTHONUSERBASE", user_base.display().to_string());
        cmd.arg("-c")
            .arg("import json, sys; print(json.dumps(sys.path))");

        let output = cmd.output()?;
        let stdout = String::from_utf8_lossy(&output.stdout);
        assert!(
            output.status.success(),
            "python exited with {}: {}\n{}",
            output.status,
            stdout,
            String::from_utf8_lossy(&output.stderr)
        );

        let allowed_user_base = fs::canonicalize(&user_base)?;
        let paths: Vec<PathBuf> = serde_json::from_str(stdout.trim())?;
        assert!(
            paths
                .iter()
                .filter_map(|entry| fs::canonicalize(entry).ok())
                .all(|entry| !entry.starts_with(&allowed_user_base)),
            "user site paths should be filtered out of sys.path: {paths:?}"
        );
        Ok(())
    }

    #[test]
    fn sitecustomize_uses_pythonpath_when_px_allowed_missing() -> Result<()> {
        let temp = tempdir()?;
        let site_dir = temp.path().join("site");
        fs::create_dir_all(&site_dir)?;
        fs::write(site_dir.join("sitecustomize.py"), SITE_CUSTOMIZE)?;

        let dep_dir = site_dir.join("deps");
        fs::create_dir_all(&dep_dir)?;
        fs::write(dep_dir.join("shim.py"), "VALUE = 'ok'\n")?;
        fs::write(site_dir.join("px.pth"), format!("{}\n", dep_dir.display()))?;

        let python = match SystemEffects::new().python().detect_interpreter() {
            Ok(path) => path,
            Err(_) => return Ok(()),
        };

        let mut cmd = Command::new(&python);
        cmd.current_dir(temp.path());
        cmd.env_clear();
        cmd.env("PYTHONPATH", site_dir.display().to_string());
        cmd.arg("-c").arg(
            "import json, sys, shim; print(json.dumps({'value': shim.VALUE, 'path': sys.path}))",
        );
        let output = cmd.output()?;
        let stdout = String::from_utf8_lossy(&output.stdout);
        assert!(
            output.status.success(),
            "python exited with {}: {}\n{}",
            output.status,
            stdout,
            String::from_utf8_lossy(&output.stderr)
        );

        let payload: Value = serde_json::from_str(stdout.trim())?;
        let value = payload
            .get("value")
            .and_then(Value::as_str)
            .unwrap_or_default();
        assert_eq!(value, "ok");
        let paths: Vec<String> = payload
            .get("path")
            .and_then(Value::as_array)
            .map(|entries| {
                entries
                    .iter()
                    .filter_map(Value::as_str)
                    .map(std::string::ToString::to_string)
                    .collect()
            })
            .unwrap_or_default();
        let dep_canon = fs::canonicalize(&dep_dir)?;
        assert!(
            paths
                .iter()
                .any(|entry| fs::canonicalize(entry).ok() == Some(dep_canon.clone())),
            "px.pth entries should persist even when PX_ALLOWED_PATHS is unset; sys.path={paths:?}"
        );
        Ok(())
    }

    #[test]
    fn sitecustomize_merges_pythonpath_when_px_allowed_set() -> Result<()> {
        let temp = tempdir()?;
        let site_dir = temp.path().join("site");
        fs::create_dir_all(&site_dir)?;
        fs::write(site_dir.join("sitecustomize.py"), SITE_CUSTOMIZE)?;

        let extra = temp.path().join("extra");
        fs::create_dir_all(&extra)?;
        fs::write(extra.join("shim.py"), "VALUE = 'ok'\n")?;

        let python = match SystemEffects::new().python().detect_interpreter() {
            Ok(path) => path,
            Err(_) => return Ok(()),
        };

        let mut cmd = Command::new(&python);
        cmd.current_dir(temp.path());
        cmd.env_clear();
        cmd.env("PX_ALLOWED_PATHS", site_dir.display().to_string());
        let pythonpath = env::join_paths([extra.clone(), site_dir.clone()])?;
        cmd.env("PYTHONPATH", pythonpath);
        cmd.arg("-c").arg(
            "import json, sys, shim; print(json.dumps({'value': shim.VALUE, 'path': sys.path}))",
        );
        let output = cmd.output()?;
        let stdout = String::from_utf8_lossy(&output.stdout);
        assert!(
            output.status.success(),
            "python exited with {}: {}\n{}",
            output.status,
            stdout,
            String::from_utf8_lossy(&output.stderr)
        );

        let payload: Value = serde_json::from_str(stdout.trim())?;
        let value = payload
            .get("value")
            .and_then(Value::as_str)
            .unwrap_or_default();
        assert_eq!(value, "ok");
        let paths: Vec<String> = payload
            .get("path")
            .and_then(Value::as_array)
            .map(|entries| {
                entries
                    .iter()
                    .filter_map(Value::as_str)
                    .map(std::string::ToString::to_string)
                    .collect()
            })
            .unwrap_or_default();
        let extra_canon = fs::canonicalize(&extra)?;
        assert!(
            paths
                .iter()
                .any(|entry| fs::canonicalize(entry).ok() == Some(extra_canon.clone())),
            "extra PYTHONPATH entries should persist when PX_ALLOWED_PATHS is set; sys.path={paths:?}"
        );
        Ok(())
    }

    #[test]
    fn sitecustomize_reinserts_cwd_when_script_dir_empty() -> Result<()> {
        let temp = tempdir()?;
        let site_dir = temp.path().join("site");
        fs::create_dir_all(&site_dir)?;
        fs::write(site_dir.join("sitecustomize.py"), SITE_CUSTOMIZE)?;

        let python = match SystemEffects::new().python().detect_interpreter() {
            Ok(path) => path,
            Err(_) => return Ok(()),
        };

        let mut cmd = Command::new(&python);
        cmd.current_dir(temp.path());
        cmd.env_clear();
        cmd.env("PYTHONPATH", site_dir.display().to_string());
        cmd.env("PX_ALLOWED_PATHS", site_dir.display().to_string());
        cmd.env("PYTHONSAFEPATH", "1");
        cmd.arg("-c").arg(
            "import sitecustomize, json, sys; print(json.dumps({'path': sys.path, 'site': getattr(sitecustomize, '__file__', '')}))",
        );
        let output = cmd.output()?;
        let stdout = String::from_utf8_lossy(&output.stdout);
        assert!(
            output.status.success(),
            "python exited with {}: {}\n{}",
            output.status,
            stdout,
            String::from_utf8_lossy(&output.stderr)
        );

        let payload: Value = serde_json::from_str(stdout.trim())?;
        let site_path = payload.get("site").and_then(Value::as_str).unwrap_or("");
        assert!(
            site_path.contains(site_dir.to_string_lossy().as_ref()),
            "sitecustomize should be loaded from the px site directory: {site_path}"
        );
        let paths: Vec<PathBuf> = payload
            .get("path")
            .and_then(Value::as_array)
            .map(|entries| {
                entries
                    .iter()
                    .filter_map(Value::as_str)
                    .map(PathBuf::from)
                    .collect()
            })
            .unwrap_or_default();
        let cwd = fs::canonicalize(temp.path())?;
        assert!(
            paths
                .iter()
                .any(|entry| fs::canonicalize(entry).ok() == Some(cwd.clone())),
            "current working directory should be retained in sys.path, got {paths:?}"
        );
        Ok(())
    }

    #[test]
    fn editable_stub_exposes_project_version_metadata() -> Result<()> {
        let temp = tempdir()?;
        let project_root = temp.path();
        let pyproject = project_root.join("pyproject.toml");
        fs::write(
            &pyproject,
            r#"[project]
name = "demo-proj"
version = "1.2.3"
requires-python = ">=3.11"
dependencies = []

[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"
"#,
        )?;
        let pkg_dir = project_root.join("src/demo_proj");
        fs::create_dir_all(&pkg_dir)?;
        fs::write(pkg_dir.join("__init__.py"), "__version__ = '1.2.3'\n")?;

        let snapshot = ProjectSnapshot::read_from(project_root)?;
        let site_dir = project_root.join(".px").join("env").join("site");
        let effects = SystemEffects::new();
        effects.fs().create_dir_all(&site_dir)?;
        write_sitecustomize(&site_dir, None, effects.fs())?;
        write_project_metadata_stub(&snapshot, &site_dir, effects.fs())?;

        let python = match effects.python().detect_interpreter() {
            Ok(path) => path,
            Err(_) => return Ok(()),
        };
        let allowed = env::join_paths([site_dir.clone(), project_root.join("src")])?;
        let allowed_str = allowed.to_string_lossy().into_owned();
        let mut cmd = Command::new(&python);
        cmd.current_dir(project_root);
        cmd.env("PYTHONPATH", allowed_str.clone());
        cmd.env("PX_ALLOWED_PATHS", allowed_str);
        cmd.arg("-c").arg(
            "import importlib.metadata, json; print(json.dumps({'version': importlib.metadata.version('demo-proj')}))",
        );
        let output = cmd.output()?;
        if !output.status.success() {
            return Ok(());
        }
        let payload: Value = serde_json::from_slice(&output.stdout)?;
        assert_eq!(
            payload.get("version").and_then(Value::as_str),
            Some("1.2.3")
        );
        Ok(())
    }

    #[test]
    fn editable_stub_writes_file_url_direct_url() -> Result<()> {
        let temp = tempdir()?;
        let project_root = temp.path();
        let pyproject = project_root.join("pyproject.toml");
        fs::write(
            &pyproject,
            r#"[project]
name = "demo-dir-url"
version = "0.1.0"
requires-python = ">=3.11"
dependencies = []

[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"
"#,
        )?;
        let pkg_dir = project_root.join("demo_dir_url");
        fs::create_dir_all(&pkg_dir)?;
        fs::write(pkg_dir.join("__init__.py"), "")?;

        let snapshot = ProjectSnapshot::read_from(project_root)?;
        let site_dir = project_root.join(".px").join("env").join("site");
        let effects = SystemEffects::new();
        effects.fs().create_dir_all(&site_dir)?;
        write_project_metadata_stub(&snapshot, &site_dir, effects.fs())?;

        let contents =
            fs::read_to_string(site_dir.join("demo_dir_url-0.1.0.dist-info/direct_url.json"))?;
        let payload: Value = serde_json::from_str(&contents)?;
        let url = payload
            .get("url")
            .and_then(Value::as_str)
            .unwrap_or_default();
        assert!(
            url.starts_with("file://"),
            "direct_url.json should contain a file:// URL, got {url}"
        );
        Ok(())
    }

    #[test]
    fn editable_stub_uses_source_version_when_manifest_missing() -> Result<()> {
        let temp = tempdir()?;
        let project_root = temp.path();
        let pyproject = project_root.join("pyproject.toml");
        fs::write(
            &pyproject,
            r#"[project]
name = "dynamic-demo"
dynamic = ["version"]
requires-python = ">=3.11"
dependencies = []

[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"
"#,
        )?;
        let pkg_dir = project_root.join("src/dynamic_demo");
        fs::create_dir_all(&pkg_dir)?;
        fs::write(pkg_dir.join("__init__.py"), "__version__ = '9.9.9'\n")?;

        let snapshot = ProjectSnapshot::read_from(project_root)?;
        let site_dir = project_root.join(".px").join("env").join("site");
        let effects = SystemEffects::new();
        effects.fs().create_dir_all(&site_dir)?;
        write_sitecustomize(&site_dir, None, effects.fs())?;
        write_project_metadata_stub(&snapshot, &site_dir, effects.fs())?;

        let dist = site_dir
            .join("dynamic_demo-9.9.9.dist-info")
            .join("METADATA");
        let metadata = fs::read_to_string(&dist)?;
        assert!(
            metadata.contains("Version: 9.9.9"),
            "metadata should contain source-derived version"
        );
        Ok(())
    }

    #[test]
    fn editable_stub_prefers_version_file_value() -> Result<()> {
        let temp = tempdir()?;
        let project_root = temp.path();
        let pyproject = project_root.join("pyproject.toml");
        fs::write(
            &pyproject,
            r#"[project]
name = "demo"
dynamic = ["version"]
requires-python = ">=3.11"
dependencies = []

[build-system]
requires = ["hatchling", "hatch-vcs"]
build-backend = "hatchling.build"

[tool.hatch.build.hooks.vcs]
version-file = "src/demo/version.py"
"#,
        )?;
        let pkg_dir = project_root.join("src/demo");
        fs::create_dir_all(&pkg_dir)?;
        fs::write(pkg_dir.join("__init__.py"), "")?;
        fs::write(
            pkg_dir.join("version.py"),
            "version = \"9.9.9\"\n__version__ = version\n",
        )?;

        let snapshot = ProjectSnapshot::read_from(project_root)?;
        let site_dir = project_root.join(".px").join("env").join("site");
        let effects = SystemEffects::new();
        effects.fs().create_dir_all(&site_dir)?;
        write_project_metadata_stub(&snapshot, &site_dir, effects.fs())?;

        let metadata = fs::read_to_string(site_dir.join("demo-9.9.9.dist-info").join("METADATA"))?;
        assert!(
            metadata.contains("Version: 9.9.9"),
            "metadata should use version from version-file stub"
        );
        Ok(())
    }

    #[test]
    fn editable_stub_writes_console_scripts() -> Result<()> {
        let temp = tempdir()?;
        let project_root = temp.path();
        let pyproject = project_root.join("pyproject.toml");
        fs::write(
            &pyproject,
            r#"[project]
name = "demo"
dynamic = ["version"]
requires-python = ">=3.11"
dependencies = []

[project.scripts]
tox = "demo.run:main"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"
"#,
        )?;
        let pkg_dir = project_root.join("src/demo");
        fs::create_dir_all(&pkg_dir)?;
        fs::write(pkg_dir.join("__init__.py"), "__version__ = '1.0.0'\n")?;
        fs::write(pkg_dir.join("run.py"), "def main():\n    return 0\n")?;

        let snapshot = ProjectSnapshot::read_from(project_root)?;
        let site_dir = project_root.join(".px").join("env").join("site");
        let effects = SystemEffects::new();
        effects.fs().create_dir_all(&site_dir)?;
        write_project_metadata_stub(&snapshot, &site_dir, effects.fs())?;

        let script = site_dir.join("bin").join("tox");
        assert!(
            script.exists(),
            "console script should be generated for project entry points"
        );
        let contents = fs::read_to_string(script)?;
        assert!(
            contents.contains("demo.run"),
            "entrypoint should import target module"
        );
        Ok(())
    }

    #[test]
    fn editable_stub_derives_hatch_vcs_version_without_version_file() -> Result<()> {
        if Command::new("git").arg("--version").status().is_err() {
            return Ok(());
        }
        let temp = tempdir()?;
        let project_root = temp.path();
        let pyproject = project_root.join("pyproject.toml");
        fs::write(
            &pyproject,
            r#"[project]
name = "demo"
dynamic = ["version"]
requires-python = ">=3.11"
dependencies = []

[build-system]
requires = ["hatchling", "hatch-vcs"]
build-backend = "hatchling.build"

[tool.hatch.version]
source = "vcs"
[tool.hatch.version.raw-options]
local_scheme = "no-local-version"
"#,
        )?;
        let pkg_dir = project_root.join("src/demo");
        fs::create_dir_all(&pkg_dir)?;
        fs::write(pkg_dir.join("__init__.py"), "")?;

        let git_status = Command::new("git")
            .args(["init", "-q"])
            .current_dir(project_root)
            .status()?;
        if !git_status.success() {
            return Ok(());
        }
        Command::new("git")
            .args(["add", "."])
            .current_dir(project_root)
            .status()?;
        Command::new("git")
            .args([
                "-c",
                "user.name=px",
                "-c",
                "user.email=px@example.com",
                "commit",
                "-m",
                "init",
            ])
            .current_dir(project_root)
            .status()?;

        let snapshot = ProjectSnapshot::read_from(project_root)?;
        let site_dir = project_root.join(".px").join("env").join("site");
        let effects = SystemEffects::new();
        effects.fs().create_dir_all(&site_dir)?;
        write_project_metadata_stub(&snapshot, &site_dir, effects.fs())?;

        let metadata = fs::read_to_string(site_dir.join("demo-0.0.0.dist-info").join("METADATA"))?;
        assert!(
            metadata.contains("Version: 0.0.0"),
            "hatch-vcs projects without version-file should derive a numeric version"
        );
        Ok(())
    }

    #[test]
    fn ensure_version_file_populates_missing_file_from_git() -> Result<()> {
        if Command::new("git").arg("--version").status().is_err() {
            return Ok(());
        }
        let temp = tempdir()?;
        let manifest = temp.path().join("pyproject.toml");
        fs::write(
            &manifest,
            r#"[project]
name = "demo"
version = "0.1.0"
requires-python = ">=3.11"

[tool.hatch.build.hooks.vcs]
version-file = "demo/_version.py"
"#,
        )?;
        let demo_dir = temp.path().join("demo");
        fs::create_dir_all(&demo_dir)?;
        fs::write(demo_dir.join("__init__.py"), "")?;

        if Command::new("git").arg("--version").output().is_err() {
            eprintln!("skipping version file test (git not available)");
            return Ok(());
        }

        assert!(
            Command::new("git")
                .arg("init")
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git init failed"
        );
        assert!(
            Command::new("git")
                .args(["config", "user.email", "ci@example.com"])
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git config email failed"
        );
        assert!(
            Command::new("git")
                .args(["config", "user.name", "CI"])
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git config name failed"
        );
        assert!(
            Command::new("git")
                .args(["add", "."])
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git add failed"
        );
        assert!(
            Command::new("git")
                .args(["commit", "-m", "init"])
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git commit failed"
        );

        ensure_version_file(&manifest)?;
        let contents = fs::read_to_string(temp.path().join("demo/_version.py"))?;
        assert!(
            contents.contains("version = \"0.0.0+g"),
            "version file should be derived from git rev"
        );
        assert!(
            contents.contains("__version__ = version"),
            "git stub should alias __version__ to version"
        );
        Ok(())
    }

    #[test]
    fn ensure_version_file_respects_hatch_git_describe_command() -> Result<()> {
        if Command::new("git").arg("--version").status().is_err() {
            return Ok(());
        }
        let temp = tempdir()?;
        let manifest = temp.path().join("pyproject.toml");
        fs::write(
            &manifest,
            r#"[project]
name = "demo"
version = "0.1.0"
requires-python = ">=3.11"

[tool.hatch.version.raw-options]
git_describe_command = ["git", "describe", "--tags", "--dirty", "--long", "--match", "demo-v*"]

[tool.hatch.build.hooks.vcs]
version-file = "demo/_version.py"
"#,
        )?;
        let demo_dir = temp.path().join("demo");
        fs::create_dir_all(&demo_dir)?;
        fs::write(demo_dir.join("__init__.py"), "")?;

        assert!(
            Command::new("git")
                .arg("init")
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git init failed"
        );
        assert!(
            Command::new("git")
                .args(["config", "user.email", "ci@example.com"])
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git config email failed"
        );
        assert!(
            Command::new("git")
                .args(["config", "user.name", "CI"])
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git config name failed"
        );
        assert!(
            Command::new("git")
                .args(["add", "."])
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git add failed"
        );
        assert!(
            Command::new("git")
                .args(["commit", "-m", "init"])
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git commit failed"
        );
        assert!(
            Command::new("git")
                .args(["tag", "demo-v1.0.0"])
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "tag demo-v1.0.0 failed"
        );

        fs::write(demo_dir.join("__init__.py"), "__version__ = '0.1.1'\n")?;
        assert!(
            Command::new("git")
                .args(["add", "."])
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git add second commit failed"
        );
        assert!(
            Command::new("git")
                .args(["commit", "-m", "second"])
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git commit second failed"
        );
        assert!(
            Command::new("git")
                .args(["tag", "other-v9.9.9"])
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "tag other-v9.9.9 failed"
        );

        ensure_version_file(&manifest)?;
        let contents = fs::read_to_string(temp.path().join("demo/_version.py"))?;
        assert!(
            contents.contains("demo-v1.0.0"),
            "custom git_describe_command should prefer matching tags"
        );
        assert!(
            !contents.contains("other-v9.9.9"),
            "custom describe command should ignore non-matching tags"
        );
        Ok(())
    }

    #[test]
    fn ensure_version_file_drops_local_suffix_for_hatch() -> Result<()> {
        if Command::new("git").arg("--version").status().is_err() {
            return Ok(());
        }
        let temp = tempdir()?;
        let manifest = temp.path().join("pyproject.toml");
        fs::write(
            &manifest,
            r#"[project]
name = "demo"
version = "0.1.0"
requires-python = ">=3.11"

[tool.hatch.version.raw-options]
local_scheme = "no-local-version"

[tool.hatch.build.hooks.vcs]
version-file = "demo/_version.py"
"#,
        )?;
        let demo_dir = temp.path().join("demo");
        fs::create_dir_all(&demo_dir)?;
        fs::write(demo_dir.join("__init__.py"), "")?;

        assert!(
            Command::new("git")
                .arg("init")
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git init failed"
        );
        assert!(
            Command::new("git")
                .args(["config", "user.email", "ci@example.com"])
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git config email failed"
        );
        assert!(
            Command::new("git")
                .args(["config", "user.name", "CI"])
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git config name failed"
        );
        assert!(
            Command::new("git")
                .args(["add", "."])
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git add failed"
        );
        assert!(
            Command::new("git")
                .args(["commit", "-m", "init"])
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git commit failed"
        );

        ensure_version_file(&manifest)?;
        let contents = fs::read_to_string(temp.path().join("demo/_version.py"))?;
        assert!(
            contents.contains("version = \"0.0.0\""),
            "no-local-version should strip the git hash suffix when no tags exist"
        );
        assert!(
            !contents.contains('+'),
            "no-local-version should omit local version segments"
        );
        Ok(())
    }

    #[test]
    fn ensure_version_file_falls_back_without_git_metadata() -> Result<()> {
        let temp = tempdir()?;
        let manifest = temp.path().join("pyproject.toml");
        fs::write(
            &manifest,
            r#"[project]
name = "demo"
version = "0.1.0"
requires-python = ">=3.11"

[tool.hatch.build.hooks.vcs]
version-file = "demo/_version.py"
"#,
        )?;
        let demo_dir = temp.path().join("demo");
        fs::create_dir_all(&demo_dir)?;
        fs::write(demo_dir.join("__init__.py"), "")?;

        ensure_version_file(&manifest)?;
        let contents = fs::read_to_string(temp.path().join("demo/_version.py"))?;
        assert!(
            contents.contains("version = \"0.0.0+unknown\""),
            "fallback version should be written when git metadata is missing"
        );
        assert!(
            contents.contains("__version__ = version"),
            "fallback stub should alias __version__ to version"
        );
        Ok(())
    }

    #[test]
    fn ensure_version_file_honors_no_local_without_git_metadata() -> Result<()> {
        let temp = tempdir()?;
        let manifest = temp.path().join("pyproject.toml");
        fs::write(
            &manifest,
            r#"[project]
name = "demo"
version = "0.1.0"
requires-python = ">=3.11"

[tool.hatch.version.raw-options]
local_scheme = "no-local-version"

[tool.hatch.build.hooks.vcs]
version-file = "demo/_version.py"
"#,
        )?;
        let demo_dir = temp.path().join("demo");
        fs::create_dir_all(&demo_dir)?;
        fs::write(demo_dir.join("__init__.py"), "")?;

        ensure_version_file(&manifest)?;
        let contents = fs::read_to_string(temp.path().join("demo/_version.py"))?;
        assert!(
            contents.contains("version = \"0.0.0\""),
            "no-local-version should drop local suffix when git metadata is unavailable"
        );
        assert!(
            !contents.contains('+'),
            "no-local-version fallback should not include local components"
        );
        Ok(())
    }

    #[test]
    fn ensure_version_file_upgrades_hatch_stub_missing_alias() -> Result<()> {
        let temp = tempdir()?;
        let manifest = temp.path().join("pyproject.toml");
        fs::write(
            &manifest,
            r#"[project]
name = "demo"
version = "0.1.0"
requires-python = ">=3.11"

[tool.hatch.build.hooks.vcs]
version-file = "demo/_version.py"
"#,
        )?;
        let demo_dir = temp.path().join("demo");
        fs::create_dir_all(&demo_dir)?;
        fs::write(demo_dir.join("__init__.py"), "")?;
        fs::write(demo_dir.join("_version.py"), "__version__ = \"1.2.3\"\n")?;

        ensure_version_file(&manifest)?;
        let contents = fs::read_to_string(demo_dir.join("_version.py"))?;
        assert!(
            contents.contains("version = \"0.0.0+unknown\""),
            "hatch stub should rewrite missing alias with derived version"
        );
        assert!(
            contents.contains("__version__ = version"),
            "hatch stub should alias __version__ to version"
        );
        assert!(
            contents.contains("__all__ = [\"__version__\", \"version\"]"),
            "hatch stub should export both aliases"
        );
        Ok(())
    }

    #[test]
    fn ensure_version_file_supports_setuptools_scm_write_to() -> Result<()> {
        let temp = tempdir()?;
        let manifest = temp.path().join("pyproject.toml");
        fs::write(
            &manifest,
            r#"[project]
name = "demo"
version = "0.1.0"
requires-python = ">=3.11"

[tool.setuptools_scm]
write_to = "demo/_version.py"
"#,
        )?;
        let demo_dir = temp.path().join("demo");
        fs::create_dir_all(&demo_dir)?;
        fs::write(demo_dir.join("__init__.py"), "")?;

        ensure_version_file(&manifest)?;
        let contents = fs::read_to_string(demo_dir.join("_version.py"))?;
        assert!(
            contents.contains("version = \"0.0.0+unknown\""),
            "setuptools_scm stub should include derived version"
        );
        assert!(
            contents.contains("__version__ = version"),
            "setuptools_scm stub should alias __version__"
        );
        assert!(
            contents.contains("version_tuple = tuple(_v.release)"),
            "setuptools_scm stub should export version_tuple from parsed release"
        );
        Ok(())
    }

    #[test]
    fn ensure_version_file_supports_pdm_write_to() -> Result<()> {
        if Command::new("git").arg("--version").status().is_err() {
            return Ok(());
        }
        let temp = tempdir()?;
        let manifest = temp.path().join("pyproject.toml");
        fs::write(
            &manifest,
            r#"[project]
name = "pdm-demo"
dynamic = ["version"]
requires-python = ">=3.11"

[tool.pdm.version]
write_to = "pdm/VERSION"

[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"
"#,
        )?;
        let pkg_dir = temp.path().join("pdm");
        fs::create_dir_all(&pkg_dir)?;
        fs::write(pkg_dir.join("__init__.py"), "")?;

        assert!(
            Command::new("git")
                .arg("init")
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git init failed"
        );
        assert!(
            Command::new("git")
                .args(["config", "user.email", "ci@example.com"])
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git config email failed"
        );
        assert!(
            Command::new("git")
                .args(["config", "user.name", "CI"])
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git config name failed"
        );
        assert!(
            Command::new("git")
                .args(["add", "."])
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git add failed"
        );
        assert!(
            Command::new("git")
                .args(["commit", "-m", "init"])
                .current_dir(temp.path())
                .output()?
                .status
                .success(),
            "git commit failed"
        );

        ensure_version_file(&manifest)?;
        let contents = fs::read_to_string(pkg_dir.join("VERSION"))?;
        assert!(
            contents.trim().starts_with("0.0.0+g"),
            "pdm VERSION file should be derived from git rev"
        );

        let metadata =
            load_editable_project_metadata(&manifest, SystemEffects::new().fs()).unwrap();
        assert!(
            metadata.version.starts_with("0.0.0+g"),
            "editable metadata should use pdm VERSION contents"
        );
        Ok(())
    }

    #[test]
    fn ensure_version_file_writes_inline_version_stub() -> Result<()> {
        let temp = tempdir()?;
        let manifest = temp.path().join("pyproject.toml");
        fs::write(
            &manifest,
            r#"[project]
name = "demo-pkg"
version = "1.2.3.dev0"
requires-python = ">=3.11"

[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"
"#,
        )?;
        let pkg_dir = temp.path().join("demo_pkg");
        fs::create_dir_all(&pkg_dir)?;
        fs::write(pkg_dir.join("__init__.py"), "")?;
        fs::write(pkg_dir.join("version.pyi"), "version: str\n")?;

        ensure_version_file(&manifest)?;
        let contents = fs::read_to_string(pkg_dir.join("version.py"))?;
        assert!(
            contents.contains("version = \"1.2.3.dev0\""),
            "stub should use manifest version"
        );
        assert!(
            contents.contains("release = False"),
            "dev versions should mark release as False"
        );
        assert!(
            contents.contains("short_version = version.split(\"+\")[0]"),
            "stub should set short_version"
        );
        Ok(())
    }

    #[test]
    fn infers_version_from_versioneer_module() -> Result<()> {
        let temp = tempdir()?;
        let manifest = temp.path().join("pyproject.toml");
        fs::write(
            &manifest,
            r#"[project]
name = "demo-ver"
dynamic = ["version"]
requires-python = ">=3.11"
dependencies = []

[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"
"#,
        )?;
        let pkg_dir = temp.path().join("demo_ver");
        fs::create_dir_all(&pkg_dir)?;
        fs::write(
            pkg_dir.join("__init__.py"),
            "from ._version import get_versions\nv = get_versions()\n__version__ = v.get('closest-tag', v['version'])\n",
        )?;
        fs::write(
            pkg_dir.join("_version.py"),
            "def get_versions():\n    return {'version': '1.2.3+dev', 'closest-tag': 'v1.2.3'}\n",
        )?;

        let metadata =
            load_editable_project_metadata(&manifest, SystemEffects::new().fs()).unwrap();
        assert_eq!(metadata.version, "1.2.3+dev");
        Ok(())
    }

    #[test]
    fn pep440_from_describe_formats_dirty_and_tagged() {
        let version = pep440_from_describe("v1.2.3-4-gabc123").unwrap();
        assert_eq!(version, "1.2.3+4.gabc123");
        let dirty = pep440_from_describe("v0.1.0-0-gdeadbeef-dirty").unwrap();
        assert_eq!(dirty, "0.1.0+0.gdeadbeef.dirty");
    }

    #[test]
    fn pep440_from_describe_handles_tags_with_hyphens() {
        let version = pep440_from_describe("v1.2.3-beta.1-0-gabc123").unwrap();
        assert_eq!(version, "1.2.3-beta.1+0.gabc123");
    }
}
