#![deny(clippy::all, warnings)]

use std::fmt::Write as _;
use std::{
    cmp::Ordering,
    collections::{HashMap, HashSet},
    env, fmt, fs,
    io::{self, IsTerminal, Write},
    path::{Path, PathBuf},
    str::FromStr,
    sync::{
        atomic::{AtomicBool, AtomicUsize, Ordering as AtomicOrdering},
        mpsc, Arc, Mutex, OnceLock,
    },
    thread,
    time::Duration,
};

use self::effects::{Effects, SharedEffects};
use crate::python_sys::{
    detect_interpreter, detect_interpreter_tags, detect_marker_environment, InterpreterTags,
};
use crate::store::{ArtifactRequest, CacheLocation, SdistRequest};
use anyhow::{anyhow, Context, Result};
use pep440_rs::{Operator, VersionSpecifiers};
use pep508_rs::{MarkerEnvironment, Requirement as PepRequirement, VersionOrUrl};
use px_domain::RunOutput;
use px_domain::{
    analyze_lock_diff, autopin_pin_key, autopin_spec_key, canonical_extras, current_project_root,
    detect_lock_drift, discover_project_root, format_specifier, load_lockfile_optional,
    marker_applies, merge_resolved_dependencies, normalize_dist_name, render_lockfile, resolve,
    spec_requires_pin, verify_locked_artifacts, AutopinEntry, InstallOverride, LockSnapshot,
    LockedArtifact, PinSpec, ProjectSnapshot, ResolvedDependency, ResolverRequest, ResolverTags,
};
use reqwest::{blocking::Client, StatusCode};
use serde::{Deserialize, Serialize};
use serde_json::{json, Value};
use sha2::{Digest, Sha256};
use toml_edit::{Array, DocumentMut, Item, Table, Value as TomlValue};

use crate::pypi::{PypiFile, PypiReleaseResponse};
use crate::traceback::{analyze_python_traceback, TracebackContext};

mod diagnostics;
mod python_sys;
mod store;

mod distribution;
mod effects;
mod fmt_runner;
mod migration;
mod project;
mod pypi;
mod python_build;
mod python_cli;
mod run;
mod runtime_manager;
mod tools;
mod traceback;

pub use diagnostics::commands as diag_commands;
pub use effects::SystemEffects;

const PYPI_BASE_URL: &str = "https://pypi.org/pypi";
const PX_VERSION: &str = env!("CARGO_PKG_VERSION");
const SITE_CUSTOMIZE: &str = r#"# Auto-generated by px. Do not edit.
import os
import sys
import sysconfig

def _stdlib_prefixes():
    prefixes = set()
    for key in ("stdlib", "platstdlib"):
        path = sysconfig.get_path(key)
        if path:
            prefixes.add(os.path.normpath(path))
    for attr in ("base_prefix", "base_exec_prefix", "exec_prefix"):
        value = getattr(sys, attr, None)
        if value:
            prefixes.add(os.path.normpath(value))
    return prefixes

_STD_PREFIXES = _stdlib_prefixes()
_ALLOWED = [p for p in os.environ.get("PX_ALLOWED_PATHS", "").split(os.pathsep) if p]

def _allow(path):
    if not path:
        return False
    norm = os.path.normpath(path)
    if "site-packages" in norm or "dist-packages" in norm:
        return False
    for prefix in _STD_PREFIXES:
        if norm == prefix or norm.startswith(prefix + os.sep):
            return True
    return False

_new_path = []
_seen = set()

def _push(path):
    if path in _seen:
        return
    _seen.add(path)
    _new_path.append(path)

if sys.path:
    _push(sys.path[0])

for path in _ALLOWED:
    _push(path)

for path in sys.path:
    if _allow(path):
        _push(path)

sys.path[:] = _new_path
"#;

type ManifestSnapshot = ProjectSnapshot;

#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct GlobalOptions {
    pub quiet: bool,
    pub verbose: u8,
    pub trace: bool,
    pub json: bool,
    pub config: Option<String>,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "kebab-case")]
pub enum CommandGroup {
    Init,
    Add,
    Remove,
    Sync,
    Update,
    Run,
    Test,
    Fmt,
    Build,
    Publish,
    Migrate,
    Status,
    Why,
    Tool,
    Python,
}

impl fmt::Display for CommandGroup {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        let name = match self {
            CommandGroup::Init => "init",
            CommandGroup::Add => "add",
            CommandGroup::Remove => "remove",
            CommandGroup::Sync => "sync",
            CommandGroup::Update => "update",
            CommandGroup::Run => "run",
            CommandGroup::Test => "test",
            CommandGroup::Fmt => "fmt",
            CommandGroup::Build => "build",
            CommandGroup::Publish => "publish",
            CommandGroup::Migrate => "migrate",
            CommandGroup::Status => "status",
            CommandGroup::Why => "why",
            CommandGroup::Tool => "tool",
            CommandGroup::Python => "python",
        };
        f.write_str(name)
    }
}

#[derive(Clone, Copy, Debug)]
pub struct CommandInfo {
    pub group: CommandGroup,
    pub name: &'static str,
}

impl CommandInfo {
    #[must_use]
    pub const fn new(group: CommandGroup, name: &'static str) -> Self {
        Self { group, name }
    }
}

#[derive(Debug, Clone)]
struct EnvSnapshot {
    vars: HashMap<String, String>,
}

impl EnvSnapshot {
    fn capture() -> Self {
        Self {
            vars: env::vars().collect(),
        }
    }

    fn flag_is_enabled(&self, key: &str) -> bool {
        matches!(self.vars.get(key).map(String::as_str), Some("1"))
    }

    fn var(&self, key: &str) -> Option<&str> {
        self.vars.get(key).map(String::as_str)
    }

    fn contains(&self, key: &str) -> bool {
        self.vars.contains_key(key)
    }

    #[cfg(test)]
    fn testing(pairs: &[(&str, &str)]) -> Self {
        let vars = pairs
            .iter()
            .map(|(k, v)| ((*k).to_string(), (*v).to_string()))
            .collect();
        Self { vars }
    }
}

#[derive(Debug)]
pub struct Config {
    cache: CacheConfig,
    network: NetworkConfig,
    resolver: ResolverConfig,
    test: TestConfig,
    publish: PublishConfig,
}

impl Config {
    /// Builds a configuration snapshot from the current process environment.
    ///
    /// # Errors
    /// Returns an error if cache paths cannot be resolved or inspected.
    pub fn from_env(effects: &dyn Effects) -> Result<Self> {
        let snapshot = EnvSnapshot::capture();
        Self::from_snapshot(&snapshot, effects.cache())
    }

    fn from_snapshot(
        snapshot: &EnvSnapshot,
        cache_store: &dyn effects::CacheStore,
    ) -> Result<Self> {
        Ok(Self {
            cache: CacheConfig {
                store: cache_store.resolve_store_path()?,
            },
            network: NetworkConfig {
                online: snapshot.flag_is_enabled("PX_ONLINE"),
            },
            resolver: ResolverConfig {
                enabled: match snapshot.var("PX_RESOLVER") {
                    Some(value) => value == "1",
                    None => true,
                },
                force_sdist: snapshot.flag_is_enabled("PX_FORCE_SDIST"),
            },
            test: TestConfig {
                fallback_builtin: snapshot.flag_is_enabled("PX_TEST_FALLBACK_STD"),
                skip_tests_flag: snapshot.var("PX_SKIP_TESTS").map(ToOwned::to_owned),
            },
            publish: PublishConfig {
                default_token_env: "PX_PUBLISH_TOKEN",
            },
        })
    }

    #[must_use]
    pub fn cache(&self) -> &CacheConfig {
        &self.cache
    }

    #[must_use]
    pub fn network(&self) -> &NetworkConfig {
        &self.network
    }

    #[must_use]
    pub fn resolver(&self) -> &ResolverConfig {
        &self.resolver
    }

    #[must_use]
    pub fn test(&self) -> &TestConfig {
        &self.test
    }

    #[must_use]
    pub fn publish(&self) -> &PublishConfig {
        &self.publish
    }
}

#[derive(Debug)]
pub struct CacheConfig {
    pub store: CacheLocation,
}

#[derive(Debug, Clone, Copy)]
pub struct NetworkConfig {
    pub online: bool,
}

#[derive(Debug, Clone, Copy)]
pub struct ResolverConfig {
    pub enabled: bool,
    pub force_sdist: bool,
}

#[derive(Debug, Clone)]
pub struct TestConfig {
    pub fallback_builtin: bool,
    pub skip_tests_flag: Option<String>,
}

#[derive(Debug, Clone, Copy)]
pub struct PublishConfig {
    pub default_token_env: &'static str,
}

pub struct CommandContext<'a> {
    pub global: &'a GlobalOptions,
    env: EnvSnapshot,
    config: Config,
    project_root: OnceLock<PathBuf>,
    effects: SharedEffects,
}

impl<'a> CommandContext<'a> {
    /// Creates a new command context with the provided global options.
    ///
    /// # Errors
    /// Returns an error if the environment snapshot or configuration cannot be prepared.
    pub fn new(global: &'a GlobalOptions, effects: SharedEffects) -> Result<Self> {
        let env = EnvSnapshot::capture();
        let config = Config::from_snapshot(&env, effects.cache())?;
        Ok(Self {
            global,
            env,
            config,
            project_root: OnceLock::new(),
            effects,
        })
    }

    pub fn effects(&self) -> &dyn Effects {
        self.effects.as_ref()
    }

    pub fn shared_effects(&self) -> SharedEffects {
        self.effects.clone()
    }

    pub fn cache(&self) -> &CacheLocation {
        &self.config.cache.store
    }

    pub fn is_online(&self) -> bool {
        self.config.network.online
    }

    pub fn fs(&self) -> &dyn effects::FileSystem {
        self.effects.fs()
    }

    pub fn python_runtime(&self) -> &dyn effects::PythonRuntime {
        self.effects.python()
    }

    pub fn git(&self) -> &dyn effects::GitClient {
        self.effects.git()
    }

    pub fn cache_store(&self) -> &dyn effects::CacheStore {
        self.effects.cache()
    }

    pub fn pypi(&self) -> &dyn effects::PypiClient {
        self.effects.pypi()
    }

    /// Detects the marker environment for PEP 508 resolution.
    ///
    /// # Errors
    /// Returns an error if interpreter detection fails.
    pub fn marker_environment(&self) -> Result<MarkerEnvironment> {
        let python = self.python_runtime().detect_interpreter()?;
        let resolver_env = detect_marker_environment(&python)?;
        resolver_env.to_marker_environment()
    }

    /// Resolves the current project's root directory.
    ///
    /// # Errors
    /// Returns an error if the working directory cannot be inspected.
    pub fn project_root(&self) -> Result<PathBuf> {
        if let Some(path) = self.project_root.get() {
            Ok(path.clone())
        } else {
            let path = current_project_root()?;
            let _ = self.project_root.set(path.clone());
            Ok(path)
        }
    }

    pub fn config(&self) -> &Config {
        &self.config
    }

    pub fn env_contains(&self, key: &str) -> bool {
        self.env.contains(key)
    }

    pub fn env_flag_enabled(&self, key: &str) -> bool {
        self.env.flag_is_enabled(key)
    }
}

pub trait CommandHandler<R> {
    /// Executes a command handler within the provided context.
    ///
    /// # Errors
    /// Returns an error if command execution fails unexpectedly.
    fn handle(&self, ctx: &CommandContext, request: R) -> Result<ExecutionOutcome>;
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExecutionOutcome {
    pub status: CommandStatus,
    pub message: String,
    #[serde(default)]
    pub details: Value,
}

impl ExecutionOutcome {
    pub fn success(message: impl Into<String>, details: Value) -> Self {
        Self {
            status: CommandStatus::Ok,
            message: message.into(),
            details,
        }
    }

    pub fn failure(message: impl Into<String>, details: Value) -> Self {
        Self {
            status: CommandStatus::Failure,
            message: message.into(),
            details,
        }
    }

    pub fn user_error(message: impl Into<String>, details: Value) -> Self {
        Self {
            status: CommandStatus::UserError,
            message: message.into(),
            details,
        }
    }
}

#[derive(thiserror::Error, Debug)]
#[error("{message}")]
pub struct InstallUserError {
    message: String,
    details: Value,
}

impl InstallUserError {
    fn new(message: impl Into<String>, details: Value) -> Self {
        Self {
            message: message.into(),
            details,
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum CommandStatus {
    Ok,
    UserError,
    Failure,
}

fn progress_enabled() -> bool {
    match env::var("PX_PROGRESS") {
        Ok(value) => value != "0",
        Err(_) => io::stderr().is_terminal(),
    }
}

struct ProgressReporter {
    current: Arc<AtomicUsize>,
    stop: Option<Arc<AtomicBool>>,
    handle: Option<thread::JoinHandle<()>>,
    enabled: bool,
}

impl ProgressReporter {
    fn spinner(label: impl Into<String>) -> Self {
        Self::start(label, None)
    }

    fn bar(label: impl Into<String>, total: usize) -> Self {
        if total == 0 {
            return Self::spinner(label);
        }
        Self::start(label, Some(total))
    }

    fn start(label: impl Into<String>, total: Option<usize>) -> Self {
        let label = label.into();
        if !progress_enabled() {
            return Self {
                current: Arc::new(AtomicUsize::new(0)),
                stop: None,
                handle: None,
                enabled: false,
            };
        }

        let stop = Arc::new(AtomicBool::new(false));
        let current = Arc::new(AtomicUsize::new(0));
        let thread_label = label.clone();
        let thread_total = total;
        let thread_stop = Arc::clone(&stop);
        let thread_current = Arc::clone(&current);
        let handle = thread::spawn(move || {
            ProgressReporter::run(&thread_label, thread_total, &thread_current, &thread_stop);
        });

        Self {
            current,
            stop: Some(stop),
            handle: Some(handle),
            enabled: true,
        }
    }

    fn increment(&self) {
        if self.enabled {
            self.current.fetch_add(1, AtomicOrdering::Relaxed);
        }
    }

    fn finish(mut self, message: impl Into<String>) {
        if self.enabled {
            if let Some(stop) = self.stop.take() {
                stop.store(true, AtomicOrdering::Relaxed);
            }
            if let Some(handle) = self.handle.take() {
                let _ = handle.join();
            }
            let _ = io::stderr().write_all(b"\r\x1b[2K");
            let _ = io::stderr().flush();
        }
        eprintln!("px ▸ {}", message.into());
    }

    fn run(label: &str, total: Option<usize>, current: &Arc<AtomicUsize>, stop: &Arc<AtomicBool>) {
        const FRAMES: [&str; 10] = ["⠋", "⠙", "⠹", "⠸", "⠼", "⠴", "⠦", "⠧", "⠇", "⠏"];
        let mut idx = 0;
        while !stop.load(AtomicOrdering::Relaxed) {
            let frame = FRAMES[idx % FRAMES.len()];
            idx += 1;
            let line = if let Some(total) = total {
                let current = current.load(AtomicOrdering::Relaxed).min(total);
                format!("\r\x1b[2Kpx ▸ {label} [{current}/{total}] {frame}")
            } else {
                format!("\r\x1b[2Kpx ▸ {label} {frame}")
            };
            let _ = io::stderr().write_all(line.as_bytes());
            let _ = io::stderr().flush();
            thread::sleep(Duration::from_millis(80));
        }
    }
}

fn download_concurrency(total: usize) -> usize {
    let requested = env::var("PX_DOWNLOADS")
        .ok()
        .and_then(|value| value.parse::<usize>().ok());
    let available = thread::available_parallelism()
        .map(std::num::NonZeroUsize::get)
        .unwrap_or(4)
        .max(1);
    let max_workers = requested.unwrap_or(available).clamp(1, 16);
    max_workers.min(total.max(1))
}

impl Drop for ProgressReporter {
    fn drop(&mut self) {
        if self.enabled {
            if let Some(stop) = self.stop.take() {
                stop.store(true, AtomicOrdering::Relaxed);
            }
            if let Some(handle) = self.handle.take() {
                let _ = handle.join();
            }
            let _ = io::stderr().write_all(b"\r\x1b[2K");
            let _ = io::stderr().flush();
        }
    }
}

pub use distribution::{build_project, publish_project, BuildRequest, PublishRequest};
pub use fmt_runner::{run_fmt, FmtRequest};
pub use migration::{
    migrate, AutopinPreference, LockBehavior, MigrateRequest, MigrationMode, WorkspacePolicy,
};
pub use project::{
    project_add, project_init, project_remove, project_status, project_sync, project_update,
    project_why, ProjectAddRequest, ProjectInitRequest, ProjectRemoveRequest, ProjectSyncRequest,
    ProjectUpdateRequest, ProjectWhyRequest,
};
pub use python_cli::{
    python_info, python_install, python_list, python_use, PythonInfoRequest, PythonInstallRequest,
    PythonListRequest, PythonUseRequest,
};
pub use run::{run_project, test_project, RunRequest, TestRequest};
pub use tools::{
    tool_install, tool_list, tool_remove, tool_run, tool_upgrade, ToolInstallRequest,
    ToolListRequest, ToolRemoveRequest, ToolRunRequest, ToolUpgradeRequest,
};

pub const MISSING_PROJECT_MESSAGE: &str =
    "No px project found. Run `px init` in your project directory first.";
pub const MISSING_PROJECT_HINT: &str = "Run `px init` in your project directory first.";

pub(crate) struct InstallOutcome {
    state: InstallState,
    lockfile: String,
    drift: Vec<String>,
    verified: bool,
}

#[derive(Clone, Copy, Debug, PartialEq)]
pub(crate) enum InstallState {
    Installed,
    UpToDate,
    Drift,
    MissingLock,
}

pub(crate) fn lock_is_fresh(snapshot: &ManifestSnapshot) -> Result<bool> {
    match load_lockfile_optional(&snapshot.lock_path)? {
        Some(lock) => {
            if let Some(fingerprint) = &lock.manifest_fingerprint {
                Ok(fingerprint == &snapshot.manifest_fingerprint)
            } else {
                Ok(detect_lock_drift(snapshot, &lock, None).is_empty())
            }
        }
        None => Ok(false),
    }
}

pub(crate) fn relative_path_str(path: &Path, root: &Path) -> String {
    path.strip_prefix(root)
        .unwrap_or(path)
        .display()
        .to_string()
}

pub(crate) fn manifest_snapshot() -> Result<ManifestSnapshot> {
    ProjectSnapshot::read_current()
}

pub(crate) fn manifest_snapshot_at(root: &Path) -> Result<ManifestSnapshot> {
    ProjectSnapshot::read_from(root)
}

pub(crate) fn install_snapshot(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
    frozen: bool,
    override_pins: Option<&InstallOverride>,
) -> Result<InstallOutcome> {
    let lockfile = snapshot.lock_path.display().to_string();
    let _ = prepare_project_runtime(snapshot)?;

    if frozen {
        return verify_lock(snapshot);
    }

    if lock_is_fresh(snapshot)? {
        Ok(InstallOutcome {
            state: InstallState::UpToDate,
            lockfile,
            drift: Vec::new(),
            verified: false,
        })
    } else {
        if let Some(parent) = snapshot.lock_path.parent() {
            fs::create_dir_all(parent)?;
        }
        let mut dependencies = if let Some(override_data) = override_pins {
            override_data.dependencies.clone()
        } else {
            snapshot.dependencies.clone()
        };
        let marker_env = ctx.marker_environment()?;
        let mut resolved_override = None;
        if override_pins.is_none() && ctx.config().resolver.enabled {
            let resolved = resolve_dependencies(ctx, snapshot)?;
            if !resolved.specs.is_empty() {
                dependencies =
                    merge_resolved_dependencies(&dependencies, &resolved.specs, &marker_env);
                persist_resolved_dependencies(snapshot, &dependencies)?;
            }
            resolved_override = Some(resolved.pins);
        }
        let pins = if let Some(override_data) = override_pins {
            let mut pins: Vec<PinSpec> = override_data
                .pins
                .iter()
                .filter(|pin| marker_applies(&pin.specifier, &marker_env))
                .cloned()
                .collect();
            if pins.is_empty() {
                for spec in &dependencies {
                    if !marker_applies(spec, &marker_env) {
                        continue;
                    }
                    pins.push(parse_exact_pin(spec)?);
                }
            }
            pins
        } else {
            match resolved_override {
                Some(pins) => pins,
                None => ensure_exact_pins(&marker_env, &dependencies)?,
            }
        };
        let resolved = resolve_pins(ctx, &pins, ctx.config().resolver.force_sdist)?;
        let contents = render_lockfile(snapshot, &resolved, PX_VERSION)?;
        fs::write(&snapshot.lock_path, contents)?;
        Ok(InstallOutcome {
            state: InstallState::Installed,
            lockfile,
            drift: Vec::new(),
            verified: false,
        })
    }
}

pub(crate) fn refresh_project_site(
    snapshot: &ManifestSnapshot,
    ctx: &CommandContext,
) -> Result<()> {
    let _ = prepare_project_runtime(snapshot)?;
    let lock = load_lockfile_optional(&snapshot.lock_path)?.ok_or_else(|| {
        anyhow!(
            "px sync: lockfile missing at {}",
            snapshot.lock_path.display()
        )
    })?;
    let runtime = detect_runtime_metadata(ctx, snapshot)?;
    let lock_hash = match lock.lock_id.clone() {
        Some(value) => value,
        None => compute_lock_hash(&snapshot.lock_path)?,
    };
    let env_id = compute_environment_id(&lock_hash, &runtime);
    let env_root = snapshot.root.join(".px").join("envs").join(&env_id);
    ctx.fs().create_dir_all(&env_root)?;
    let site_dir = env_root.join("site");
    ctx.fs().create_dir_all(&site_dir)?;
    materialize_project_site(&site_dir, &lock, ctx.fs())?;
    let canonical_site = ctx.fs().canonicalize(&site_dir).unwrap_or(site_dir.clone());
    let env_state = StoredEnvironment {
        id: env_id,
        lock_hash,
        platform: runtime.platform,
        site_packages: canonical_site.display().to_string(),
        python: StoredPython {
            path: runtime.path,
            version: runtime.version,
        },
    };
    persist_project_state(ctx.fs(), &snapshot.root, env_state)
}

fn materialize_project_site(
    site_dir: &Path,
    lock: &LockSnapshot,
    fs: &dyn effects::FileSystem,
) -> Result<()> {
    fs.create_dir_all(site_dir)?;
    let pth_path = site_dir.join("px.pth");

    let mut entries = Vec::new();
    for dep in &lock.resolved {
        let Some(artifact) = &dep.artifact else {
            continue;
        };
        if artifact.cached_path.is_empty() {
            continue;
        }
        let wheel_path = PathBuf::from(&artifact.cached_path);
        if !wheel_path.exists() {
            continue;
        }
        let dist_path = wheel_path.with_extension("dist");
        let entry_path = if dist_path.exists() {
            dist_path
        } else {
            wheel_path
        };
        let canonical = entry_path.canonicalize().unwrap_or(entry_path);
        entries.push(canonical);
    }

    entries.sort();
    entries.dedup();

    let mut contents = entries
        .iter()
        .map(|path| path.display().to_string())
        .collect::<Vec<_>>()
        .join("\n");
    if !contents.is_empty() {
        contents.push('\n');
    }
    fs.write(&pth_path, contents.as_bytes())?;
    write_sitecustomize(site_dir, fs)?;
    Ok(())
}

fn write_sitecustomize(site_dir: &Path, fs: &dyn effects::FileSystem) -> Result<()> {
    let path = site_dir.join("sitecustomize.py");
    fs.write(&path, SITE_CUSTOMIZE.as_bytes())
}

fn persist_project_state(
    fs: &dyn effects::FileSystem,
    project_root: &Path,
    env: StoredEnvironment,
) -> Result<()> {
    let mut state = load_project_state(fs, project_root);
    state.current_env = Some(env);
    write_project_state(fs, project_root, &state)
}

pub(crate) fn load_project_state(
    fs: &dyn effects::FileSystem,
    project_root: &Path,
) -> ProjectState {
    let path = project_root.join(".px").join("state.json");
    match fs.read_to_string(&path) {
        Ok(contents) => serde_json::from_str(&contents).unwrap_or_default(),
        Err(_) => ProjectState::default(),
    }
}

fn write_project_state(
    fs: &dyn effects::FileSystem,
    project_root: &Path,
    state: &ProjectState,
) -> Result<()> {
    let path = project_root.join(".px").join("state.json");
    let mut contents = serde_json::to_vec_pretty(state)?;
    contents.push(b'\n');
    fs.write(&path, &contents)
}

fn resolve_project_site(fs: &dyn effects::FileSystem, project_root: &Path) -> Option<PathBuf> {
    let state = load_project_state(fs, project_root);
    if let Some(env) = state.current_env {
        let path = PathBuf::from(env.site_packages);
        if path.exists() {
            return Some(path);
        }
    }
    let fallback = project_root.join(".px").join("site");
    if fallback.exists() {
        Some(fallback)
    } else {
        None
    }
}

#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub(crate) struct ProjectState {
    #[serde(default)]
    current_env: Option<StoredEnvironment>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub(crate) struct StoredEnvironment {
    id: String,
    lock_hash: String,
    platform: String,
    site_packages: String,
    python: StoredPython,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub(crate) struct StoredPython {
    path: String,
    version: String,
}

#[derive(Clone, Debug)]
struct RuntimeMetadata {
    path: String,
    version: String,
    platform: String,
}

fn prepare_project_runtime(
    snapshot: &ManifestSnapshot,
) -> Result<runtime_manager::RuntimeSelection> {
    let selection = runtime_manager::resolve_runtime(
        snapshot.python_override.as_deref(),
        &snapshot.python_requirement,
    )
    .map_err(|err| {
        InstallUserError::new(
            "python runtime unavailable",
            json!({
                "hint": err.to_string(),
                "reason": "missing_runtime",
            }),
        )
    })?;
    env::set_var("PX_RUNTIME_PYTHON", &selection.record.path);
    Ok(selection)
}

fn detect_runtime_metadata(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
) -> Result<RuntimeMetadata> {
    let path = ctx.python_runtime().detect_interpreter()?;
    let version = probe_python_version(ctx, snapshot, &path)?;
    let tags = detect_interpreter_tags(&path)?;
    let platform = tags
        .platform
        .first()
        .cloned()
        .unwrap_or_else(|| "any".to_string());
    Ok(RuntimeMetadata {
        path,
        version,
        platform,
    })
}

fn compute_environment_id(lock_hash: &str, runtime: &RuntimeMetadata) -> String {
    let mut hasher = Sha256::new();
    hasher.update(lock_hash.as_bytes());
    hasher.update(runtime.version.as_bytes());
    hasher.update(runtime.platform.as_bytes());
    hasher.update(runtime.path.as_bytes());
    let digest = format!("{:x}", hasher.finalize());
    let short = &digest[..digest.len().min(16)];
    format!("env-{short}")
}

pub(crate) fn compute_lock_hash(lock_path: &Path) -> Result<String> {
    let contents = fs::read(lock_path)?;
    let mut hasher = Sha256::new();
    hasher.update(contents);
    Ok(format!("{:x}", hasher.finalize()))
}

fn probe_python_version(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
    python: &str,
) -> Result<String> {
    const SCRIPT: &str =
        "import json, platform; print(json.dumps({'version': platform.python_version()}))";
    let args = vec!["-c".to_string(), SCRIPT.to_string()];
    let output = ctx
        .python_runtime()
        .run_command(python, &args, &[], &snapshot.root)?;
    if output.code != 0 {
        return Err(anyhow!("python exited with {}", output.code));
    }
    let payload: RuntimeProbe =
        serde_json::from_str(output.stdout.trim()).context("invalid runtime probe payload")?;
    Ok(payload.version)
}

#[derive(Deserialize)]
struct RuntimeProbe {
    version: String,
}

fn verify_lock(snapshot: &ManifestSnapshot) -> Result<InstallOutcome> {
    let lockfile = snapshot.lock_path.display().to_string();
    match load_lockfile_optional(&snapshot.lock_path)? {
        Some(lock) => {
            let report = analyze_lock_diff(snapshot, &lock, None);
            let mut drift = report.to_messages();
            if drift.is_empty() {
                drift = verify_locked_artifacts(&lock);
            }
            if drift.is_empty() {
                Ok(InstallOutcome {
                    state: InstallState::UpToDate,
                    lockfile,
                    drift,
                    verified: true,
                })
            } else {
                Ok(InstallOutcome {
                    state: InstallState::Drift,
                    lockfile,
                    drift,
                    verified: true,
                })
            }
        }
        None => Ok(InstallOutcome {
            state: InstallState::MissingLock,
            lockfile,
            drift: Vec::new(),
            verified: true,
        }),
    }
}

struct ResolvedSpecOutput {
    specs: Vec<String>,
    pins: Vec<PinSpec>,
}

fn resolve_dependencies(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
) -> Result<ResolvedSpecOutput> {
    resolve_dependencies_with_effects(ctx.effects(), snapshot)
}

fn resolve_dependencies_with_effects(
    effects: &dyn Effects,
    snapshot: &ManifestSnapshot,
) -> Result<ResolvedSpecOutput> {
    let spinner = ProgressReporter::spinner("Resolving dependencies");
    let python = effects.python().detect_interpreter()?;
    let tags = detect_interpreter_tags(&python)?;
    let resolver_env = detect_marker_environment(&python)?;
    let marker_env = resolver_env
        .to_marker_environment()
        .map_err(|err| anyhow!("invalid marker environment: {err}"))?;
    let request = ResolverRequest {
        project: snapshot.name.clone(),
        requirements: snapshot.dependencies.clone(),
        tags: ResolverTags {
            python: tags.python.clone(),
            abi: tags.abi.clone(),
            platform: tags.platform.clone(),
        },
        env: resolver_env.clone(),
        indexes: resolver_indexes(),
    };
    let resolved = resolve(&request).map_err(|err| {
        InstallUserError::new(
            "dependency resolution failed",
            resolver_failure_details(&err),
        )
    })?;
    let mut pins = Vec::new();
    let mut autopin_lookup = HashMap::new();
    let mut seen = HashSet::new();
    for spec in resolved {
        let formatted = format_specifier(
            &spec.normalized,
            &spec.extras,
            &spec.selected_version,
            spec.marker.as_deref(),
        );
        let pin = PinSpec {
            name: spec.name,
            specifier: formatted.clone(),
            version: spec.selected_version,
            normalized: spec.normalized,
            extras: spec.extras,
            marker: spec.marker,
            direct: spec.direct,
            requires: spec.requires,
        };
        autopin_lookup.insert(autopin_pin_key(&pin), formatted);
        if seen.insert(pin.normalized.clone()) {
            pins.push(pin);
        }
    }

    let mut autopin_specs = Vec::new();
    for spec in &snapshot.dependencies {
        if spec_requires_pin(spec) && marker_applies(spec, &marker_env) {
            let key = autopin_spec_key(spec);
            if let Some(pinned) = autopin_lookup.get(&key) {
                autopin_specs.push(pinned.clone());
            } else {
                autopin_specs.push(spec.clone());
            }
        }
    }
    spinner.finish(format!("Resolved {} dependencies", pins.len()));
    Ok(ResolvedSpecOutput {
        specs: autopin_specs,
        pins,
    })
}

fn resolver_indexes() -> Vec<String> {
    let mut indexes = Vec::new();
    if let Ok(primary) = env::var("PX_INDEX_URL")
        .or_else(|_| env::var("PIP_INDEX_URL"))
        .map(|value| value.trim().to_string())
    {
        if !primary.is_empty() {
            indexes.push(normalize_index_url(&primary));
        }
    }
    if let Ok(extra) = env::var("PIP_EXTRA_INDEX_URL") {
        for entry in extra.split_whitespace() {
            let trimmed = entry.trim();
            if !trimmed.is_empty() {
                indexes.push(normalize_index_url(trimmed));
            }
        }
    }
    if indexes.is_empty() {
        indexes.push("https://pypi.org/pypi".to_string());
    }
    indexes
}

fn normalize_index_url(raw: &str) -> String {
    let mut url = raw.trim_end_matches('/').to_string();
    if !url.ends_with("/pypi") && !url.ends_with("/json") {
        url.push_str("/pypi");
    }
    url
}

fn resolver_failure_details(err: &anyhow::Error) -> Value {
    let message = err.to_string();
    let issue = message.clone();
    let details = json!({
        "reason": "resolve_failed",
        "issues": [issue],
        "hint": "Inspect dependency constraints and rerun `px sync`.",
        "code": diag_commands::SYNC,
    });
    if let Some(req) = extract_quoted_requirement(&message) {
        if message.contains("unable to resolve") {
            return json!({
                "reason": "resolve_no_match",
                "issues": [issue],
                "requirement": req,
                "hint": format!("Relax or remove `{}` in pyproject.toml, then rerun `px sync`.", req),
                "code": diag_commands::SYNC,
            });
        }
        if message.contains("failed to parse requirement")
            || message.contains("failed to parse specifiers")
        {
            return json!({
                "reason": "invalid_requirement",
                "issues": [issue],
                "requirement": req,
                "hint": format!("Fix `{}` to a valid PEP 508 requirement, then rerun `px sync`.", req),
                "code": diag_commands::SYNC,
            });
        }
    }
    if message.contains("failed to query PyPI") || message.contains("PyPI error") {
        return json!({
            "reason": "pypi_unreachable",
            "issues": [issue],
            "hint": "Check your network connection (PX_ONLINE=1) and rerun `px sync`.",
            "code": diag_commands::SYNC,
        });
    }
    details
}

fn extract_quoted_requirement(message: &str) -> Option<String> {
    let start = message.find('`')?;
    let rest = &message[start + 1..];
    let end = rest.find('`')?;
    Some(rest[..end].to_string())
}

fn persist_resolved_dependencies(snapshot: &ManifestSnapshot, specs: &[String]) -> Result<()> {
    let contents = fs::read_to_string(&snapshot.manifest_path)?;
    let mut doc: DocumentMut = contents.parse()?;
    write_dependencies(&mut doc, specs)?;
    fs::write(&snapshot.manifest_path, doc.to_string())?;
    Ok(())
}

fn ensure_exact_pins(marker_env: &MarkerEnvironment, specs: &[String]) -> Result<Vec<PinSpec>> {
    let mut pins = Vec::new();
    for spec in specs {
        if !marker_applies(spec, marker_env) {
            continue;
        }
        pins.push(parse_exact_pin(spec)?);
    }
    Ok(pins)
}

fn parse_exact_pin(spec: &str) -> Result<PinSpec> {
    let trimmed_raw = spec.trim();
    let trimmed = strip_wrapping_quotes(trimmed_raw);
    if trimmed.is_empty() {
        return Err(InstallUserError::new(
            "dependency specifier cannot be empty",
            json!({ "specifier": spec }),
        )
        .into());
    }

    let requirement = PepRequirement::from_str(trimmed).map_err(|err| {
        InstallUserError::new(
            format!("invalid requirement `{trimmed}`: {err}"),
            json!({ "specifier": trimmed }),
        )
    })?;

    let name = dependency_name(trimmed);
    if name.is_empty() {
        return Err(InstallUserError::new(
            "dependency name missing before `==`",
            json!({ "specifier": trimmed }),
        )
        .into());
    }

    let version_spec = match requirement.version_or_url.as_ref() {
        Some(VersionOrUrl::VersionSpecifier(specifiers)) => specifiers.to_string(),
        Some(VersionOrUrl::Url(_)) => {
            return Err(InstallUserError::new(
                "URL requirements are not supported in pinned installs",
                json!({ "specifier": trimmed }),
            )
            .into())
        }
        None => {
            return Err(InstallUserError::new(
                format!("px sync requires `name==version`; `{trimmed}` is not pinned"),
                json!({ "specifier": trimmed }),
            )
            .into())
        }
    };
    let parsed = VersionSpecifiers::from_str(&version_spec).map_err(|_| {
        InstallUserError::new(
            format!("px sync requires `name==version`; `{trimmed}` is not pinned"),
            json!({ "specifier": trimmed }),
        )
    })?;
    let mut iter = parsed.iter();
    let Some(first) = iter.next() else {
        return Err(InstallUserError::new(
            format!("px sync requires `name==version`; `{trimmed}` is not pinned"),
            json!({ "specifier": trimmed }),
        )
        .into());
    };
    if iter.next().is_some() || !matches!(first.operator(), Operator::Equal | Operator::ExactEqual)
    {
        return Err(InstallUserError::new(
            format!("px sync requires `name==version`; `{trimmed}` is not pinned"),
            json!({ "specifier": trimmed }),
        )
        .into());
    }
    let version_str = first.version().to_string();

    let extras = canonical_extras(
        &requirement
            .extras
            .iter()
            .map(ToString::to_string)
            .collect::<Vec<_>>(),
    );
    let marker = requirement.marker.as_ref().map(ToString::to_string);
    let normalized = normalize_dist_name(&name);
    Ok(PinSpec {
        name,
        specifier: format_specifier(&normalized, &extras, &version_str, marker.as_deref()),
        version: version_str,
        normalized,
        extras,
        marker,
        direct: true,
        requires: Vec::new(),
    })
}

fn resolve_pins(
    ctx: &CommandContext,
    pins: &[PinSpec],
    force_sdist: bool,
) -> Result<Vec<ResolvedDependency>> {
    if pins.is_empty() {
        return Ok(Vec::new());
    }

    let python = detect_interpreter()?;
    let tags = Arc::new(detect_interpreter_tags(&python)?);
    let cache = ctx.cache().clone();
    let effects = ctx.shared_effects();

    let progress = ProgressReporter::bar("Downloading artifacts", pins.len());
    let worker_count = download_concurrency(pins.len());
    let (job_tx, job_rx) = mpsc::channel();
    for pin in pins {
        job_tx.send(pin.clone()).expect("queue artifacts");
    }
    drop(job_tx);

    let job_rx = Arc::new(Mutex::new(job_rx));
    let (result_tx, result_rx) = mpsc::channel();

    for _ in 0..worker_count {
        let work_rx = Arc::clone(&job_rx);
        let result_tx = result_tx.clone();
        let effects = effects.clone();
        let cache = cache.clone();
        let python = python.clone();
        let tags = Arc::clone(&tags);
        thread::spawn(move || {
            let pypi = effects.pypi();
            let cache_store = effects.cache();
            loop {
                let pin = {
                    let guard = work_rx.lock().expect("lock job receiver");
                    match guard.recv() {
                        Ok(pin) => pin,
                        Err(_) => break,
                    }
                };

                let outcome = download_artifact(
                    pypi,
                    cache_store,
                    &cache,
                    &python,
                    tags.as_ref(),
                    pin,
                    force_sdist,
                );
                if result_tx.send(outcome).is_err() {
                    break;
                }
            }
        });
    }
    drop(result_tx);

    let mut resolved = Vec::with_capacity(pins.len());
    for result in result_rx {
        progress.increment();
        match result {
            Ok(dep) => resolved.push(dep),
            Err(err) => return Err(err),
        }
    }

    progress.finish(format!("Downloaded {} artifacts", resolved.len()));
    Ok(resolved)
}

fn download_artifact(
    pypi: &dyn effects::PypiClient,
    cache_store: &dyn effects::CacheStore,
    cache: &CacheLocation,
    python: &str,
    tags: &InterpreterTags,
    pin: PinSpec,
    force_sdist: bool,
) -> Result<ResolvedDependency> {
    let release = pypi.fetch_release(&pin.normalized, &pin.version, &pin.specifier)?;
    let artifact = if force_sdist {
        build_wheel_via_sdist(cache_store, cache, &release, &pin, python)?
    } else {
        match select_wheel(&release.urls, tags, &pin.specifier) {
            Ok(wheel) => {
                let request = ArtifactRequest {
                    name: &pin.normalized,
                    version: &pin.version,
                    filename: &wheel.filename,
                    url: &wheel.url,
                    sha256: &wheel.sha256,
                };
                let cached = cache_store.cache_wheel(&cache.path, &request)?;
                LockedArtifact {
                    filename: wheel.filename.clone(),
                    url: wheel.url.clone(),
                    sha256: wheel.sha256.clone(),
                    size: cached.size,
                    cached_path: cached.wheel_path.display().to_string(),
                    python_tag: wheel.python_tag.clone(),
                    abi_tag: wheel.abi_tag.clone(),
                    platform_tag: wheel.platform_tag.clone(),
                }
            }
            Err(_) => build_wheel_via_sdist(cache_store, cache, &release, &pin, python)?,
        }
    };

    Ok(ResolvedDependency {
        name: pin.name,
        specifier: pin.specifier,
        extras: pin.extras,
        marker: pin.marker,
        artifact,
        direct: pin.direct,
        requires: pin.requires,
    })
}

fn build_wheel_via_sdist(
    cache_store: &dyn effects::CacheStore,
    cache: &CacheLocation,
    release: &PypiReleaseResponse,
    pin: &PinSpec,
    python: &str,
) -> Result<LockedArtifact> {
    let sdist = select_sdist(&release.urls, &pin.specifier)?;
    let built = cache_store.ensure_sdist_build(
        &cache.path,
        &SdistRequest {
            normalized_name: &pin.normalized,
            version: &pin.version,
            filename: &sdist.filename,
            url: &sdist.url,
            sha256: Some(&sdist.digests.sha256),
            python_path: python,
        },
    )?;
    Ok(LockedArtifact {
        filename: built.filename,
        url: built.url,
        sha256: built.sha256,
        size: built.size,
        cached_path: built.cached_path.display().to_string(),
        python_tag: built.python_tag,
        abi_tag: built.abi_tag,
        platform_tag: built.platform_tag,
    })
}

fn select_sdist<'a>(files: &'a [PypiFile], specifier: &str) -> Result<&'a PypiFile> {
    files
        .iter()
        .find(|file| file.packagetype == "sdist" && !file.yanked.unwrap_or(false))
        .ok_or_else(|| {
            InstallUserError::new(
                format!("PyPI does not provide an sdist for {specifier}"),
                json!({ "specifier": specifier }),
            )
            .into()
        })
}

pub(crate) fn build_http_client() -> Result<Client> {
    Client::builder()
        .user_agent(format!("px/{PX_VERSION}"))
        .timeout(Duration::from_secs(60))
        .build()
        .context("failed to build HTTP client")
}

pub(crate) fn fetch_release(
    client: &Client,
    normalized: &str,
    version: &str,
    specifier: &str,
) -> Result<PypiReleaseResponse> {
    let url = format!("{PYPI_BASE_URL}/{normalized}/{version}/json");
    let mut last_error = None;
    for attempt in 1..=3 {
        let response = client
            .get(&url)
            .send()
            .map_err(|err| anyhow!("failed to query PyPI for {specifier}: {err}"))?;
        if response.status() == StatusCode::NOT_FOUND {
            return Err(InstallUserError::new(
                format!("PyPI does not provide {specifier}"),
                json!({ "specifier": specifier }),
            )
            .into());
        }
        let response = response
            .error_for_status()
            .map_err(|err| anyhow!("PyPI returned an error for {specifier}: {err}"))?;
        match response.json::<PypiReleaseResponse>() {
            Ok(result) => return Ok(result),
            Err(err) => {
                last_error = Some(err);
                thread::sleep(Duration::from_millis(150 * attempt));
            }
        }
    }
    Err(anyhow!(
        "invalid JSON for {specifier}: {}",
        last_error
            .map(|err| err.to_string())
            .unwrap_or_else(|| "unknown error".to_string())
    ))
}

#[derive(Clone, Debug)]
struct WheelCandidate {
    filename: String,
    url: String,
    sha256: String,
    python_tag: String,
    abi_tag: String,
    platform_tag: String,
}

fn select_wheel(
    files: &[PypiFile],
    tags: &InterpreterTags,
    specifier: &str,
) -> Result<WheelCandidate> {
    let mut candidates = Vec::new();
    for file in files {
        if file.packagetype != "bdist_wheel" || file.yanked.unwrap_or(false) {
            continue;
        }
        let Some((python_tag, abi_tag, platform_tag)) = parse_wheel_tags(&file.filename) else {
            continue;
        };
        let candidate = WheelCandidate {
            filename: file.filename.clone(),
            url: file.url.clone(),
            sha256: file.digests.sha256.clone(),
            python_tag,
            abi_tag,
            platform_tag,
        };
        if wheel_supported(&candidate, tags) {
            candidates.push(candidate);
        }
    }

    if let Some(universal) = candidates
        .iter()
        .find(|c| c.python_tag == "py3" && c.abi_tag == "none" && c.platform_tag == "any")
    {
        return Ok(universal.clone());
    }

    let mut best: Option<(i32, WheelCandidate)> = None;
    for candidate in candidates {
        let score = score_candidate(&candidate, tags);
        match &mut best {
            Some((best_score, best_candidate)) => match score.cmp(best_score) {
                Ordering::Greater => {
                    *best_score = score;
                    *best_candidate = candidate;
                }
                Ordering::Equal => {
                    if candidate.filename < best_candidate.filename {
                        *best_candidate = candidate;
                    }
                }
                Ordering::Less => {}
            },
            None => best = Some((score, candidate)),
        }
    }

    best.map(|(_, candidate)| candidate).ok_or_else(|| {
        InstallUserError::new(
            format!("PyPI did not provide any wheels for {specifier}"),
            json!({ "specifier": specifier }),
        )
        .into()
    })
}

fn score_candidate(candidate: &WheelCandidate, tags: &InterpreterTags) -> i32 {
    let mut score = 0;
    if matches_any(&tags.python, &candidate.python_tag) {
        score += 100;
    } else if candidate.python_tag.starts_with("py3") {
        score += 50;
    }

    if matches_any(&tags.abi, &candidate.abi_tag) {
        score += 40;
    } else if candidate.abi_tag == "none" {
        score += 20;
    }

    if candidate.platform_tag == "any" {
        score += 30;
    } else if matches_any(&tags.platform, &candidate.platform_tag) {
        score += 25;
    }

    score
}

fn matches_any(values: &[String], candidate: &str) -> bool {
    candidate
        .split('.')
        .any(|part| values.iter().any(|val| part.eq_ignore_ascii_case(val)))
}

fn wheel_supported(candidate: &WheelCandidate, tags: &InterpreterTags) -> bool {
    let combos = candidate_tag_combos(candidate);
    if !tags.supported.is_empty()
        && combos
            .iter()
            .any(|(py, abi, platform)| tags.supports_triple(py, abi, platform))
    {
        return true;
    }
    fallback_python(&candidate.python_tag, &tags.python)
        && fallback_abi(&candidate.abi_tag, &tags.abi)
        && fallback_platform(&candidate.platform_tag, &tags.platform)
}

fn candidate_tag_combos(candidate: &WheelCandidate) -> Vec<(String, String, String)> {
    let python = split_tag_values(&candidate.python_tag);
    let abi = split_tag_values(&candidate.abi_tag);
    let platform = split_tag_values(&candidate.platform_tag);
    let mut combos = Vec::new();
    for py in &python {
        for abi_tag in &abi {
            for plat in &platform {
                combos.push((py.clone(), abi_tag.clone(), plat.clone()));
            }
        }
    }
    combos
}

fn split_tag_values(value: &str) -> Vec<String> {
    let mut values = value
        .split('.')
        .map(|part| part.trim().to_ascii_lowercase())
        .filter(|part| !part.is_empty())
        .collect::<Vec<_>>();
    if values.is_empty() {
        values.push(value.to_ascii_lowercase());
    }
    values
}

fn fallback_python(tag: &str, supported: &[String]) -> bool {
    split_tag_values(tag)
        .iter()
        .any(|token| token == "py3" || supported.iter().any(|val| val == token))
}

fn fallback_abi(tag: &str, supported: &[String]) -> bool {
    split_tag_values(tag)
        .iter()
        .any(|token| token == "none" || supported.iter().any(|val| val == token))
}

fn fallback_platform(tag: &str, supported: &[String]) -> bool {
    split_tag_values(tag)
        .iter()
        .any(|token| platform_token_supported(supported, token))
}

fn platform_token_supported(supported: &[String], token: &str) -> bool {
    if token == "any" {
        return true;
    }
    let normalized = normalize_platform_value(token);
    for platform in supported {
        let normalized_platform = normalize_platform_value(platform);
        if normalized_platform == "any" {
            continue;
        }
        if normalized_platform == normalized
            || same_platform_family(&normalized_platform, &normalized)
        {
            return true;
        }
    }
    false
}

fn normalize_platform_value(value: &str) -> String {
    value.replace('-', "_").to_ascii_lowercase()
}

fn same_platform_family(interpreter: &str, candidate: &str) -> bool {
    if interpreter.starts_with("linux") && candidate.contains("linux") {
        return arch_overlap(interpreter, candidate);
    }
    if interpreter.starts_with("macosx") && candidate.starts_with("macosx") {
        return arch_overlap(interpreter, candidate);
    }
    if interpreter.starts_with("win") && candidate.starts_with("win") {
        return arch_overlap(interpreter, candidate);
    }
    false
}

const ARCH_ALIASES: &[(&str, &str)] = &[
    ("x86_64", "x86_64"),
    ("amd64", "x86_64"),
    ("aarch64", "aarch64"),
    ("arm64", "arm64"),
    ("armv7l", "armv7l"),
    ("armv6l", "armv6l"),
    ("i686", "i686"),
    ("i386", "i386"),
    ("ppc64le", "ppc64le"),
    ("s390x", "s390x"),
];

fn arch_overlap(a: &str, b: &str) -> bool {
    match (arch_hint(a), arch_hint(b)) {
        (Some(left), Some(right)) => left == right,
        (None, None) => true,
        _ => false,
    }
}

fn arch_hint(value: &str) -> Option<&'static str> {
    let lower = value.to_ascii_lowercase();
    for (alias, canonical) in ARCH_ALIASES {
        if lower.contains(alias) {
            return Some(*canonical);
        }
    }
    None
}

fn parse_wheel_tags(filename: &str) -> Option<(String, String, String)> {
    let path = std::path::Path::new(filename);
    if !path
        .extension()
        .is_some_and(|ext| ext.eq_ignore_ascii_case("whl"))
    {
        return None;
    }
    let trimmed = path.file_stem()?.to_str()?;
    let parts: Vec<&str> = trimmed.split('-').collect();
    if parts.len() < 5 {
        return None;
    }
    let python_tag = parts[parts.len() - 3].to_string();
    let abi_tag = parts[parts.len() - 2].to_string();
    let platform_tag = parts[parts.len() - 1].to_string();
    Some((python_tag, abi_tag, platform_tag))
}

pub(crate) fn summarize_autopins(entries: &[AutopinEntry]) -> Option<String> {
    if entries.is_empty() {
        return None;
    }
    let mut labels = Vec::new();
    for entry in entries.iter().take(3) {
        labels.push(entry.short_label());
    }
    let mut summary = format!(
        "Pinned {} package{} automatically",
        entries.len(),
        if entries.len() == 1 { "" } else { "s" }
    );
    if !labels.is_empty() {
        summary.push_str(" (");
        summary.push_str(&labels.join(", "));
        if entries.len() > 3 {
            let _ = write!(&mut summary, ", +{} more", entries.len() - 3);
        }
        summary.push(')');
    }
    Some(summary)
}

fn write_dependencies(doc: &mut DocumentMut, specs: &[String]) -> Result<()> {
    let table = project_table_mut(doc)?;
    let mut array = Array::new();
    for spec in specs {
        array.push_formatted(TomlValue::from(spec.clone()));
    }
    table.insert("dependencies", Item::Value(TomlValue::Array(array)));
    Ok(())
}

pub(crate) fn project_table(doc: &DocumentMut) -> Result<&Table> {
    doc.get("project")
        .and_then(Item::as_table)
        .ok_or_else(|| anyhow!("[project] must be a table"))
}

fn project_table_mut(doc: &mut DocumentMut) -> Result<&mut Table> {
    doc.entry("project")
        .or_insert(Item::Table(Table::new()))
        .as_table_mut()
        .ok_or_else(|| anyhow!("[project] must be a table"))
}

pub(crate) fn dependency_name(spec: &str) -> String {
    let trimmed = strip_wrapping_quotes(spec.trim());
    let mut end = trimmed.len();
    for (idx, ch) in trimmed.char_indices() {
        if ch.is_ascii_whitespace() || matches!(ch, '<' | '>' | '=' | '!' | '~' | ';') {
            end = idx;
            break;
        }
    }
    let head = &trimmed[..end];
    let base = head.split('[').next().unwrap_or(head);
    base.to_lowercase()
}

fn strip_wrapping_quotes(input: &str) -> &str {
    if input.len() >= 2 {
        let bytes = input.as_bytes();
        let first = bytes[0];
        let last = bytes[input.len() - 1];
        if (first == b'"' && last == b'"') || (first == b'\'' && last == b'\'') {
            return &input[1..input.len() - 1];
        }
    }
    input
}

pub(crate) fn outcome_from_output(
    command_name: &str,
    target: &str,
    output: &RunOutput,
    prefix: &str,
    extra: Option<Value>,
) -> ExecutionOutcome {
    let mut extra_details = extra;
    let context = TracebackContext::new(command_name, target, extra_details.as_ref());
    let mut details = json!({
        "stdout": output.stdout.clone(),
        "stderr": output.stderr.clone(),
        "code": output.code,
        "target": target,
    });

    if let Some(extra_value) = extra_details.take() {
        if let Value::Object(map) = extra_value {
            if let Some(details_map) = details.as_object_mut() {
                for (key, value) in map {
                    details_map.insert(key, value);
                }
            }
        } else {
            details["extra"] = extra_value;
        }
    }

    let mut has_traceback = false;
    if output.code != 0 {
        if let Some(report) = analyze_python_traceback(&output.stderr, &context) {
            has_traceback = true;
            let recommendation = report.recommendation.clone();
            let trace_value = serde_json::to_value(&report).expect("traceback serialization");
            if let Some(map) = details.as_object_mut() {
                map.insert("traceback".to_string(), trace_value);
            }
            if let Some(rec) = recommendation {
                let hint_text = rec.hint.clone();
                let rec_value = serde_json::to_value(&rec).expect("traceback recommendation");
                if let Some(map) = details.as_object_mut() {
                    map.insert("recommendation".to_string(), rec_value);
                    if !map.contains_key("hint") {
                        map.insert("hint".to_string(), Value::String(hint_text));
                    }
                }
            }
        }
    }

    if output.code == 0 {
        let stdout = output.stdout.trim_end();
        if !stdout.is_empty() {
            details["passthrough"] = Value::Bool(true);
            return ExecutionOutcome::success(stdout.to_string(), details);
        }
        let stderr = output.stderr.trim_end();
        if !stderr.is_empty() {
            details["passthrough"] = Value::Bool(true);
            return ExecutionOutcome::success(stderr.to_string(), details);
        }
        let message = format!("{prefix} {command_name}({target}) succeeded");
        ExecutionOutcome::success(message, details)
    } else {
        let trimmed_stderr = output.stderr.trim();
        let message = if trimmed_stderr.is_empty() || has_traceback {
            format!(
                "{prefix} {command_name}({target}) exited with {}",
                output.code
            )
        } else {
            details["passthrough"] = Value::Bool(true);
            output.stderr.trim_end().to_string()
        };
        ExecutionOutcome::failure(message, details)
    }
}

pub(crate) struct PythonContext {
    project_root: PathBuf,
    python: String,
    pythonpath: String,
    allowed_paths: Vec<PathBuf>,
}

#[derive(Clone, Copy, Debug)]
pub(crate) enum EnvGuard {
    Strict,
    AutoSync,
}

#[derive(Clone, Debug)]
pub(crate) struct EnvironmentSyncReport {
    action: &'static str,
    note: String,
}

impl EnvironmentSyncReport {
    fn new(issue: EnvironmentIssue) -> Self {
        Self {
            action: issue.action_key(),
            note: issue.note().to_string(),
        }
    }

    fn to_json(&self) -> Value {
        json!({
            "action": self.action,
            "note": self.note,
        })
    }
}

#[derive(Clone, Copy, Debug)]
pub(crate) enum EnvironmentIssue {
    MissingLock,
    LockDrift,
    MissingArtifacts,
    MissingEnv,
    EnvOutdated,
    RuntimeMismatch,
}

impl EnvironmentIssue {
    fn from_details(details: &Value) -> Option<Self> {
        let reason = details
            .as_object()
            .and_then(|map| map.get("reason"))
            .and_then(Value::as_str)?;
        match reason {
            "missing_lock" => Some(EnvironmentIssue::MissingLock),
            "lock_drift" => Some(EnvironmentIssue::LockDrift),
            "missing_artifacts" => Some(EnvironmentIssue::MissingArtifacts),
            "missing_env" => Some(EnvironmentIssue::MissingEnv),
            "env_outdated" => Some(EnvironmentIssue::EnvOutdated),
            "runtime_mismatch" => Some(EnvironmentIssue::RuntimeMismatch),
            _ => None,
        }
    }

    fn note(self) -> &'static str {
        match self {
            EnvironmentIssue::MissingLock => "No px.lock found, resolving dependencies…",
            EnvironmentIssue::LockDrift => {
                "Manifest drift detected; syncing px.lock and environment…"
            }
            EnvironmentIssue::MissingArtifacts => {
                "Cached artifacts missing; rehydrating environment…"
            }
            EnvironmentIssue::MissingEnv => "Environment missing; rebuilding from px.lock…",
            EnvironmentIssue::EnvOutdated => {
                "Environment stale; syncing with latest lock and runtime…"
            }
            EnvironmentIssue::RuntimeMismatch => {
                "Environment runtime mismatch; rebuilding for current Python…"
            }
        }
    }

    fn action_key(self) -> &'static str {
        match self {
            EnvironmentIssue::MissingLock => "lock-bootstrap",
            EnvironmentIssue::LockDrift => "lock-sync",
            EnvironmentIssue::MissingArtifacts => "env-rehydrate",
            EnvironmentIssue::MissingEnv => "env-recreate",
            EnvironmentIssue::EnvOutdated => "env-refresh",
            EnvironmentIssue::RuntimeMismatch => "env-runtime",
        }
    }

    fn auto_fixable(self) -> bool {
        matches!(
            self,
            EnvironmentIssue::MissingArtifacts
                | EnvironmentIssue::MissingEnv
                | EnvironmentIssue::EnvOutdated
                | EnvironmentIssue::RuntimeMismatch
        )
    }
}
pub(crate) fn issue_from_details(details: &Value) -> Option<EnvironmentIssue> {
    EnvironmentIssue::from_details(details)
}

impl PythonContext {
    fn new_with_guard(
        ctx: &CommandContext,
        guard: EnvGuard,
    ) -> Result<(Self, Option<EnvironmentSyncReport>)> {
        let project_root = ctx.project_root()?;
        let manifest_path = project_root.join("pyproject.toml");
        if !manifest_path.exists() {
            return Err(InstallUserError::new(
                format!("pyproject.toml not found in {}", project_root.display()),
                json!({
                    "pyproject": manifest_path.display().to_string(),
                    "hint": "run `px migrate --apply` or create pyproject.toml first",
                    "reason": "missing_manifest",
                }),
            )
            .into());
        }
        let snapshot = manifest_snapshot_at(&project_root)?;
        let runtime = prepare_project_runtime(&snapshot)?;
        let sync_report = ensure_environment_with_guard(ctx, &snapshot, guard)?;
        let python = runtime.record.path.clone();
        let (pythonpath, allowed_paths) = build_pythonpath(ctx.fs(), &project_root)?;
        Ok((
            Self {
                project_root,
                python,
                pythonpath,
                allowed_paths,
            },
            sync_report,
        ))
    }

    fn base_env(&self, command_args: &Value) -> Result<Vec<(String, String)>> {
        let mut envs = Vec::new();
        envs.push(("PYTHONPATH".into(), self.pythonpath.clone()));
        envs.push(("PYTHONUNBUFFERED".into(), "1".into()));
        let allowed =
            env::join_paths(&self.allowed_paths).context("allowed path contains invalid UTF-8")?;
        let allowed = allowed
            .into_string()
            .map_err(|_| anyhow!("allowed path contains non-utf8 data"))?;
        envs.push(("PX_ALLOWED_PATHS".into(), allowed));
        envs.push((
            "PX_PROJECT_ROOT".into(),
            self.project_root.display().to_string(),
        ));
        envs.push(("PX_COMMAND_JSON".into(), command_args.to_string()));
        Ok(envs)
    }
}

pub(crate) fn build_pythonpath(
    fs: &dyn effects::FileSystem,
    project_root: &Path,
) -> Result<(String, Vec<PathBuf>)> {
    let mut paths = Vec::new();
    let src = project_root.join("src");
    if src.exists() {
        paths.push(src);
    }
    paths.push(project_root.to_path_buf());

    if let Some(site_dir) = resolve_project_site(fs, project_root) {
        let canonical = fs.canonicalize(&site_dir).unwrap_or(site_dir.clone());
        paths.push(canonical.clone());
        let pth = canonical.join("px.pth");
        if pth.exists() {
            if let Ok(contents) = fs.read_to_string(&pth) {
                for line in contents.lines() {
                    let trimmed = line.trim();
                    if trimmed.is_empty() {
                        continue;
                    }
                    let entry_path = PathBuf::from(trimmed);
                    if entry_path.exists() {
                        paths.push(entry_path);
                    }
                }
            }
        }
    }

    paths.retain(|p| p.exists());
    if paths.is_empty() {
        paths.push(project_root.to_path_buf());
    }

    let joined = env::join_paths(&paths).context("failed to build PYTHONPATH")?;
    let pythonpath = joined
        .into_string()
        .map_err(|_| anyhow!("pythonpath contains non-UTF paths"))?;
    Ok((pythonpath, paths))
}

pub(crate) fn ensure_project_environment_synced(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
) -> Result<()> {
    if !snapshot.manifest_path.exists() {
        return Err(InstallUserError::new(
            format!("pyproject.toml not found in {}", snapshot.root.display()),
            json!({
                "hint": "run `px migrate --apply` or pass ENTRY explicitly",
                "project_root": snapshot.root.display().to_string(),
                "manifest": snapshot.manifest_path.display().to_string(),
                "reason": "missing_manifest",
            }),
        )
        .into());
    }
    let lock_path = snapshot.lock_path.clone();
    let Some(lock) = load_lockfile_optional(&lock_path)? else {
        return Err(InstallUserError::new(
            "missing px.lock (run `px sync`)",
            json!({
                "lockfile": lock_path.display().to_string(),
                "hint": "run `px sync` to generate px.lock before running this command",
                "reason": "missing_lock",
            }),
        )
        .into());
    };

    let drift = detect_lock_drift(snapshot, &lock, None);
    if !drift.is_empty() {
        return Err(InstallUserError::new(
            "px.lock is out of date",
            json!({
                "lockfile": lock_path.display().to_string(),
                "drift": drift,
                "hint": "run `px sync` to refresh px.lock",
                "reason": "lock_drift",
            }),
        )
        .into());
    }

    let missing = verify_locked_artifacts(&lock);
    if !missing.is_empty() {
        return Err(InstallUserError::new(
            "cached artifacts missing",
            json!({
                "lockfile": lock_path.display().to_string(),
                "missing": missing,
                "hint": "run `px sync` to rehydrate the environment",
                "reason": "missing_artifacts",
            }),
        )
        .into());
    }

    let lock_hash = match lock.lock_id.clone() {
        Some(value) => value,
        None => compute_lock_hash(&lock_path)?,
    };
    let _ = prepare_project_runtime(snapshot)?;
    ensure_env_matches_lock(ctx, snapshot, &lock_hash)
}

pub(crate) fn ensure_env_matches_lock(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
    lock_hash: &str,
) -> Result<()> {
    let state = load_project_state(ctx.fs(), &snapshot.root);
    let Some(env) = state.current_env else {
        return Err(InstallUserError::new(
            "project environment missing",
            json!({
                "hint": "run `px sync` to build the environment",
                "reason": "missing_env",
            }),
        )
        .into());
    };
    if env.lock_hash != lock_hash {
        return Err(InstallUserError::new(
            "environment is out of date",
            json!({
                "expected_lock_hash": lock_hash,
                "current_lock_hash": env.lock_hash,
                "hint": "run `px sync` to rebuild the environment",
                "reason": "env_outdated",
            }),
        )
        .into());
    }
    let site_dir = PathBuf::from(&env.site_packages);
    if !site_dir.exists() {
        return Err(InstallUserError::new(
            "environment files missing",
            json!({
                "site": env.site_packages,
                "hint": "run `px sync` to rebuild the environment",
                "reason": "missing_env",
            }),
        )
        .into());
    }

    let runtime = detect_runtime_metadata(ctx, snapshot)?;
    if runtime.version != env.python.version || runtime.platform != env.platform {
        return Err(InstallUserError::new(
            format!(
                "environment targets Python {} ({}) but {} ({}) is active",
                env.python.version, env.platform, runtime.version, runtime.platform
            ),
            json!({
                "expected_python": env.python.version,
                "current_python": runtime.version,
                "expected_platform": env.platform,
                "current_platform": runtime.platform,
                "hint": "run `px sync` to rebuild for the current runtime",
                "reason": "runtime_mismatch",
            }),
        )
        .into());
    }

    Ok(())
}

fn ensure_environment_with_guard(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
    guard: EnvGuard,
) -> Result<Option<EnvironmentSyncReport>> {
    match ensure_project_environment_synced(ctx, snapshot) {
        Ok(()) => Ok(None),
        Err(err) => match err.downcast::<InstallUserError>() {
            Ok(user) => match guard {
                EnvGuard::Strict => Err(user.into()),
                EnvGuard::AutoSync => {
                    if let Some(issue) = EnvironmentIssue::from_details(&user.details) {
                        if issue.auto_fixable() {
                            auto_sync_environment(ctx, snapshot, issue)
                        } else {
                            Err(user.into())
                        }
                    } else {
                        Err(user.into())
                    }
                }
            },
            Err(err) => Err(err),
        },
    }
}

pub(crate) fn auto_sync_environment(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
    issue: EnvironmentIssue,
) -> Result<Option<EnvironmentSyncReport>> {
    install_snapshot(ctx, snapshot, false, None)?;
    refresh_project_site(snapshot, ctx)?;
    Ok(Some(EnvironmentSyncReport::new(issue)))
}

pub(crate) fn attach_autosync_details(
    outcome: &mut ExecutionOutcome,
    report: Option<EnvironmentSyncReport>,
) {
    let Some(report) = report else {
        return;
    };
    let autosync = report.to_json();
    match outcome.details {
        Value::Object(ref mut map) => {
            map.insert("autosync".to_string(), autosync);
        }
        Value::Null => {
            outcome.details = json!({ "autosync": autosync });
        }
        ref mut other => {
            let previous = other.take();
            outcome.details = json!({
                "value": previous,
                "autosync": autosync,
            });
        }
    }
}

pub(crate) fn python_context(ctx: &CommandContext) -> Result<PythonContext, ExecutionOutcome> {
    python_context_with_mode(ctx, EnvGuard::Strict).map(|(py, _)| py)
}

pub(crate) fn python_context_with_mode(
    ctx: &CommandContext,
    guard: EnvGuard,
) -> Result<(PythonContext, Option<EnvironmentSyncReport>), ExecutionOutcome> {
    match PythonContext::new_with_guard(ctx, guard) {
        Ok(result) => Ok(result),
        Err(err) => {
            if is_missing_project_error(&err) {
                return Err(missing_project_outcome());
            }
            match err.downcast::<InstallUserError>() {
                Ok(user) => Err(ExecutionOutcome::user_error(user.message, user.details)),
                Err(err) => Err(ExecutionOutcome::failure(
                    "failed to prepare python environment",
                    json!({ "error": err.to_string() }),
                )),
            }
        }
    }
}

pub fn missing_project_outcome() -> ExecutionOutcome {
    ExecutionOutcome::user_error(
        MISSING_PROJECT_MESSAGE,
        json!({
            "reason": "missing_project",
            "hint": MISSING_PROJECT_HINT,
        }),
    )
}

pub fn is_missing_project_error(err: &anyhow::Error) -> bool {
    err.chain()
        .any(|cause| cause.to_string().contains("No px project found"))
}

#[must_use]
pub fn to_json_response(info: CommandInfo, outcome: &ExecutionOutcome, _code: i32) -> Value {
    let status = match outcome.status {
        CommandStatus::Ok => "ok",
        CommandStatus::UserError => "user-error",
        CommandStatus::Failure => "failure",
    };
    let details = match &outcome.details {
        Value::Object(_) => outcome.details.clone(),
        Value::Null => json!({}),
        other => json!({ "value": other }),
    };
    json!({
        "status": status,
        "message": format_status_message(info, &outcome.message),
        "details": details,
    })
}

#[must_use]
pub fn format_status_message(info: CommandInfo, message: &str) -> String {
    let group_name = info.group.to_string();
    let prefix = if group_name == info.name {
        format!("px {}", info.name)
    } else {
        format!("px {} {}", group_name, info.name)
    };
    if message.is_empty() {
        prefix
    } else if message.starts_with(&prefix) {
        message.to_string()
    } else {
        format!("{prefix}: {message}")
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::pypi::{PypiDigests, PypiFile};
    use crate::python_sys::{current_marker_environment, InterpreterSupportedTag};
    use crate::run::python_script_target;
    use px_domain::lockfile::LockedDependency;
    use std::path::PathBuf;
    use tempfile::tempdir;

    use crate::SystemEffects;

    #[test]
    fn config_respects_env_flags() {
        let snapshot = EnvSnapshot::testing(&[
            ("PX_ONLINE", "1"),
            ("PX_RESOLVER", "1"),
            ("PX_FORCE_SDIST", "1"),
            ("PX_TEST_FALLBACK_STD", "1"),
            ("PX_SKIP_TESTS", "1"),
        ]);
        let effects = SystemEffects::new();
        let config = Config::from_snapshot(&snapshot, effects.cache()).expect("config");
        assert!(config.network.online);
        assert!(config.resolver.enabled);
        assert!(config.resolver.force_sdist);
        assert!(config.test.fallback_builtin);
        assert_eq!(config.test.skip_tests_flag.as_deref(), Some("1"));
    }

    #[test]
    fn resolver_enabled_by_default() {
        let snapshot = EnvSnapshot::testing(&[]);
        let effects = SystemEffects::new();
        let config = Config::from_snapshot(&snapshot, effects.cache()).expect("config");
        assert!(config.resolver.enabled);
    }

    #[test]
    fn resolver_can_be_disabled_via_env() {
        let snapshot = EnvSnapshot::testing(&[("PX_RESOLVER", "0")]);
        let effects = SystemEffects::new();
        let config = Config::from_snapshot(&snapshot, effects.cache()).expect("config");
        assert!(!config.resolver.enabled);
    }

    #[test]
    fn marker_applies_respects_python_version() {
        let env = current_marker_environment().expect("marker env");
        assert!(
            !marker_applies("tomli>=1.1.0; python_version < '3.11'", &env),
            "non-matching marker should be skipped"
        );
    }

    #[test]
    fn parse_exact_pin_handles_extras_and_markers() {
        let spec = r#"requests[socks]==2.32 ; python_version >= "3.10""#;
        let pin = parse_exact_pin(spec).expect("pin");
        assert_eq!(pin.name, "requests");
        assert_eq!(pin.version, "2.32");
        assert_eq!(pin.extras, vec!["socks".to_string()]);
        assert!(
            pin.specifier.contains("[socks]==2.32"),
            "specifier should include extras"
        );
        assert!(
            pin.marker
                .as_deref()
                .is_some_and(|m| m.contains("python_version")),
            "marker should be preserved"
        );
    }

    #[test]
    fn python_script_target_detects_relative_paths() {
        let root = PathBuf::from("/tmp/project");
        let (arg, path) =
            python_script_target("src/app.py", &root).expect("relative script detected");
        assert_eq!(arg, "src/app.py");
        assert_eq!(PathBuf::from(path), root.join("src/app.py"));
    }

    #[test]
    fn python_script_target_detects_absolute_paths() {
        let absolute = PathBuf::from("/opt/demo/main.py");
        let entry = absolute.to_string_lossy().to_string();
        let root = PathBuf::from("/tmp/project");
        let (arg, path) = python_script_target(&entry, &root).expect("absolute script detected");
        assert_eq!(arg, entry);
        assert_eq!(PathBuf::from(path), absolute);
    }

    #[test]
    fn python_script_target_ignores_non_python_files() {
        let root = PathBuf::from("/tmp/project");
        assert!(python_script_target("bin/tool", &root).is_none());
    }

    #[test]
    fn materialize_project_site_writes_cached_paths() {
        let temp = tempdir().expect("tempdir");
        let root = temp.path();
        let cache_dir = root.join("cache");
        fs::create_dir_all(&cache_dir).expect("cache dir");
        let wheel = cache_dir.join("demo-1.0.0.whl");
        fs::write(&wheel, b"demo").expect("wheel stub");
        let dist_dir = wheel.with_extension("dist");
        fs::create_dir_all(&dist_dir).expect("dist dir");

        let snapshot = ManifestSnapshot {
            root: root.to_path_buf(),
            manifest_path: root.join("pyproject.toml"),
            lock_path: root.join("px.lock"),
            name: "demo".into(),
            python_requirement: ">=3.11".into(),
            dependencies: Vec::new(),
            python_override: None,
            manifest_fingerprint: "demo-fingerprint".into(),
        };
        let lock = LockSnapshot {
            version: 1,
            project_name: Some("demo".into()),
            python_requirement: Some(">=3.11".into()),
            manifest_fingerprint: Some("demo-fingerprint".into()),
            lock_id: Some("lock-demo".into()),
            dependencies: Vec::new(),
            mode: Some("p0-pinned".into()),
            resolved: vec![LockedDependency {
                name: "demo".into(),
                direct: true,
                artifact: Some(LockedArtifact {
                    filename: "demo.whl".into(),
                    url: "https://example.invalid/demo.whl".into(),
                    sha256: "abc123".into(),
                    size: 4,
                    cached_path: wheel.display().to_string(),
                    python_tag: "py3".into(),
                    abi_tag: "none".into(),
                    platform_tag: "any".into(),
                }),
                requires: Vec::new(),
            }],
            graph: None,
        };

        let effects = SystemEffects::new();
        let site_dir = snapshot
            .root
            .join(".px")
            .join("envs")
            .join("test-env")
            .join("site");
        materialize_project_site(&site_dir, &lock, effects.fs()).expect("materialize site");

        let pxpth = site_dir.join("px.pth");
        assert!(
            pxpth.exists(),
            "env site px.pth should be created alongside install"
        );
        let contents = fs::read_to_string(pxpth).expect("read px.pth");
        assert!(
            contents.contains(dist_dir.to_str().unwrap()),
            "px.pth should reference unpacked artifact path"
        );
    }

    #[test]
    fn materialize_project_site_skips_missing_artifacts() {
        let temp = tempdir().expect("tempdir");
        let root = temp.path();
        let snapshot = ManifestSnapshot {
            root: root.to_path_buf(),
            manifest_path: root.join("pyproject.toml"),
            lock_path: root.join("px.lock"),
            name: "demo".into(),
            python_requirement: ">=3.11".into(),
            dependencies: Vec::new(),
            python_override: None,
            manifest_fingerprint: "demo-fingerprint".into(),
        };
        let lock = LockSnapshot {
            version: 1,
            project_name: Some("demo".into()),
            python_requirement: Some(">=3.11".into()),
            manifest_fingerprint: Some("demo-fingerprint".into()),
            lock_id: Some("lock-demo".into()),
            dependencies: Vec::new(),
            mode: Some("p0-pinned".into()),
            resolved: vec![LockedDependency {
                name: "missing".into(),
                direct: true,
                artifact: Some(LockedArtifact {
                    filename: "missing.whl".into(),
                    url: "https://example.invalid/missing.whl".into(),
                    sha256: "deadbeef".into(),
                    size: 0,
                    cached_path: root.join("nope").display().to_string(),
                    python_tag: "py3".into(),
                    abi_tag: "none".into(),
                    platform_tag: "any".into(),
                }),
                requires: Vec::new(),
            }],
            graph: None,
        };

        let effects = SystemEffects::new();
        let site_dir = snapshot
            .root
            .join(".px")
            .join("envs")
            .join("test-env")
            .join("site");
        materialize_project_site(&site_dir, &lock, effects.fs())
            .expect("materialize site with gap");
        let pxpth = site_dir.join("px.pth");
        assert!(pxpth.exists(), "px.pth should still be created");
        let contents = fs::read_to_string(pxpth).expect("read px.pth");
        assert!(
            contents.trim().is_empty(),
            "missing artifacts should not be written to px.pth"
        );
    }

    #[test]
    fn select_wheel_prefers_linux_over_macos() {
        let files = vec![
            wheel_file("demo-1.0.0-cp312-cp312-macosx_10_13_x86_64.whl"),
            wheel_file("demo-1.0.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"),
        ];
        let tags = linux_interpreter_tags();
        let wheel = select_wheel(&files, &tags, "demo==1.0.0").expect("linux match");
        assert!(wheel.platform_tag.contains("manylinux"));
    }

    #[test]
    fn select_wheel_rejects_incompatible_platforms() {
        let files = vec![wheel_file("demo-1.0.0-cp312-cp312-macosx_10_13_x86_64.whl")];
        let tags = linux_interpreter_tags();
        let err = select_wheel(&files, &tags, "demo==1.0.0").expect_err("mac wheel rejected");
        assert!(err.to_string().contains("did not provide any wheels"));
    }

    #[test]
    fn heuristic_platform_matching_handles_manylinux() {
        let files = vec![wheel_file(
            "demo-1.0.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
        )];
        let mut tags = linux_interpreter_tags();
        tags.supported.clear();
        let wheel = select_wheel(&files, &tags, "demo==1.0.0").expect("fallback tags");
        assert!(wheel.platform_tag.contains("manylinux"));
    }

    fn wheel_file(name: &str) -> PypiFile {
        PypiFile {
            filename: name.into(),
            url: format!("https://example.invalid/{name}"),
            packagetype: "bdist_wheel".into(),
            yanked: Some(false),
            digests: PypiDigests {
                sha256: "deadbeef".into(),
            },
        }
    }

    fn linux_interpreter_tags() -> InterpreterTags {
        InterpreterTags {
            python: vec!["cp312".into(), "py312".into(), "py3".into()],
            abi: vec!["cp312".into(), "abi3".into(), "none".into()],
            platform: vec!["linux_x86_64".into(), "any".into()],
            supported: vec![
                InterpreterSupportedTag {
                    python: "cp312".into(),
                    abi: "cp312".into(),
                    platform: "manylinux_2_17_x86_64".into(),
                },
                InterpreterSupportedTag {
                    python: "cp312".into(),
                    abi: "cp312".into(),
                    platform: "manylinux2014_x86_64".into(),
                },
            ],
        }
    }
}
