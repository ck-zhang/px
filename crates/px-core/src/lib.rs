use std::{
    cmp::Ordering,
    collections::{HashMap, VecDeque},
    env,
    ffi::OsString,
    fmt,
    fs::{self, File},
    io::{self, Read, Write},
    path::{Path, PathBuf},
    process::Command,
    str::FromStr,
    sync::OnceLock,
    time::Duration,
};

use self::effects::{Effects, SharedEffects};
use anyhow::{anyhow, bail, Context, Result};
use flate2::{write::GzEncoder, Compression};
use pep440_rs::{Operator, VersionSpecifiers};
use pep508_rs::{MarkerEnvironment, Requirement as PepRequirement, VersionOrUrl};
use px_lockfile::{
    analyze_lock_diff, detect_lock_drift, load_lockfile_optional, lock_prefetch_specs,
    render_lockfile, render_lockfile_v2, verify_locked_artifacts, LockPrefetchSpec, LockSnapshot,
    LockedArtifact, ResolvedDependency,
};
use px_project::resolver::{
    autopin_pin_key, autopin_spec_key, marker_applies, merge_resolved_dependencies,
};
use px_project::{
    collect_pyproject_packages, collect_requirement_packages, discover_project_root, plan_autopin,
    prepare_pyproject_plan, resolve_onboard_path, AutopinEntry, AutopinState, BackupManager,
    InstallOverride, ManifestEditor, PinSpec, ProjectInitializer,
};
use px_python;
use px_resolver::{ResolveRequest as ResolverRequest, ResolverEnv, ResolverTags};
use px_runtime::{self, RunOutput};
use px_store::{
    ArtifactRequest, CacheLocation, PrefetchOptions as StorePrefetchOptions,
    PrefetchSpec as StorePrefetchSpec, SdistRequest,
};
use reqwest::{blocking::Client, StatusCode};
use serde::{Deserialize, Serialize};
use serde_json::{json, Value};
use sha2::{Digest, Sha256};
use tar::Builder;
use toml_edit::{Array, DocumentMut, Item, Table, Value as TomlValue};
use tracing::warn;
use zip::{write::FileOptions, CompressionMethod, ZipWriter};

use crate::pypi::{PypiFile, PypiReleaseResponse};

mod effects;
mod pypi;
mod workspace;

pub use effects::SystemEffects;

const PYPI_BASE_URL: &str = "https://pypi.org/pypi";
const PX_VERSION: &str = env!("CARGO_PKG_VERSION");
const SITE_CUSTOMIZE: &str = r#"# Auto-generated by px. Do not edit.
import os
import sys
import sysconfig

def _stdlib_prefixes():
    prefixes = set()
    for key in ("stdlib", "platstdlib"):
        path = sysconfig.get_path(key)
        if path:
            prefixes.add(os.path.normpath(path))
    for attr in ("base_prefix", "base_exec_prefix", "exec_prefix"):
        value = getattr(sys, attr, None)
        if value:
            prefixes.add(os.path.normpath(value))
    return prefixes

_STD_PREFIXES = _stdlib_prefixes()
_ALLOWED = [p for p in os.environ.get("PX_ALLOWED_PATHS", "").split(os.pathsep) if p]

def _allow(path):
    if not path:
        return False
    norm = os.path.normpath(path)
    if "site-packages" in norm or "dist-packages" in norm:
        return False
    for prefix in _STD_PREFIXES:
        if norm == prefix or norm.startswith(prefix + os.sep):
            return True
    return False

_new_path = []
_seen = set()

def _push(path):
    if path in _seen:
        return
    _seen.add(path)
    _new_path.append(path)

if sys.path:
    _push(sys.path[0])

for path in _ALLOWED:
    _push(path)

for path in sys.path:
    if _allow(path):
        _push(path)

sys.path[:] = _new_path
"#;

type ManifestSnapshot = px_project::ProjectSnapshot;

#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct GlobalOptions {
    pub quiet: bool,
    pub verbose: u8,
    pub trace: bool,
    pub json: bool,
    pub config: Option<String>,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "kebab-case")]
pub enum CommandGroup {
    Init,
    Add,
    Remove,
    Install,
    Update,
    Run,
    Test,
    Fmt,
    Lint,
    Tidy,
    Build,
    Publish,
    Migrate,
    Status,
    Env,
    Cache,
    Lock,
    Workspace,
    Explain,
    Why,
}

impl fmt::Display for CommandGroup {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        let name = match self {
            CommandGroup::Init => "init",
            CommandGroup::Add => "add",
            CommandGroup::Remove => "remove",
            CommandGroup::Install => "install",
            CommandGroup::Update => "update",
            CommandGroup::Run => "run",
            CommandGroup::Test => "test",
            CommandGroup::Fmt => "fmt",
            CommandGroup::Lint => "lint",
            CommandGroup::Tidy => "tidy",
            CommandGroup::Build => "build",
            CommandGroup::Publish => "publish",
            CommandGroup::Migrate => "migrate",
            CommandGroup::Status => "status",
            CommandGroup::Env => "env",
            CommandGroup::Cache => "cache",
            CommandGroup::Lock => "lock",
            CommandGroup::Workspace => "workspace",
            CommandGroup::Explain => "explain",
            CommandGroup::Why => "why",
        };
        f.write_str(name)
    }
}

#[derive(Clone, Copy, Debug)]
pub struct CommandInfo {
    pub group: CommandGroup,
    pub name: &'static str,
}

impl CommandInfo {
    pub const fn new(group: CommandGroup, name: &'static str) -> Self {
        Self { group, name }
    }
}

#[derive(Debug, Clone)]
struct EnvSnapshot {
    vars: HashMap<String, String>,
}

impl EnvSnapshot {
    fn capture() -> Self {
        Self {
            vars: env::vars().collect(),
        }
    }

    fn flag_is_enabled(&self, key: &str) -> bool {
        matches!(self.vars.get(key).map(String::as_str), Some("1"))
    }

    fn var(&self, key: &str) -> Option<&str> {
        self.vars.get(key).map(String::as_str)
    }

    fn contains(&self, key: &str) -> bool {
        self.vars.contains_key(key)
    }

    #[cfg(test)]
    fn testing(pairs: &[(&str, &str)]) -> Self {
        let vars = pairs
            .iter()
            .map(|(k, v)| (k.to_string(), v.to_string()))
            .collect();
        Self { vars }
    }
}

#[derive(Debug)]
pub struct Config {
    cache: CacheConfig,
    network: NetworkConfig,
    resolver: ResolverConfig,
    test: TestConfig,
    publish: PublishConfig,
}

impl Config {
    pub fn from_env(effects: &dyn Effects) -> Result<Self> {
        let snapshot = EnvSnapshot::capture();
        Self::from_snapshot(&snapshot, effects.cache())
    }

    fn from_snapshot(
        snapshot: &EnvSnapshot,
        cache_store: &dyn effects::CacheStore,
    ) -> Result<Self> {
        Ok(Self {
            cache: CacheConfig {
                store: cache_store.resolve_store_path()?,
            },
            network: NetworkConfig {
                online: snapshot.flag_is_enabled("PX_ONLINE"),
            },
            resolver: ResolverConfig {
                enabled: match snapshot.var("PX_RESOLVER") {
                    Some(value) => value == "1",
                    None => true,
                },
                force_sdist: snapshot.flag_is_enabled("PX_FORCE_SDIST"),
            },
            test: TestConfig {
                fallback_builtin: snapshot.flag_is_enabled("PX_TEST_FALLBACK_STD"),
                skip_tests_flag: snapshot.var("PX_SKIP_TESTS").map(ToOwned::to_owned),
            },
            publish: PublishConfig {
                default_token_env: "PX_PUBLISH_TOKEN",
            },
        })
    }

    pub fn cache(&self) -> &CacheConfig {
        &self.cache
    }

    pub fn network(&self) -> &NetworkConfig {
        &self.network
    }

    pub fn resolver(&self) -> &ResolverConfig {
        &self.resolver
    }

    pub fn test(&self) -> &TestConfig {
        &self.test
    }

    pub fn publish(&self) -> &PublishConfig {
        &self.publish
    }
}

#[derive(Debug)]
pub struct CacheConfig {
    pub store: CacheLocation,
}

#[derive(Debug, Clone, Copy)]
pub struct NetworkConfig {
    pub online: bool,
}

#[derive(Debug, Clone, Copy)]
pub struct ResolverConfig {
    pub enabled: bool,
    pub force_sdist: bool,
}

#[derive(Debug, Clone)]
pub struct TestConfig {
    pub fallback_builtin: bool,
    pub skip_tests_flag: Option<String>,
}

#[derive(Debug, Clone, Copy)]
pub struct PublishConfig {
    pub default_token_env: &'static str,
}

pub struct CommandContext<'a> {
    pub global: &'a GlobalOptions,
    env: EnvSnapshot,
    config: Config,
    project_root: OnceLock<PathBuf>,
    effects: SharedEffects,
}

impl<'a> CommandContext<'a> {
    pub fn new(global: &'a GlobalOptions, effects: SharedEffects) -> Result<Self> {
        let env = EnvSnapshot::capture();
        let config = Config::from_snapshot(&env, effects.cache())?;
        Ok(Self {
            global,
            env,
            config,
            project_root: OnceLock::new(),
            effects,
        })
    }

    pub fn effects(&self) -> &dyn Effects {
        self.effects.as_ref()
    }

    pub fn shared_effects(&self) -> SharedEffects {
        self.effects.clone()
    }

    pub fn cache(&self) -> &CacheLocation {
        &self.config.cache.store
    }

    pub fn is_online(&self) -> bool {
        self.config.network.online
    }

    pub fn fs(&self) -> &dyn effects::FileSystem {
        self.effects.fs()
    }

    pub fn python_runtime(&self) -> &dyn effects::PythonRuntime {
        self.effects.python()
    }

    pub fn git(&self) -> &dyn effects::GitClient {
        self.effects.git()
    }

    pub fn cache_store(&self) -> &dyn effects::CacheStore {
        self.effects.cache()
    }

    pub fn pypi(&self) -> &dyn effects::PypiClient {
        self.effects.pypi()
    }

    pub fn marker_environment(&self) -> Result<MarkerEnvironment> {
        let python = self.python_runtime().detect_interpreter()?;
        let resolver_env = detect_marker_environment_with(&python)?;
        resolver_env.to_marker_environment()
    }

    pub fn project_root(&self) -> Result<PathBuf> {
        if let Some(path) = self.project_root.get() {
            Ok(path.clone())
        } else {
            let path = current_project_root()?;
            let _ = self.project_root.set(path.clone());
            Ok(path)
        }
    }

    pub fn config(&self) -> &Config {
        &self.config
    }

    pub fn env_contains(&self, key: &str) -> bool {
        self.env.contains(key)
    }
}

pub trait CommandHandler<R> {
    fn handle(&self, ctx: &CommandContext, request: R) -> Result<ExecutionOutcome>;
}

#[derive(Clone, Debug)]
pub struct ProjectInitRequest {
    pub package: Option<String>,
    pub python: Option<String>,
    pub dry_run: bool,
    pub force: bool,
}

#[derive(Clone, Debug, Default)]
pub struct CacheStatsRequest;

#[derive(Clone, Debug, Default)]
pub struct CachePathRequest;

#[derive(Clone, Debug, Default)]
pub struct WorkspaceListRequest;

#[derive(Clone, Debug, Default)]
pub struct LockDiffRequest;

#[derive(Clone, Debug)]
pub struct CachePruneRequest {
    pub all: bool,
    pub dry_run: bool,
}

#[derive(Clone, Debug, Default)]
pub struct WorkspaceVerifyRequest;

#[derive(Clone, Debug)]
pub struct WorkflowTestRequest {
    pub pytest_args: Vec<String>,
}

#[derive(Clone, Debug)]
pub struct OutputBuildRequest {
    pub include_sdist: bool,
    pub include_wheel: bool,
    pub out: Option<PathBuf>,
    pub dry_run: bool,
}

#[derive(Clone, Debug)]
pub struct OutputPublishRequest {
    pub registry: Option<String>,
    pub token_env: Option<String>,
    pub dry_run: bool,
}

#[derive(Clone, Debug)]
pub struct ProjectInstallRequest {
    pub frozen: bool,
}

#[derive(Clone, Debug)]
pub struct WorkspaceInstallRequest {
    pub frozen: bool,
}

#[derive(Clone, Debug)]
pub enum EnvMode {
    Info,
    Paths,
    Python,
    Unknown(String),
}

#[derive(Clone, Debug)]
pub struct EnvRequest {
    pub mode: EnvMode,
}

#[derive(Clone, Debug)]
pub struct StorePrefetchRequest {
    pub workspace: bool,
    pub dry_run: bool,
}

#[derive(Clone, Debug, Default)]
pub struct QualityTidyRequest;

#[derive(Clone, Debug)]
pub struct WorkflowRunRequest {
    pub entry: Option<String>,
    pub target: Option<String>,
    pub args: Vec<String>,
}

#[derive(Clone, Debug)]
pub struct ProjectAddRequest {
    pub specs: Vec<String>,
}

#[derive(Clone, Debug)]
pub struct ProjectRemoveRequest {
    pub specs: Vec<String>,
}

#[derive(Clone, Debug)]
pub struct ProjectUpdateRequest {
    pub specs: Vec<String>,
}

#[derive(Clone, Debug)]
pub struct MigrateRequest {
    pub source: Option<String>,
    pub dev_source: Option<String>,
    pub write: bool,
    pub allow_dirty: bool,
    pub lock_only: bool,
    pub no_autopin: bool,
}

#[derive(Clone, Debug, Default)]
pub struct LockUpgradeRequest;

#[derive(Clone, Debug, Default)]
pub struct WorkspaceTidyRequest;

#[derive(Clone, Debug)]
pub struct ToolCommandRequest {
    pub args: Vec<String>,
}

pub fn project_init(ctx: &CommandContext, request: ProjectInitRequest) -> Result<ExecutionOutcome> {
    ProjectInitHandler.handle(ctx, request)
}

pub fn cache_stats(ctx: &CommandContext, request: CacheStatsRequest) -> Result<ExecutionOutcome> {
    CacheStatsHandler.handle(ctx, request)
}

pub fn cache_path(ctx: &CommandContext, request: CachePathRequest) -> Result<ExecutionOutcome> {
    CachePathHandler.handle(ctx, request)
}

pub fn workspace_list(
    ctx: &CommandContext,
    request: WorkspaceListRequest,
) -> Result<ExecutionOutcome> {
    WorkspaceListHandler.handle(ctx, request)
}

pub fn lock_diff(ctx: &CommandContext, request: LockDiffRequest) -> Result<ExecutionOutcome> {
    LockDiffHandler.handle(ctx, request)
}

pub fn cache_prune(ctx: &CommandContext, request: CachePruneRequest) -> Result<ExecutionOutcome> {
    CachePruneHandler.handle(ctx, request)
}

pub fn workspace_verify(
    ctx: &CommandContext,
    request: WorkspaceVerifyRequest,
) -> Result<ExecutionOutcome> {
    WorkspaceVerifyHandler.handle(ctx, request)
}

pub fn workflow_test(
    ctx: &CommandContext,
    request: WorkflowTestRequest,
) -> Result<ExecutionOutcome> {
    WorkflowTestHandler.handle(ctx, request)
}

pub fn output_build(ctx: &CommandContext, request: OutputBuildRequest) -> Result<ExecutionOutcome> {
    OutputBuildHandler.handle(ctx, request)
}

pub fn output_publish(
    ctx: &CommandContext,
    request: OutputPublishRequest,
) -> Result<ExecutionOutcome> {
    OutputPublishHandler.handle(ctx, request)
}

pub fn project_install(
    ctx: &CommandContext,
    request: ProjectInstallRequest,
) -> Result<ExecutionOutcome> {
    ProjectInstallHandler.handle(ctx, request)
}

pub fn workspace_install(
    ctx: &CommandContext,
    request: WorkspaceInstallRequest,
) -> Result<ExecutionOutcome> {
    WorkspaceInstallHandler.handle(ctx, request)
}

pub fn env(ctx: &CommandContext, request: EnvRequest) -> Result<ExecutionOutcome> {
    EnvHandler.handle(ctx, request)
}

pub fn store_prefetch(
    ctx: &CommandContext,
    request: StorePrefetchRequest,
) -> Result<ExecutionOutcome> {
    StorePrefetchHandler.handle(ctx, request)
}

pub fn quality_tidy(ctx: &CommandContext, request: QualityTidyRequest) -> Result<ExecutionOutcome> {
    QualityTidyHandler.handle(ctx, request)
}

pub fn quality_fmt(_ctx: &CommandContext, request: ToolCommandRequest) -> Result<ExecutionOutcome> {
    Ok(ExecutionOutcome::success(
        "stubbed quality fmt",
        json!({ "args": request.args }),
    ))
}

pub fn quality_lint(
    _ctx: &CommandContext,
    request: ToolCommandRequest,
) -> Result<ExecutionOutcome> {
    Ok(ExecutionOutcome::success(
        "stubbed quality lint",
        json!({ "args": request.args }),
    ))
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExecutionOutcome {
    pub status: CommandStatus,
    pub message: String,
    #[serde(default)]
    pub details: Value,
}

impl ExecutionOutcome {
    pub fn success(message: impl Into<String>, details: Value) -> Self {
        Self {
            status: CommandStatus::Ok,
            message: message.into(),
            details,
        }
    }

    pub fn failure(message: impl Into<String>, details: Value) -> Self {
        Self {
            status: CommandStatus::Failure,
            message: message.into(),
            details,
        }
    }

    pub fn user_error(message: impl Into<String>, details: Value) -> Self {
        Self {
            status: CommandStatus::UserError,
            message: message.into(),
            details,
        }
    }
}

#[derive(thiserror::Error, Debug)]
#[error("{message}")]
struct InstallUserError {
    message: String,
    details: Value,
}

impl InstallUserError {
    fn new(message: impl Into<String>, details: Value) -> Self {
        Self {
            message: message.into(),
            details,
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum CommandStatus {
    Ok,
    UserError,
    Failure,
}

fn env_outcome(ctx: &CommandContext, mode: EnvMode) -> Result<ExecutionOutcome> {
    match mode {
        EnvMode::Python => {
            let interpreter = ctx.python_runtime().detect_interpreter()?;
            Ok(ExecutionOutcome::success(
                interpreter.clone(),
                json!({
                    "mode": "python",
                    "interpreter": interpreter,
                }),
            ))
        }
        EnvMode::Info => {
            let py = match python_context(ctx) {
                Ok(py) => py,
                Err(outcome) => return Ok(outcome),
            };
            let mut details = env_details(&py);
            if let Value::Object(ref mut map) = details {
                map.insert("mode".to_string(), Value::String("info".to_string()));
            }
            Ok(ExecutionOutcome::success(
                format!(
                    "interpreter {} • project {}",
                    py.python,
                    py.project_root.display()
                ),
                details,
            ))
        }
        EnvMode::Paths => {
            let py = match python_context(ctx) {
                Ok(py) => py,
                Err(outcome) => return Ok(outcome),
            };
            let mut details = env_details(&py);
            let pythonpath_os = OsString::from(&py.pythonpath);
            let os_paths = env::split_paths(&pythonpath_os)
                .map(|p| p.display().to_string())
                .collect::<Vec<_>>();
            if let Value::Object(ref mut map) = details {
                map.insert("mode".to_string(), Value::String("paths".to_string()));
                map.insert(
                    "paths".to_string(),
                    Value::Array(os_paths.iter().map(|p| Value::String(p.clone())).collect()),
                );
            }
            Ok(ExecutionOutcome::success(
                format!("pythonpath entries: {}", os_paths.len()),
                details,
            ))
        }
        EnvMode::Unknown(other) => bail!("px env mode `{other}` not implemented"),
    }
}

pub fn workflow_run(ctx: &CommandContext, request: WorkflowRunRequest) -> Result<ExecutionOutcome> {
    let py_ctx = match python_context(ctx) {
        Ok(py) => py,
        Err(outcome) => return Ok(outcome),
    };
    let extra_args = request.args.clone();
    let command_args = json!({
        "entry": request.entry,
        "target": request.target,
        "args": extra_args,
    });
    if let Some(entry) = request.entry.as_deref() {
        if let Some(target) = detect_passthrough_target(entry, &py_ctx) {
            return run_passthrough(ctx, &py_ctx, target, extra_args, &command_args);
        }
    }

    let resolved = match request.entry.clone() {
        Some(entry) => ResolvedEntry::explicit(entry),
        None => {
            let manifest = py_ctx.project_root.join("pyproject.toml");
            if !manifest.exists() {
                return Ok(DefaultEntryIssue::MissingManifest(manifest).into_outcome(&py_ctx));
            }
            match infer_default_entry(&manifest)? {
                Some(entry) => entry,
                None => {
                    return Ok(DefaultEntryIssue::NoScripts(manifest).into_outcome(&py_ctx));
                }
            }
        }
    };

    run_module_entry(ctx, &py_ctx, resolved, extra_args, &command_args)
}

#[derive(Debug, Clone)]
struct ResolvedEntry {
    entry: String,
    source: EntrySource,
}

impl ResolvedEntry {
    fn explicit(entry: String) -> Self {
        Self {
            entry,
            source: EntrySource::Explicit,
        }
    }
}

#[derive(Debug, Clone)]
enum EntrySource {
    Explicit,
    ProjectScript { script: String },
    PackageCli { package: String },
}

impl EntrySource {
    fn label(&self) -> &'static str {
        match self {
            EntrySource::Explicit => "explicit",
            EntrySource::ProjectScript { .. } => "project-scripts",
            EntrySource::PackageCli { .. } => "package-cli",
        }
    }

    fn script_name(&self) -> Option<&str> {
        match self {
            EntrySource::ProjectScript { script } => Some(script.as_str()),
            _ => None,
        }
    }

    fn is_inferred(&self) -> bool {
        !matches!(self, EntrySource::Explicit)
    }
}

#[derive(Debug)]
enum DefaultEntryIssue {
    MissingManifest(PathBuf),
    NoScripts(PathBuf),
}

impl DefaultEntryIssue {
    fn into_outcome(self, ctx: &PythonContext) -> ExecutionOutcome {
        match self {
            DefaultEntryIssue::MissingManifest(path) => ExecutionOutcome::user_error(
                format!("pyproject.toml not found in {}", ctx.project_root.display()),
                json!({
                    "hint": "run `px migrate --apply` or pass ENTRY explicitly",
                    "project_root": ctx.project_root.display().to_string(),
                    "manifest": path.display().to_string(),
                }),
            ),
            DefaultEntryIssue::NoScripts(path) => ExecutionOutcome::user_error(
                "no default entry found; add [project.scripts] or pass ENTRY",
                json!({
                    "hint": "add [project.scripts] to pyproject.toml or run `px run <module>`",
                    "manifest": path.display().to_string(),
                }),
            ),
        }
    }
}

#[derive(Debug, Clone)]
struct PassthroughTarget {
    program: String,
    display: String,
    reason: PassthroughReason,
    resolved: Option<String>,
}

#[derive(Debug, Clone)]
enum PassthroughReason {
    PythonAlias,
    ExecutablePath,
    PythonScript {
        script_arg: String,
        script_path: String,
    },
}

fn run_module_entry(
    core_ctx: &CommandContext,
    py_ctx: &PythonContext,
    resolved: ResolvedEntry,
    extra_args: Vec<String>,
    command_args: &Value,
) -> Result<ExecutionOutcome> {
    let ResolvedEntry { entry, source } = resolved;
    let mut python_args = vec!["-m".to_string(), entry.clone()];
    python_args.extend(extra_args.iter().cloned());

    let mut envs = py_ctx.base_env(command_args)?;
    envs.push(("PX_RUN_ENTRY".into(), entry.clone()));

    let output = core_ctx.python_runtime().run_command(
        &py_ctx.python,
        &python_args,
        &envs,
        &py_ctx.project_root,
    )?;
    let mut details = json!({
        "mode": "module",
        "entry": entry.clone(),
        "args": extra_args,
        "source": source.label(),
    });
    if let Some(script) = source.script_name() {
        details["script"] = Value::String(script.to_string());
    }
    if source.is_inferred() {
        details["defaulted"] = Value::Bool(true);
    }
    if let EntrySource::PackageCli { package } = &source {
        details["package"] = Value::String(package.clone());
    }

    Ok(outcome_from_output(
        "run",
        &entry,
        output,
        "px run",
        Some(details),
    ))
}

fn run_passthrough(
    core_ctx: &CommandContext,
    py_ctx: &PythonContext,
    target: PassthroughTarget,
    extra_args: Vec<String>,
    command_args: &Value,
) -> Result<ExecutionOutcome> {
    let PassthroughTarget {
        program,
        display,
        reason,
        resolved,
    } = target;
    let envs = py_ctx.base_env(command_args)?;
    let program_args = match &reason {
        PassthroughReason::PythonScript { script_arg, .. } => {
            let mut args = Vec::with_capacity(extra_args.len() + 1);
            args.push(script_arg.clone());
            args.extend(extra_args.clone());
            args
        }
        _ => extra_args.clone(),
    };
    let output = core_ctx.python_runtime().run_command(
        &program,
        &program_args,
        &envs,
        &py_ctx.project_root,
    )?;
    let mut details = json!({
        "mode": "passthrough",
        "program": display.clone(),
        "args": extra_args,
    });
    if let Some(resolved_path) = resolved {
        details["resolved_program"] = Value::String(resolved_path);
    }
    match reason {
        PassthroughReason::PythonAlias => {
            details["uses_px_python"] = Value::Bool(true);
        }
        PassthroughReason::ExecutablePath => {}
        PassthroughReason::PythonScript { script_path, .. } => {
            details["uses_px_python"] = Value::Bool(true);
            details["script"] = Value::String(script_path);
        }
    }

    Ok(outcome_from_output(
        "run",
        &display,
        output,
        "px run",
        Some(details),
    ))
}

fn infer_default_entry(manifest: &Path) -> Result<Option<ResolvedEntry>> {
    let contents = fs::read_to_string(manifest)?;
    let doc: DocumentMut = contents.parse()?;
    let project = project_table(&doc)?;

    if let Some((script, module)) = first_script_entry(project) {
        return Ok(Some(ResolvedEntry {
            entry: module,
            source: EntrySource::ProjectScript { script },
        }));
    }

    if let Some(name) = project.get("name").and_then(Item::as_str) {
        if !name.trim().is_empty() {
            let module = package_module_name(name);
            return Ok(Some(ResolvedEntry {
                entry: format!("{module}.cli"),
                source: EntrySource::PackageCli {
                    package: name.to_string(),
                },
            }));
        }
    }

    Ok(None)
}

fn first_script_entry(project: &Table) -> Option<(String, String)> {
    let scripts = project.get("scripts")?.as_table()?;
    for (name, item) in scripts.iter() {
        if let Some(value) = item.as_str() {
            if let Some(module) = parse_script_value(value) {
                return Some((name.to_string(), module));
            }
        }
    }
    None
}

fn parse_script_value(value: &str) -> Option<String> {
    let trimmed = value.trim();
    if trimmed.is_empty() {
        return None;
    }
    let module = trimmed
        .split(|c| c == ':' || c == ' ')
        .next()
        .map(|part| part.trim())
        .unwrap_or("");
    if module.is_empty() {
        None
    } else {
        Some(module.to_string())
    }
}

fn package_module_name(name: &str) -> String {
    name.replace('-', "_").replace(' ', "_")
}

fn detect_passthrough_target(entry: &str, ctx: &PythonContext) -> Option<PassthroughTarget> {
    if looks_like_python_alias(entry) {
        return Some(PassthroughTarget {
            program: ctx.python.clone(),
            display: entry.to_string(),
            reason: PassthroughReason::PythonAlias,
            resolved: Some(ctx.python.clone()),
        });
    }

    if let Some((script_arg, script_path)) = python_script_target(entry, &ctx.project_root) {
        return Some(PassthroughTarget {
            program: ctx.python.clone(),
            display: entry.to_string(),
            reason: PassthroughReason::PythonScript {
                script_arg,
                script_path,
            },
            resolved: Some(ctx.python.clone()),
        });
    }

    if looks_like_path_target(entry) {
        let (program, resolved) = resolve_executable_path(entry, &ctx.project_root);
        return Some(PassthroughTarget {
            program,
            display: entry.to_string(),
            reason: PassthroughReason::ExecutablePath,
            resolved,
        });
    }

    None
}

fn looks_like_python_alias(entry: &str) -> bool {
    let lower = entry.to_lowercase();
    lower == "python"
        || lower == "python3"
        || lower.starts_with("python3.")
        || lower == "py"
        || lower == "py3"
}

fn looks_like_path_target(entry: &str) -> bool {
    let path = Path::new(entry);
    path.components().count() > 1 || entry.contains('/') || entry.contains('\\')
}

fn python_script_target(entry: &str, root: &Path) -> Option<(String, String)> {
    if !looks_like_python_script(entry) {
        return None;
    }
    let script_arg = entry.to_string();
    let script_path = resolve_script_path(entry, root);
    Some((script_arg, script_path))
}

fn looks_like_python_script(entry: &str) -> bool {
    Path::new(entry)
        .extension()
        .and_then(|ext| ext.to_str())
        .map(|ext| ext.eq_ignore_ascii_case("py") || ext.eq_ignore_ascii_case("pyw"))
        .unwrap_or(false)
}

fn resolve_script_path(entry: &str, root: &Path) -> String {
    let path = Path::new(entry);
    if path.is_absolute() {
        entry.to_string()
    } else {
        root.join(path).display().to_string()
    }
}

fn resolve_executable_path(entry: &str, root: &Path) -> (String, Option<String>) {
    let path = Path::new(entry);
    if path.is_absolute() {
        (entry.to_string(), Some(entry.to_string()))
    } else {
        let resolved = root.join(path);
        let display = resolved.display().to_string();
        (display.clone(), Some(display))
    }
}

fn workflow_test_outcome(ctx: &CommandContext, pytest_args: &[String]) -> Result<ExecutionOutcome> {
    let py_ctx = match python_context(ctx) {
        Ok(py) => py,
        Err(outcome) => return Ok(outcome),
    };
    let command_args = json!({ "pytest_args": pytest_args });
    let mut envs = py_ctx.base_env(&command_args)?;
    envs.push(("PX_TEST_RUNNER".into(), "pytest".into()));

    if ctx.config().test.fallback_builtin {
        return run_builtin_tests("test", ctx, py_ctx, envs);
    }

    let mut pytest_cmd = vec!["-m".to_string(), "pytest".to_string(), "tests".to_string()];
    pytest_cmd.extend(pytest_args.iter().cloned());

    let output = ctx.python_runtime().run_command(
        &py_ctx.python,
        &pytest_cmd,
        &envs,
        &py_ctx.project_root,
    )?;
    if output.code == 0 {
        return Ok(outcome_from_output(
            "test", "pytest", output, "px test", None,
        ));
    }

    if missing_pytest(&output.stderr) {
        return run_builtin_tests("test", ctx, py_ctx, envs);
    }

    Ok(ExecutionOutcome::failure(
        format!("px test failed (exit {})", output.code),
        json!({
            "stdout": output.stdout,
            "stderr": output.stderr,
            "code": output.code,
        }),
    ))
}

fn output_build_outcome(
    ctx: &CommandContext,
    request: &OutputBuildRequest,
) -> Result<ExecutionOutcome> {
    let py_ctx = match python_context(ctx) {
        Ok(py) => py,
        Err(outcome) => return Ok(outcome),
    };
    let targets = build_targets_from_request(request);
    let out_dir = resolve_output_dir_from_request(&py_ctx, request.out.as_ref())?;

    if request.dry_run {
        let artifacts = collect_artifact_summaries(&out_dir, None, &py_ctx)?;
        let details = json!({
            "artifacts": artifacts,
            "out_dir": relative_path_str(&out_dir, &py_ctx.project_root),
            "format": targets.label(),
            "dry_run": true,
        });
        let message = format!(
            "px build: dry-run (format={}, out={})",
            targets.label(),
            relative_path_str(&out_dir, &py_ctx.project_root)
        );
        return Ok(ExecutionOutcome::success(message, details));
    }

    ctx.fs()
        .create_dir_all(&out_dir)
        .context("creating build directory")?;
    let (name, version) = project_name_version(&py_ctx.project_root)?;
    let mut produced = Vec::new();
    if targets.sdist {
        produced.push(write_sdist(&py_ctx, &out_dir, &name, &version)?);
    }
    if targets.wheel {
        produced.push(write_wheel(&py_ctx, &out_dir, &name, &version)?);
    }

    let artifacts = summarize_selected_artifacts(&produced, &py_ctx)?;
    if artifacts.is_empty() {
        return Ok(ExecutionOutcome::user_error(
            "px build: build completed but produced no artifacts",
            json!({
                "out_dir": relative_path_str(&out_dir, &py_ctx.project_root),
                "format": targets.label(),
            }),
        ));
    }

    let first = &artifacts[0];
    let sha_short: String = first.sha256.chars().take(12).collect();
    let message = if artifacts.len() == 1 {
        format!(
            "px build: wrote {} ({}, sha256={}…)",
            first.path,
            format_bytes(first.bytes),
            sha_short
        )
    } else {
        format!(
            "px build: wrote {} artifacts ({}, sha256={}…)",
            artifacts.len(),
            format_bytes(first.bytes),
            sha_short
        )
    };
    let details = json!({
        "artifacts": artifacts,
        "out_dir": relative_path_str(&out_dir, &py_ctx.project_root),
        "format": targets.label(),
        "dry_run": false,
        "skip_tests": ctx.config().test.skip_tests_flag.clone(),
    });
    Ok(ExecutionOutcome::success(message, details))
}

fn output_publish_outcome(
    ctx: &CommandContext,
    request: &OutputPublishRequest,
) -> Result<ExecutionOutcome> {
    let py_ctx = match python_context(ctx) {
        Ok(py) => py,
        Err(outcome) => return Ok(outcome),
    };
    let registry = request
        .registry
        .as_deref()
        .filter(|s| !s.is_empty())
        .unwrap_or("pypi");
    let token_env = request
        .token_env
        .clone()
        .filter(|s| !s.is_empty())
        .unwrap_or_else(|| ctx.config().publish.default_token_env.to_string());
    let build_dir = py_ctx.project_root.join("build");
    let artifacts = collect_artifact_summaries(&build_dir, None, &py_ctx)?;
    if artifacts.is_empty() {
        return Ok(ExecutionOutcome::user_error(
            "px publish: no artifacts found (run `px build` first)",
            json!({ "build_dir": relative_path_str(&build_dir, &py_ctx.project_root) }),
        ));
    }

    if request.dry_run {
        let details = json!({
            "registry": registry,
            "token_env": token_env,
            "dry_run": true,
            "artifacts": artifacts.clone(),
        });
        let message = format!(
            "px publish: dry-run to {registry} ({} artifacts)",
            artifacts.len()
        );
        return Ok(ExecutionOutcome::success(message, details));
    }

    if !ctx.is_online() {
        return Ok(ExecutionOutcome::user_error(
            "px publish: PX_ONLINE=1 required for uploads",
            json!({
                "registry": registry,
                "token_env": token_env,
                "hint": format!(
                    "export PX_ONLINE=1 && {token_env}=<token> before publishing"
                ),
            }),
        ));
    }

    if !ctx.env_contains(&token_env) {
        return Ok(ExecutionOutcome::user_error(
            format!("px publish: {token_env} must be set"),
            json!({
                "registry": registry,
                "token_env": token_env,
                "hint": format!("export {token_env}=<token> before publishing"),
            }),
        ));
    }

    let details = json!({
        "registry": registry,
        "token_env": token_env,
        "dry_run": false,
        "artifacts": artifacts.clone(),
    });
    let message = format!(
        "px publish: uploaded {} artifacts to {registry}",
        artifacts.len()
    );
    Ok(ExecutionOutcome::success(message, details))
}

#[derive(Clone, Serialize)]
struct ArtifactSummary {
    path: String,
    bytes: u64,
    sha256: String,
}

#[derive(Clone, Copy)]
struct BuildTargets {
    sdist: bool,
    wheel: bool,
}

impl BuildTargets {
    fn label(&self) -> &'static str {
        match (self.sdist, self.wheel) {
            (true, true) => "both",
            (true, false) => "sdist",
            (false, true) => "wheel",
            (false, false) => "none",
        }
    }
}

fn build_targets_from_request(request: &OutputBuildRequest) -> BuildTargets {
    let mut targets = BuildTargets {
        sdist: request.include_sdist,
        wheel: request.include_wheel,
    };
    if !targets.sdist && !targets.wheel {
        targets = BuildTargets {
            sdist: true,
            wheel: true,
        };
    }
    targets
}

fn resolve_output_dir_from_request(ctx: &PythonContext, out: Option<&PathBuf>) -> Result<PathBuf> {
    if let Some(path) = out {
        if path.is_absolute() {
            Ok(path.clone())
        } else {
            Ok(ctx.project_root.join(path))
        }
    } else {
        Ok(ctx.project_root.join("build"))
    }
}

fn collect_artifact_summaries(
    dir: &Path,
    targets: Option<&BuildTargets>,
    ctx: &PythonContext,
) -> Result<Vec<ArtifactSummary>> {
    if !dir.exists() {
        return Ok(Vec::new());
    }
    let mut entries = Vec::new();
    for entry in fs::read_dir(dir)? {
        let path = entry?.path();
        if !path.is_file() {
            continue;
        }
        if let Some(targets) = targets {
            if !artifact_matches_format(&path, targets) {
                continue;
            }
        }
        let bytes = fs::metadata(&path)?.len();
        let sha256 = compute_file_sha256(&path)?;
        entries.push(ArtifactSummary {
            path: relative_path_str(&path, &ctx.project_root),
            bytes,
            sha256,
        });
    }
    entries.sort_by(|a, b| a.path.cmp(&b.path));
    Ok(entries)
}

fn artifact_matches_format(path: &Path, targets: &BuildTargets) -> bool {
    if targets.sdist {
        if let Some(ext) = path.extension().and_then(|s| s.to_str()) {
            if ext.eq_ignore_ascii_case("gz") {
                return true;
            }
        }
    }
    if targets.wheel {
        if let Some(ext) = path.extension().and_then(|s| s.to_str()) {
            if ext.eq_ignore_ascii_case("whl") {
                return true;
            }
        }
    }
    false
}

fn relative_path_str(path: &Path, root: &Path) -> String {
    path.strip_prefix(root)
        .unwrap_or(path)
        .display()
        .to_string()
}

fn format_bytes(bytes: u64) -> String {
    const KB: f64 = 1024.0;
    const MB: f64 = KB * 1024.0;
    if bytes as f64 >= MB {
        format!("{:.1} MB", bytes as f64 / MB)
    } else if bytes as f64 >= KB {
        format!("{:.1} KB", bytes as f64 / KB)
    } else {
        format!("{} B", bytes)
    }
}

fn summarize_selected_artifacts(
    paths: &[PathBuf],
    ctx: &PythonContext,
) -> Result<Vec<ArtifactSummary>> {
    let mut entries = Vec::new();
    for path in paths {
        let bytes = fs::metadata(path)?.len();
        let sha256 = compute_file_sha256(path)?;
        entries.push(ArtifactSummary {
            path: relative_path_str(path, &ctx.project_root),
            bytes,
            sha256,
        });
    }
    Ok(entries)
}

fn project_name_version(root: &Path) -> Result<(String, String)> {
    let pyproject_path = root.join("pyproject.toml");
    let contents = fs::read_to_string(&pyproject_path)?;
    let doc: DocumentMut = contents.parse()?;
    let project = project_table(&doc)?;
    let name = project
        .get("name")
        .and_then(Item::as_str)
        .ok_or_else(|| anyhow!("pyproject missing [project].name"))?
        .to_string();
    let version = project
        .get("version")
        .and_then(Item::as_str)
        .ok_or_else(|| anyhow!("pyproject missing [project].version"))?
        .to_string();
    Ok((name, version))
}

fn write_sdist(ctx: &PythonContext, out_dir: &Path, name: &str, version: &str) -> Result<PathBuf> {
    let filename = format!("{}-{}.tar.gz", name, version);
    let path = out_dir.join(filename);
    let file = File::create(&path)?;
    let encoder = GzEncoder::new(file, Compression::default());
    let mut tar = Builder::new(encoder);
    let base = format!("{}-{}", name, version);
    let pyproject = ctx.project_root.join("pyproject.toml");
    if pyproject.exists() {
        tar.append_path_with_name(pyproject, format!("{base}/pyproject.toml"))?;
    }
    let readme = ctx.project_root.join("README.md");
    if readme.exists() {
        tar.append_path_with_name(readme, format!("{base}/README.md"))?;
    }
    let src = ctx.project_root.join("src");
    if src.exists() {
        tar.append_dir_all(format!("{base}/src"), src)?;
    }
    tar.finish()?;
    let encoder = tar.into_inner()?;
    encoder.finish()?;
    Ok(path)
}

fn write_wheel(ctx: &PythonContext, out_dir: &Path, name: &str, version: &str) -> Result<PathBuf> {
    let normalized = name.replace('-', "_");
    let filename = format!("{}-{}-py3-none-any.whl", normalized, version);
    let path = out_dir.join(filename);
    let file = File::create(&path)?;
    let mut zip = ZipWriter::new(file);
    let src = ctx.project_root.join("src");
    if src.exists() {
        append_dir_to_zip(&mut zip, &src, &normalized)?;
    }
    let options = FileOptions::default().compression_method(CompressionMethod::Deflated);
    let metadata = format!(
        "Metadata-Version: 2.1\nName: {}\nVersion: {}\n",
        name, version
    );
    zip.start_file(format!("{normalized}/METADATA"), options)?;
    zip.write_all(metadata.as_bytes())?;
    zip.start_file(format!("{normalized}/WHEEL"), options)?;
    zip.write_all(b"Wheel-Version: 1.0\nGenerator: px\nTag: py3-none-any\n")?;
    zip.start_file(format!("{normalized}/RECORD"), options)?;
    zip.write_all(b"")?;
    zip.finish()?;
    Ok(path)
}

fn append_dir_to_zip(zip: &mut ZipWriter<File>, src: &Path, prefix: &str) -> Result<()> {
    if !src.exists() {
        return Ok(());
    }
    for entry in fs::read_dir(src)? {
        let entry = entry?;
        let path = entry.path();
        let name = entry.file_name();
        let name = name.to_string_lossy();
        if path.is_dir() {
            append_dir_to_zip(zip, &path, &format!("{prefix}/{name}"))?;
        } else {
            let options = FileOptions::default().compression_method(CompressionMethod::Deflated);
            zip.start_file(format!("{prefix}/{name}"), options)?;
            let mut file = File::open(&path)?;
            io::copy(&mut file, zip)?;
        }
    }
    Ok(())
}

fn run_builtin_tests(
    command_name: &str,
    core_ctx: &CommandContext,
    ctx: PythonContext,
    mut envs: Vec<(String, String)>,
) -> Result<ExecutionOutcome> {
    envs.push(("PX_TEST_RUNNER".into(), "builtin".into()));
    let script = "from sample_px_app import cli\nassert cli.greet() == 'Hello, World!'\nprint('px fallback test passed')";
    let args = vec!["-c".to_string(), script.to_string()];
    let output =
        core_ctx
            .python_runtime()
            .run_command(&ctx.python, &args, &envs, &ctx.project_root)?;
    Ok(outcome_from_output(
        command_name,
        "builtin",
        output,
        "px test",
        None,
    ))
}

fn env_details(ctx: &PythonContext) -> Value {
    json!({
        "interpreter": ctx.python.clone(),
        "project_root": ctx.project_root.display().to_string(),
        "pythonpath": ctx.pythonpath.clone(),
        "env": {
            "PX_PROJECT_ROOT": ctx.project_root.display().to_string(),
            "PYTHONPATH": ctx.pythonpath.clone(),
        }
    })
}

fn store_prefetch_outcome(
    ctx: &CommandContext,
    request: &StorePrefetchRequest,
) -> Result<ExecutionOutcome> {
    if !request.dry_run && !ctx.is_online() {
        return Ok(ExecutionOutcome::user_error(
            "PX_ONLINE=1 required for downloads",
            json!({
                "status": "gated-offline",
                "dry_run": request.dry_run,
                "hint": "export PX_ONLINE=1 or add --dry-run to inspect work without downloading",
            }),
        ));
    }

    if request.workspace {
        workspace::prefetch(ctx, request.dry_run)
    } else {
        handle_project_prefetch(ctx, request.dry_run)
    }
}

pub fn migrate(ctx: &CommandContext, request: MigrateRequest) -> Result<ExecutionOutcome> {
    let root = match discover_project_root()? {
        Some(path) => path,
        None => env::current_dir().context("unable to determine current directory")?,
    };
    let pyproject_path = root.join("pyproject.toml");
    let pyproject_exists = pyproject_path.exists();

    let source_override = request.source.clone();
    let dev_override = request.dev_source.clone();

    let requirements_path = match resolve_onboard_path(
        &root,
        source_override.as_deref(),
        "requirements.txt",
    ) {
        Ok(path) => path,
        Err(err) => {
            return Ok(ExecutionOutcome::user_error(
                "px migrate: override path invalid",
                json!({
                    "error": err.to_string(),
                    "hint": "Override path invalid; specify a repo-relative file before retrying.",
                }),
            ))
        }
    };
    let dev_path = match resolve_onboard_path(
        &root,
        dev_override.as_deref(),
        "requirements-dev.txt",
    ) {
        Ok(path) => path,
        Err(err) => {
            return Ok(ExecutionOutcome::user_error(
                "px migrate: override path invalid",
                json!({
                    "error": err.to_string(),
                    "hint": "Override path invalid; specify a repo-relative file before retrying.",
                }),
            ))
        }
    };

    if !pyproject_exists && requirements_path.is_none() && dev_path.is_none() {
        return Ok(ExecutionOutcome::user_error(
            "px migrate: no project files found",
            json!({
                "project_type": "bare",
                "sources": [],
                "hint": "add pyproject.toml or requirements.txt before running px migrate",
            }),
        ));
    }

    let mut packages = Vec::new();
    let mut source_summaries = Vec::new();

    if pyproject_exists {
        let (summary, mut rows) = collect_pyproject_packages(&root, &pyproject_path)?;
        source_summaries.push(summary);
        packages.append(&mut rows);
    }

    if let Some(path) = requirements_path.as_ref() {
        let (summary, mut rows) =
            collect_requirement_packages(&root, path, "requirements", "prod")?;
        source_summaries.push(summary);
        packages.append(&mut rows);
    }

    if let Some(path) = dev_path.as_ref() {
        let (summary, mut rows) =
            collect_requirement_packages(&root, path, "requirements-dev", "dev")?;
        source_summaries.push(summary);
        packages.append(&mut rows);
    }

    let project_type = if pyproject_exists {
        if requirements_path.is_some() || dev_path.is_some() {
            "pyproject+requirements"
        } else {
            "pyproject"
        }
    } else if requirements_path.is_some() || dev_path.is_some() {
        "requirements"
    } else {
        "bare"
    };

    let prod_count = packages.iter().filter(|pkg| pkg.scope == "prod").count();
    let dev_count = packages.iter().filter(|pkg| pkg.scope == "dev").count();
    let source_count = source_summaries.len();

    let mut message = format!(
        "px migrate: plan ready (prod: {prod_count}, dev: {dev_count}, sources: {source_count}, project: {project_type})"
    );
    let write_requested = request.write;
    let allow_dirty = request.allow_dirty;
    let lock_only = request.lock_only;
    let no_autopin = request.no_autopin;

    if lock_only && !pyproject_exists {
        return Ok(ExecutionOutcome::user_error(
            "px migrate: pyproject.toml required when --lock-only is set",
            json!({
                "hint": "Create pyproject.toml or drop --lock-only to let px write it",
            }),
        ));
    }

    let package_values: Vec<Value> = packages
        .iter()
        .map(|pkg| {
            json!({
                "name": pkg.name,
                "requested": pkg.requested,
                "scope": pkg.scope,
                "source": pkg.source,
            })
        })
        .collect();

    let mut details = json!({
        "project_type": project_type,
        "sources": source_summaries,
        "packages": package_values,
        "write_requested": write_requested,
        "dry_run": !write_requested,
        "actions": {
            "pyproject_updated": false,
            "lock_written": false,
            "backups": [],
        },
    });

    if !write_requested {
        details["hint"] =
            Value::String("Preview confirmed; rerun with --apply to write changes".to_string());
        return Ok(ExecutionOutcome::success(message, details));
    }

    if !allow_dirty {
        if let Some(changes) = ctx.git().worktree_changes(&root)? {
            if !changes.is_empty() {
                details["changes"] =
                    Value::Array(changes.iter().map(|c| Value::String(c.clone())).collect());
                details["hint"] = Value::String(
                    "Repo dirty—stash, commit, or use --allow-dirty before retrying.".to_string(),
                );
                return Ok(ExecutionOutcome::user_error(
                    "px migrate: worktree dirty (stash, commit, or use --allow-dirty)",
                    details,
                ));
            }
        }
    }

    let mut backups = BackupManager::new(&root);
    let pyproject_plan = prepare_pyproject_plan(&root, &pyproject_path, lock_only, &packages)?;
    let mut pyproject_backed_up = false;
    if pyproject_plan.needs_backup() {
        backups.backup(&pyproject_plan.path)?;
        pyproject_backed_up = true;
    }
    if let Some(contents) = &pyproject_plan.contents {
        if let Some(parent) = pyproject_plan.path.parent() {
            fs::create_dir_all(parent)?;
        }
        fs::write(&pyproject_plan.path, contents)?;
    }

    let mut autopin_entries = Vec::new();
    let mut install_override: Option<InstallOverride> = None;
    let mut autopin_changed_pyproject = false;
    let mut autopin_hint = None;

    if pyproject_path.exists() {
        let marker_env = ctx.marker_environment()?;
        let autopin_snapshot = px_project::ProjectSnapshot::read_from(&root)?;
        let effects = ctx.shared_effects();
        let resolver = move |snap: &ManifestSnapshot, specs: &[String]| -> Result<Vec<PinSpec>> {
            let mut override_snapshot = snap.clone();
            override_snapshot.dependencies = specs.to_vec();
            let resolved = resolve_dependencies_with_effects(effects.as_ref(), &override_snapshot)?;
            Ok(resolved.pins)
        };
        match plan_autopin(
            &autopin_snapshot,
            &pyproject_path,
            lock_only,
            no_autopin,
            &resolver,
            &marker_env,
        )? {
            AutopinState::NotNeeded => {}
            AutopinState::Disabled { pending } => {
                if !pending.is_empty() {
                    details["autopinned"] =
                        Value::Array(pending.iter().map(|entry| entry.to_json()).collect());
                }
                details["hint"] = Value::String(
                    "Loose specs remain; drop --no-autopin or pin pyproject manually.".to_string(),
                );
                return Ok(ExecutionOutcome::user_error(
                    "px migrate: automatic pinning disabled but loose specs remain",
                    details,
                ));
            }
            AutopinState::Planned(plan) => {
                autopin_entries = plan.autopinned;
                if let Some(contents) = plan.doc_contents {
                    if !pyproject_plan.created && !pyproject_backed_up {
                        backups.backup(&pyproject_plan.path)?;
                    }
                    if let Some(parent) = pyproject_plan.path.parent() {
                        fs::create_dir_all(parent)?;
                    }
                    fs::write(&pyproject_plan.path, contents)?;
                    autopin_changed_pyproject = true;
                }
                install_override = plan.install_override;
                autopin_hint = summarize_autopins(&autopin_entries);
            }
        }
    }

    if !autopin_entries.is_empty() {
        details["autopinned"] = Value::Array(
            autopin_entries
                .iter()
                .map(|entry| entry.to_json())
                .collect(),
        );
        if autopin_hint.is_none() {
            autopin_hint = summarize_autopins(&autopin_entries);
        }
    }

    let snapshot = manifest_snapshot_at(&root)?;
    let lock_needs_backup = snapshot.lock_path.exists() && !lock_is_fresh(&snapshot)?;
    if lock_needs_backup {
        backups.backup(&snapshot.lock_path)?;
    }
    let install_outcome = match install_snapshot(ctx, &snapshot, false, install_override.as_ref()) {
        Ok(ok) => ok,
        Err(err) => match err.downcast::<InstallUserError>() {
            Ok(user) => return Ok(ExecutionOutcome::user_error(user.message, user.details)),
            Err(err) => return Err(err),
        },
    };

    let backup_summary = backups.finish();
    let pyproject_updated = pyproject_plan.updated() || autopin_changed_pyproject;
    let lock_written = matches!(install_outcome.state, InstallState::Installed);

    details["actions"]["pyproject_updated"] = Value::Bool(pyproject_updated);
    details["actions"]["lock_written"] = Value::Bool(lock_written);
    details["actions"]["backups"] = Value::Array(
        backup_summary
            .files
            .iter()
            .map(|entry| Value::String(entry.clone()))
            .collect(),
    );
    if let Some(dir) = backup_summary.directory.as_ref() {
        details["actions"]["backup_dir"] = Value::String(dir.clone());
    }

    let changes_applied = pyproject_updated || lock_written;
    if changes_applied {
        let mut hint = if let Some(dir) = backup_summary.directory.as_ref() {
            format!("Backups stored under {dir}")
        } else {
            "No backups created (new files only)".to_string()
        };
        if let Some(extra) = autopin_hint {
            if hint.is_empty() {
                hint = extra;
            } else {
                hint = format!("{hint} • {extra}");
            }
        }
        if !hint.is_empty() {
            details["hint"] = Value::String(hint);
        }
        message = format!("px migrate: plan applied (prod: {prod_count}, dev: {dev_count})");
        Ok(ExecutionOutcome::success(message, details))
    } else {
        let mut hint =
            "No changes detected; nothing to write. Run again if you expect updates.".to_string();
        if let Some(extra) = autopin_hint {
            hint = format!("{hint} • {extra}");
        }
        details["hint"] = Value::String(hint);
        Ok(ExecutionOutcome::success(
            "px migrate: nothing to apply (already in sync)",
            details,
        ))
    }
}

fn handle_project_prefetch(ctx: &CommandContext, dry_run: bool) -> Result<ExecutionOutcome> {
    let snapshot = manifest_snapshot()?;
    let lock = match load_lockfile_optional(&snapshot.lock_path)? {
        Some(lock) => lock,
        None => {
            return Ok(ExecutionOutcome::user_error(
                "px.lock not found (run `px install`)",
                json!({
                    "lockfile": snapshot.lock_path.display().to_string(),
                    "hint": "run `px install` to regenerate the lockfile",
                }),
            ))
        }
    };

    let lock_specs = match lock_prefetch_specs(&lock) {
        Ok(specs) => specs,
        Err(err) => {
            return Ok(ExecutionOutcome::user_error(
                err.to_string(),
                json!({ "lockfile": snapshot.lock_path.display().to_string() }),
            ))
        }
    };

    if lock_specs.is_empty() {
        return Ok(ExecutionOutcome::user_error(
            "px.lock does not contain artifact metadata",
            json!({ "lockfile": snapshot.lock_path.display().to_string() }),
        ));
    }

    let cache = ctx.cache();
    let store_specs = store_prefetch_specs(&lock_specs);
    let summary = ctx.cache_store().prefetch(
        &cache.path,
        &store_specs,
        StorePrefetchOptions {
            dry_run,
            parallel: 4,
        },
    )?;

    let mut details = json!({
        "lockfile": snapshot.lock_path.display().to_string(),
        "cache": {
            "path": cache.path.display().to_string(),
            "source": cache.source,
        },
        "dry_run": dry_run,
        "summary": summary,
    });
    details["status"] = Value::String(if dry_run { "dry-run" } else { "prefetched" }.to_string());

    if summary.failed > 0 {
        return Ok(ExecutionOutcome::user_error(
            "prefetch encountered errors",
            details,
        ));
    }

    let message = if dry_run {
        format!(
            "dry-run {} artifacts ({} cached)",
            summary.requested, summary.hit
        )
    } else {
        format!(
            "hydrated {} artifacts ({} cached, {} fetched)",
            summary.requested, summary.hit, summary.fetched
        )
    };

    Ok(ExecutionOutcome::success(message, details))
}

fn cache_path_outcome(ctx: &CommandContext) -> Result<ExecutionOutcome> {
    let cache = ctx.cache();
    ctx.fs()
        .create_dir_all(&cache.path)
        .context("unable to create cache directory")?;
    let canonical = ctx
        .fs()
        .canonicalize(&cache.path)
        .unwrap_or(cache.path.clone());
    let path_str = canonical.display().to_string();
    Ok(ExecutionOutcome::success(
        format!("path {path_str}"),
        json!({
            "status": "path",
            "path": path_str,
            "source": cache.source,
        }),
    ))
}

fn cache_stats_outcome(ctx: &CommandContext) -> Result<ExecutionOutcome> {
    let cache = ctx.cache();
    let usage = ctx.cache_store().compute_usage(&cache.path)?;
    let message = if usage.exists {
        format!(
            "stats: {} files, {} bytes",
            usage.total_entries, usage.total_size_bytes
        )
    } else {
        format!("cache path {} not found", cache.path.display())
    };
    Ok(ExecutionOutcome::success(
        message,
        json!({
            "status": "stats",
            "cache_path": cache.path.display().to_string(),
            "cache_exists": usage.exists,
            "total_entries": usage.total_entries,
            "total_size_bytes": usage.total_size_bytes,
        }),
    ))
}

struct CacheStatsHandler;

impl CommandHandler<CacheStatsRequest> for CacheStatsHandler {
    fn handle(
        &self,
        ctx: &CommandContext,
        _request: CacheStatsRequest,
    ) -> Result<ExecutionOutcome> {
        cache_stats_outcome(ctx)
    }
}

struct CachePathHandler;

impl CommandHandler<CachePathRequest> for CachePathHandler {
    fn handle(&self, ctx: &CommandContext, _request: CachePathRequest) -> Result<ExecutionOutcome> {
        cache_path_outcome(ctx)
    }
}

struct CachePruneHandler;

impl CommandHandler<CachePruneRequest> for CachePruneHandler {
    fn handle(&self, ctx: &CommandContext, request: CachePruneRequest) -> Result<ExecutionOutcome> {
        cache_prune_outcome(ctx, request.all, request.dry_run)
    }
}

struct WorkspaceListHandler;

impl CommandHandler<WorkspaceListRequest> for WorkspaceListHandler {
    fn handle(
        &self,
        ctx: &CommandContext,
        _request: WorkspaceListRequest,
    ) -> Result<ExecutionOutcome> {
        workspace::list(ctx)
    }
}

struct LockDiffHandler;

impl CommandHandler<LockDiffRequest> for LockDiffHandler {
    fn handle(&self, _ctx: &CommandContext, _request: LockDiffRequest) -> Result<ExecutionOutcome> {
        lock_diff_outcome()
    }
}

struct WorkspaceVerifyHandler;

impl CommandHandler<WorkspaceVerifyRequest> for WorkspaceVerifyHandler {
    fn handle(
        &self,
        ctx: &CommandContext,
        _request: WorkspaceVerifyRequest,
    ) -> Result<ExecutionOutcome> {
        workspace::verify(ctx)
    }
}

struct WorkflowTestHandler;

impl CommandHandler<WorkflowTestRequest> for WorkflowTestHandler {
    fn handle(
        &self,
        ctx: &CommandContext,
        request: WorkflowTestRequest,
    ) -> Result<ExecutionOutcome> {
        workflow_test_outcome(ctx, &request.pytest_args)
    }
}

struct OutputBuildHandler;

impl CommandHandler<OutputBuildRequest> for OutputBuildHandler {
    fn handle(
        &self,
        ctx: &CommandContext,
        request: OutputBuildRequest,
    ) -> Result<ExecutionOutcome> {
        output_build_outcome(ctx, &request)
    }
}

struct OutputPublishHandler;

impl CommandHandler<OutputPublishRequest> for OutputPublishHandler {
    fn handle(
        &self,
        ctx: &CommandContext,
        request: OutputPublishRequest,
    ) -> Result<ExecutionOutcome> {
        output_publish_outcome(ctx, &request)
    }
}

struct ProjectInstallHandler;

impl CommandHandler<ProjectInstallRequest> for ProjectInstallHandler {
    fn handle(
        &self,
        ctx: &CommandContext,
        request: ProjectInstallRequest,
    ) -> Result<ExecutionOutcome> {
        project_install_outcome(ctx, request.frozen)
    }
}

struct WorkspaceInstallHandler;

impl CommandHandler<WorkspaceInstallRequest> for WorkspaceInstallHandler {
    fn handle(
        &self,
        ctx: &CommandContext,
        request: WorkspaceInstallRequest,
    ) -> Result<ExecutionOutcome> {
        workspace::install(ctx, request.frozen)
    }
}

struct EnvHandler;

impl CommandHandler<EnvRequest> for EnvHandler {
    fn handle(&self, ctx: &CommandContext, request: EnvRequest) -> Result<ExecutionOutcome> {
        env_outcome(ctx, request.mode)
    }
}

struct StorePrefetchHandler;

impl CommandHandler<StorePrefetchRequest> for StorePrefetchHandler {
    fn handle(
        &self,
        ctx: &CommandContext,
        request: StorePrefetchRequest,
    ) -> Result<ExecutionOutcome> {
        store_prefetch_outcome(ctx, &request)
    }
}

struct QualityTidyHandler;

impl CommandHandler<QualityTidyRequest> for QualityTidyHandler {
    fn handle(
        &self,
        _ctx: &CommandContext,
        _request: QualityTidyRequest,
    ) -> Result<ExecutionOutcome> {
        quality_tidy_outcome()
    }
}

fn cache_prune_outcome(ctx: &CommandContext, all: bool, dry_run: bool) -> Result<ExecutionOutcome> {
    let cache = ctx.cache();
    if !all {
        return Ok(ExecutionOutcome::user_error(
            "px cache prune currently requires --all",
            json!({
                "cache_path": cache.path.display().to_string(),
                "dry_run": dry_run,
                "hint": "rerun with --all to prune every cached artifact",
            }),
        ));
    }

    if !cache.path.exists() {
        return Ok(ExecutionOutcome::success(
            format!("cache path {} not found", cache.path.display()),
            json!({
                "cache_path": cache.path.display().to_string(),
                "cache_exists": false,
                "dry_run": dry_run,
                "candidate_entries": 0,
                "candidate_size_bytes": 0,
                "deleted_entries": 0,
                "deleted_size_bytes": 0,
                "errors": [],
                "status": "no-cache",
            }),
        ));
    }

    let walk = ctx.cache_store().collect_walk(&cache.path)?;
    let candidate_entries = walk.files.len() as u64;
    let candidate_size_bytes = walk.total_bytes;

    if candidate_entries == 0 {
        return Ok(ExecutionOutcome::success(
            format!("nothing to remove under {}", cache.path.display()),
            json!({
                "cache_path": cache.path.display().to_string(),
                "cache_exists": true,
                "dry_run": dry_run,
                "candidate_entries": 0,
                "candidate_size_bytes": 0,
                "deleted_entries": 0,
                "deleted_size_bytes": 0,
                "errors": [],
                "status": if dry_run { "dry-run" } else { "success" },
            }),
        ));
    }

    if dry_run {
        return Ok(ExecutionOutcome::success(
            format!(
                "would remove {} files ({candidate_size_bytes} bytes)",
                candidate_entries
            ),
            json!({
                "cache_path": cache.path.display().to_string(),
                "cache_exists": true,
                "dry_run": true,
                "candidate_entries": candidate_entries,
                "candidate_size_bytes": candidate_size_bytes,
                "deleted_entries": 0,
                "deleted_size_bytes": 0,
                "errors": [],
                "status": "dry-run",
            }),
        ));
    }

    let prune = ctx.cache_store().prune(&walk);
    let error_count = prune.errors.len();
    let errors_json: Vec<_> = prune
        .errors
        .iter()
        .map(|err| {
            json!({
                "path": err.path.display().to_string(),
                "error": err.error,
            })
        })
        .collect();
    let details = json!({
        "cache_path": cache.path.display().to_string(),
        "cache_exists": true,
        "dry_run": false,
        "candidate_entries": prune.candidate_entries,
        "candidate_size_bytes": prune.candidate_size_bytes,
        "deleted_entries": prune.deleted_entries,
        "deleted_size_bytes": prune.deleted_size_bytes,
        "errors": errors_json,
        "status": if error_count == 0 { "success" } else { "partial" },
    });

    if error_count == 0 {
        Ok(ExecutionOutcome::success(
            format!(
                "removed {} files ({} bytes)",
                prune.deleted_entries, prune.deleted_size_bytes
            ),
            details,
        ))
    } else {
        Ok(ExecutionOutcome::failure(
            format!(
                "removed {} files but {} errors occurred",
                prune.deleted_entries, error_count
            ),
            details,
        ))
    }
}

pub(crate) struct InstallOutcome {
    state: InstallState,
    lockfile: String,
    drift: Vec<String>,
    verified: bool,
}

pub(crate) enum InstallState {
    Installed,
    UpToDate,
    Drift,
    MissingLock,
}

struct ProjectInitHandler;

impl CommandHandler<ProjectInitRequest> for ProjectInitHandler {
    fn handle(
        &self,
        ctx: &CommandContext,
        request: ProjectInitRequest,
    ) -> Result<ExecutionOutcome> {
        let root = match discover_project_root()? {
            Some(path) => path,
            None => env::current_dir().context("unable to determine current directory")?,
        };
        let pyproject_path = root.join("pyproject.toml");

        if pyproject_path.exists() {
            return existing_pyproject_response(&pyproject_path);
        }

        if !request.force {
            if let Some(changes) = ctx.git().worktree_changes(&root)? {
                if !changes.is_empty() {
                    return Ok(dirty_worktree_response(changes));
                }
            }
        }

        let package_arg = request
            .package
            .as_deref()
            .map(str::trim)
            .filter(|s| !s.is_empty());
        let (package, inferred) = px_project::infer_package_name(package_arg, &root)?;
        let package_name = package.clone();
        let python_req = resolve_python_requirement_arg(request.python.as_deref());

        let files = ProjectInitializer::scaffold(&root, &package, &python_req)?;
        let mut details = json!({
            "package": package,
            "python": python_req,
            "files_created": files,
            "project_root": root.display().to_string(),
        });
        if inferred {
            details["inferred_package"] = Value::Bool(true);
            details["hint"] = Value::String(
                "Pass --package <name> to override the inferred module name.".to_string(),
            );
        }

        Ok(ExecutionOutcome::success(
            format!("initialized project {package_name}"),
            details,
        ))
    }
}

fn resolve_python_requirement_arg(raw: Option<&str>) -> String {
    raw.map(str::trim)
        .filter(|s| !s.is_empty())
        .map(|s| {
            if s.starts_with('>') {
                s.to_string()
            } else {
                format!(">={s}")
            }
        })
        .unwrap_or_else(|| ">=3.12".to_string())
}

fn existing_pyproject_response(pyproject_path: &Path) -> Result<ExecutionOutcome> {
    let mut details = json!({
        "pyproject": pyproject_path.display().to_string(),
    });
    if let Some(name) = project_name_from_pyproject(pyproject_path)? {
        details["package"] = Value::String(name);
    }
    details["hint"] = Value::String(
        "pyproject.toml already exists; run `px add` or start in an empty directory.".to_string(),
    );
    Ok(ExecutionOutcome::user_error(
        "project already initialized (pyproject.toml present)",
        details,
    ))
}

fn project_name_from_pyproject(pyproject_path: &Path) -> Result<Option<String>> {
    px_project::project_name_from_pyproject(pyproject_path)
}

fn dirty_worktree_response(changes: Vec<String>) -> ExecutionOutcome {
    ExecutionOutcome::user_error(
        "worktree dirty; stash, commit, or rerun with --force",
        json!({
            "changes": changes,
            "hint": "Stash or commit changes, or add --force to bypass this guard.",
        }),
    )
}

pub fn project_add(ctx: &CommandContext, request: ProjectAddRequest) -> Result<ExecutionOutcome> {
    if request.specs.is_empty() {
        return Ok(ExecutionOutcome::user_error(
            "provide at least one dependency",
            json!({ "hint": "run `px add name==version`" }),
        ));
    }

    let root = ctx.project_root()?;
    let pyproject_path = root.join("pyproject.toml");
    let cleaned_specs: Vec<String> = request
        .specs
        .iter()
        .map(|s| s.trim().to_string())
        .filter(|s| !s.is_empty())
        .collect();
    if cleaned_specs.is_empty() {
        return Ok(ExecutionOutcome::user_error(
            "provide at least one dependency",
            json!({ "hint": "run `px add name==version`" }),
        ));
    }

    let mut editor = ManifestEditor::open(&pyproject_path)?;
    let report = editor.add_specs(&cleaned_specs)?;

    if report.added.is_empty() && report.updated.is_empty() {
        return Ok(ExecutionOutcome::success(
            "dependencies already satisfied",
            json!({ "pyproject": pyproject_path.display().to_string() }),
        ));
    }

    let message = format!(
        "updated dependencies (added {}, updated {})",
        report.added.len(),
        report.updated.len()
    );
    Ok(ExecutionOutcome::success(
        message,
        json!({
            "pyproject": pyproject_path.display().to_string(),
            "added": report.added,
            "updated": report.updated,
        }),
    ))
}

pub fn project_remove(
    ctx: &CommandContext,
    request: ProjectRemoveRequest,
) -> Result<ExecutionOutcome> {
    if request.specs.is_empty() {
        return Ok(ExecutionOutcome::user_error(
            "provide at least one dependency to remove",
            json!({ "hint": "run `px remove name`" }),
        ));
    }

    let root = ctx.project_root()?;
    let pyproject_path = root.join("pyproject.toml");
    let cleaned_specs: Vec<String> = request
        .specs
        .iter()
        .map(|s| s.trim().to_string())
        .filter(|s| !s.is_empty())
        .collect();
    if cleaned_specs.is_empty() {
        return Ok(ExecutionOutcome::user_error(
            "dependencies must contain at least one name",
            json!({ "hint": "use bare names like requests==2.32.3" }),
        ));
    }

    let mut editor = ManifestEditor::open(&pyproject_path)?;
    let report = editor.remove_specs(&cleaned_specs)?;
    if report.removed.is_empty() {
        return Ok(ExecutionOutcome::success(
            "no matching dependencies found",
            json!({ "removed": [] }),
        ));
    }

    Ok(ExecutionOutcome::success(
        "removed dependencies",
        json!({
            "pyproject": pyproject_path.display().to_string(),
            "removed": report.removed,
        }),
    ))
}

pub fn project_update(
    _ctx: &CommandContext,
    request: ProjectUpdateRequest,
) -> Result<ExecutionOutcome> {
    Ok(ExecutionOutcome::success(
        "stubbed project update",
        json!({ "specs": request.specs }),
    ))
}

fn project_install_outcome(ctx: &CommandContext, frozen: bool) -> Result<ExecutionOutcome> {
    let snapshot = manifest_snapshot()?;
    let outcome = match install_snapshot(ctx, &snapshot, frozen, None) {
        Ok(ok) => ok,
        Err(err) => match err.downcast::<InstallUserError>() {
            Ok(user) => return Ok(ExecutionOutcome::user_error(user.message, user.details)),
            Err(err) => return Err(err),
        },
    };
    let mut details = json!({
        "lockfile": outcome.lockfile,
        "project": snapshot.name,
        "python": snapshot.python_requirement,
    });

    match outcome.state {
        InstallState::Installed => {
            refresh_project_site(&snapshot, ctx.fs())?;
            Ok(ExecutionOutcome::success(
                format!("wrote {}", outcome.lockfile),
                details,
            ))
        }
        InstallState::UpToDate => {
            refresh_project_site(&snapshot, ctx.fs())?;
            let message = if frozen && outcome.verified {
                "lockfile verified".to_string()
            } else {
                "px.lock already up to date".to_string()
            };
            Ok(ExecutionOutcome::success(message, details))
        }
        InstallState::Drift => {
            details["drift"] = Value::Array(outcome.drift.iter().map(|d| json!(d)).collect());
            details["hint"] = Value::String("rerun `px install` to refresh px.lock".to_string());
            Ok(ExecutionOutcome::user_error(
                "px.lock is out of date",
                details,
            ))
        }
        InstallState::MissingLock => Ok(ExecutionOutcome::user_error(
            "px.lock not found (run `px install`)",
            json!({
                "lockfile": outcome.lockfile,
                "project": snapshot.name,
                "python": snapshot.python_requirement,
                "hint": "run `px install` to generate a lockfile",
            }),
        )),
    }
}

fn quality_tidy_outcome() -> Result<ExecutionOutcome> {
    let snapshot = manifest_snapshot()?;

    let lock = match load_lockfile_optional(&snapshot.lock_path)? {
        Some(lock) => lock,
        None => {
            return Ok(ExecutionOutcome::user_error(
                "px tidy: px.lock not found (run `px install`)",
                json!({
                    "lockfile": snapshot.lock_path.display().to_string(),
                    "hint": "run `px install` to generate px.lock before running tidy",
                }),
            ))
        }
    };

    let drift = detect_lock_drift(&snapshot, &lock, None);
    if drift.is_empty() {
        Ok(ExecutionOutcome::success(
            "px.lock matches pyproject",
            json!({
                "status": "clean",
                "lockfile": snapshot.lock_path.display().to_string(),
            }),
        ))
    } else {
        Ok(ExecutionOutcome::user_error(
            "px.lock is out of date",
            json!({
                "status": "drift",
                "lockfile": snapshot.lock_path.display().to_string(),
                "drift": drift,
                "hint": "rerun `px install` to refresh the lockfile",
            }),
        ))
    }
}

fn lock_diff_outcome() -> Result<ExecutionOutcome> {
    let snapshot = manifest_snapshot()?;
    match load_lockfile_optional(&snapshot.lock_path)? {
        Some(lock) => {
            let report = analyze_lock_diff(&snapshot, &lock, None);
            let mut details = report.to_json(&snapshot);
            if report.is_clean() {
                Ok(ExecutionOutcome::success(report.summary(), details))
            } else {
                details["hint"] = Value::String(
                    "run `px install` (or `px lock upgrade`) to regenerate the lock".to_string(),
                );
                Ok(ExecutionOutcome::user_error(report.summary(), details))
            }
        }
        None => {
            let details = json!({
                "status": "missing_lock",
                "pyproject": snapshot.manifest_path.display().to_string(),
                "lockfile": snapshot.lock_path.display().to_string(),
                "added": [],
                "removed": [],
                "changed": [],
                "version_mismatch": Value::Null,
                "python_mismatch": Value::Null,
                "mode_mismatch": Value::Null,
                "hint": "run `px install` to generate px.lock before diffing",
            });
            Ok(ExecutionOutcome::user_error(
                format!(
                    "missing px.lock at {} (run `px install` first)",
                    snapshot.lock_path.display()
                ),
                details,
            ))
        }
    }
}

pub fn lock_upgrade(
    _ctx: &CommandContext,
    _request: LockUpgradeRequest,
) -> Result<ExecutionOutcome> {
    let snapshot = manifest_snapshot()?;
    let lock_path = snapshot.lock_path.clone();
    let lock = match load_lockfile_optional(&lock_path)? {
        Some(lock) => lock,
        None => {
            return Ok(ExecutionOutcome::user_error(
                "missing px.lock (run `px install` first)",
                json!({
                    "status": "missing_lock",
                    "lockfile": lock_path.display().to_string(),
                    "hint": "run `px install` to create a lock before upgrading",
                }),
            ))
        }
    };

    if lock.version >= 2 {
        return Ok(ExecutionOutcome::success(
            "lock already at version 2",
            json!({
                "lockfile": lock_path.display().to_string(),
                "version": lock.version,
                "status": "unchanged",
            }),
        ));
    }

    let upgraded = render_lockfile_v2(&snapshot, &lock, PX_VERSION)?;
    fs::write(&lock_path, upgraded)?;

    Ok(ExecutionOutcome::success(
        "upgraded lock to version 2",
        json!({
            "lockfile": lock_path.display().to_string(),
            "version": 2,
            "status": "upgraded",
        }),
    ))
}

pub fn workspace_tidy(
    ctx: &CommandContext,
    _request: WorkspaceTidyRequest,
) -> Result<ExecutionOutcome> {
    workspace::tidy(ctx)
}

fn lock_is_fresh(snapshot: &ManifestSnapshot) -> Result<bool> {
    match load_lockfile_optional(&snapshot.lock_path)? {
        Some(lock) => Ok(detect_lock_drift(snapshot, &lock, None).is_empty()),
        None => Ok(false),
    }
}

pub(crate) fn manifest_snapshot() -> Result<ManifestSnapshot> {
    Ok(px_project::ProjectSnapshot::read_current()?)
}

pub(crate) fn manifest_snapshot_at(root: &Path) -> Result<ManifestSnapshot> {
    Ok(px_project::ProjectSnapshot::read_from(root)?)
}

pub(crate) fn install_snapshot(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
    frozen: bool,
    override_pins: Option<&InstallOverride>,
) -> Result<InstallOutcome> {
    let lockfile = snapshot.lock_path.display().to_string();

    if frozen {
        return verify_lock(snapshot);
    }

    if lock_is_fresh(snapshot)? {
        Ok(InstallOutcome {
            state: InstallState::UpToDate,
            lockfile,
            drift: Vec::new(),
            verified: false,
        })
    } else {
        if let Some(parent) = snapshot.lock_path.parent() {
            fs::create_dir_all(parent)?;
        }
        let mut dependencies = if let Some(override_data) = override_pins {
            override_data.dependencies.clone()
        } else {
            snapshot.dependencies.clone()
        };
        let marker_env = ctx.marker_environment()?;
        let mut resolved_override = None;
        if override_pins.is_none()
            && dependencies_require_resolution(&dependencies)
            && ctx.config().resolver.enabled
        {
            let resolved = resolve_dependencies(ctx, snapshot)?;
            dependencies = merge_resolved_dependencies(&dependencies, &resolved.specs, &marker_env);
            resolved_override = Some(resolved.pins);
            persist_resolved_dependencies(snapshot, &dependencies)?;
        }
        let pins = if let Some(override_data) = override_pins {
            pins_with_override(&marker_env, &dependencies, override_data)?
        } else {
            match resolved_override {
                Some(pins) => pins,
                None => ensure_exact_pins(&marker_env, &dependencies)?,
            }
        };
        let resolved = resolve_pins(ctx, &pins, ctx.config().resolver.force_sdist)?;
        let contents = render_lockfile(snapshot, &resolved, PX_VERSION)?;
        fs::write(&snapshot.lock_path, contents)?;
        Ok(InstallOutcome {
            state: InstallState::Installed,
            lockfile,
            drift: Vec::new(),
            verified: false,
        })
    }
}

fn refresh_project_site(snapshot: &ManifestSnapshot, fs: &dyn effects::FileSystem) -> Result<()> {
    let lock = load_lockfile_optional(&snapshot.lock_path)?.ok_or_else(|| {
        anyhow!(
            "px install: lockfile missing at {}",
            snapshot.lock_path.display()
        )
    })?;
    materialize_project_site(snapshot, &lock, fs)
}

fn materialize_project_site(
    snapshot: &ManifestSnapshot,
    lock: &LockSnapshot,
    fs: &dyn effects::FileSystem,
) -> Result<()> {
    let site_dir = snapshot.root.join(".px").join("site");
    fs.create_dir_all(&site_dir)?;
    let pth_path = site_dir.join("px.pth");

    let mut entries = Vec::new();
    for dep in &lock.resolved {
        let Some(artifact) = &dep.artifact else {
            continue;
        };
        if artifact.cached_path.is_empty() {
            continue;
        }
        let wheel_path = PathBuf::from(&artifact.cached_path);
        if !wheel_path.exists() {
            continue;
        }
        let dist_path = wheel_path.with_extension("dist");
        let entry_path = if dist_path.exists() {
            dist_path
        } else {
            wheel_path
        };
        let canonical = entry_path.canonicalize().unwrap_or(entry_path);
        entries.push(canonical);
    }

    entries.sort();
    entries.dedup();

    let mut contents = entries
        .iter()
        .map(|path| path.display().to_string())
        .collect::<Vec<_>>()
        .join("\n");
    if !contents.is_empty() {
        contents.push('\n');
    }
    fs.write(&pth_path, contents.as_bytes())?;
    write_sitecustomize(&site_dir, fs)?;
    Ok(())
}

fn write_sitecustomize(site_dir: &Path, fs: &dyn effects::FileSystem) -> Result<()> {
    let path = site_dir.join("sitecustomize.py");
    fs.write(&path, SITE_CUSTOMIZE.as_bytes())
}

fn ensure_project_site_bootstrap(project_root: &Path, fs: &dyn effects::FileSystem) {
    let pth_path = project_root.join(".px").join("site").join("px.pth");
    if pth_path.exists() {
        return;
    }
    let lock_path = project_root.join("px.lock");
    if !lock_path.exists() {
        return;
    }
    let snapshot = ManifestSnapshot {
        root: project_root.to_path_buf(),
        manifest_path: project_root.join("pyproject.toml"),
        lock_path,
        name: String::new(),
        python_requirement: String::new(),
        dependencies: Vec::new(),
    };
    match load_lockfile_optional(&snapshot.lock_path) {
        Ok(Some(lock)) => {
            if let Err(err) = materialize_project_site(&snapshot, &lock, fs) {
                warn!("failed to refresh .px/site from px.lock: {err:?}");
            }
        }
        Ok(None) => {}
        Err(err) => {
            warn!(
                "failed to load px.lock at {}: {err:?}",
                snapshot.lock_path.display()
            );
        }
    }
}

fn verify_lock(snapshot: &ManifestSnapshot) -> Result<InstallOutcome> {
    let lockfile = snapshot.lock_path.display().to_string();
    match load_lockfile_optional(&snapshot.lock_path)? {
        Some(lock) => {
            let report = analyze_lock_diff(snapshot, &lock, None);
            let mut drift = report.to_messages();
            if drift.is_empty() {
                drift = verify_locked_artifacts(&lock);
            }
            if drift.is_empty() {
                Ok(InstallOutcome {
                    state: InstallState::UpToDate,
                    lockfile,
                    drift,
                    verified: true,
                })
            } else {
                Ok(InstallOutcome {
                    state: InstallState::Drift,
                    lockfile,
                    drift,
                    verified: true,
                })
            }
        }
        None => Ok(InstallOutcome {
            state: InstallState::MissingLock,
            lockfile,
            drift: Vec::new(),
            verified: true,
        }),
    }
}

fn compute_file_sha256(path: &Path) -> Result<String> {
    let mut file = File::open(path)?;
    let mut hasher = Sha256::new();
    let mut buf = [0u8; 64 * 1024];
    loop {
        let read = file.read(&mut buf)?;
        if read == 0 {
            break;
        }
        hasher.update(&buf[..read]);
    }
    Ok(format!("{:x}", hasher.finalize()))
}

fn dependencies_require_resolution(specs: &[String]) -> bool {
    specs.iter().any(|spec| !spec.trim().contains("=="))
}

struct ResolvedSpecOutput {
    specs: Vec<String>,
    pins: Vec<PinSpec>,
}

fn resolve_dependencies(
    ctx: &CommandContext,
    snapshot: &ManifestSnapshot,
) -> Result<ResolvedSpecOutput> {
    resolve_dependencies_with_effects(ctx.effects(), snapshot)
}

fn resolve_dependencies_with_effects(
    effects: &dyn Effects,
    snapshot: &ManifestSnapshot,
) -> Result<ResolvedSpecOutput> {
    let python = effects.python().detect_interpreter()?;
    let tags = detect_interpreter_tags_with(&python)?;
    let marker_env = detect_marker_environment_with(&python)?;
    let request = ResolverRequest {
        project: snapshot.name.clone(),
        requirements: snapshot.dependencies.clone(),
        tags: ResolverTags {
            python: tags.python.clone(),
            abi: tags.abi.clone(),
            platform: tags.platform.clone(),
        },
        env: marker_env,
    };
    let resolved = px_resolver::resolve(request).map_err(|err| {
        InstallUserError::new(
            format!("resolver failed: {err}"),
            json!({ "error": err.to_string() }),
        )
    })?;
    let mut specs = Vec::new();
    let mut pins = Vec::new();
    for spec in resolved {
        let formatted = format_specifier(
            &spec.normalized,
            &spec.extras,
            &spec.selected_version,
            spec.marker.as_deref(),
        );
        specs.push(formatted.clone());
        pins.push(PinSpec {
            name: spec.name,
            specifier: formatted,
            version: spec.selected_version,
            normalized: spec.normalized,
            extras: spec.extras,
            marker: spec.marker,
        });
    }
    Ok(ResolvedSpecOutput { specs, pins })
}

fn persist_resolved_dependencies(snapshot: &ManifestSnapshot, specs: &[String]) -> Result<()> {
    let contents = fs::read_to_string(&snapshot.manifest_path)?;
    let mut doc: DocumentMut = contents.parse()?;
    write_dependencies(&mut doc, specs)?;
    fs::write(&snapshot.manifest_path, doc.to_string())?;
    Ok(())
}

pub(crate) fn store_prefetch_specs<'a>(
    entries: &'a [LockPrefetchSpec],
) -> Vec<StorePrefetchSpec<'a>> {
    entries
        .iter()
        .map(|entry| StorePrefetchSpec {
            name: entry.name.as_str(),
            version: entry.version.as_str(),
            filename: entry.filename.as_str(),
            url: entry.url.as_str(),
            sha256: entry.sha256.as_str(),
        })
        .collect()
}

fn ensure_exact_pins(marker_env: &MarkerEnvironment, specs: &[String]) -> Result<Vec<PinSpec>> {
    let mut pins = Vec::new();
    for spec in specs {
        if !marker_applies(spec, &marker_env) {
            continue;
        }
        pins.push(parse_exact_pin(spec)?);
    }
    Ok(pins)
}

fn parse_exact_pin(spec: &str) -> Result<PinSpec> {
    let trimmed_raw = spec.trim();
    let trimmed = strip_wrapping_quotes(trimmed_raw);
    if trimmed.is_empty() {
        return Err(InstallUserError::new(
            "dependency specifier cannot be empty",
            json!({ "specifier": spec }),
        )
        .into());
    }

    let requirement = PepRequirement::from_str(trimmed).map_err(|err| {
        InstallUserError::new(
            format!("invalid requirement `{trimmed}`: {err}"),
            json!({ "specifier": trimmed }),
        )
    })?;

    let name = dependency_name(trimmed);
    if name.is_empty() {
        return Err(InstallUserError::new(
            "dependency name missing before `==`",
            json!({ "specifier": trimmed }),
        )
        .into());
    }

    let version_spec = match requirement.version_or_url.as_ref() {
        Some(VersionOrUrl::VersionSpecifier(specifiers)) => specifiers.to_string(),
        Some(VersionOrUrl::Url(_)) => {
            return Err(InstallUserError::new(
                "URL requirements are not supported in pinned installs",
                json!({ "specifier": trimmed }),
            )
            .into())
        }
        None => {
            return Err(InstallUserError::new(
                format!("px install requires `name==version`; `{trimmed}` is not pinned"),
                json!({ "specifier": trimmed }),
            )
            .into())
        }
    };
    let parsed = VersionSpecifiers::from_str(&version_spec).map_err(|_| {
        InstallUserError::new(
            format!("px install requires `name==version`; `{trimmed}` is not pinned"),
            json!({ "specifier": trimmed }),
        )
    })?;
    let mut iter = parsed.iter();
    let Some(first) = iter.next() else {
        return Err(InstallUserError::new(
            format!("px install requires `name==version`; `{trimmed}` is not pinned"),
            json!({ "specifier": trimmed }),
        )
        .into());
    };
    if iter.next().is_some() || !matches!(first.operator(), Operator::Equal | Operator::ExactEqual)
    {
        return Err(InstallUserError::new(
            format!("px install requires `name==version`; `{trimmed}` is not pinned"),
            json!({ "specifier": trimmed }),
        )
        .into());
    }
    let version_str = first.version().to_string();

    let extras = canonical_extras(
        &requirement
            .extras
            .iter()
            .map(|extra| extra.to_string())
            .collect::<Vec<_>>(),
    );
    let marker = requirement.marker.as_ref().map(|m| m.to_string());
    let normalized = normalize_dist_name(&name);
    Ok(PinSpec {
        name,
        specifier: format_specifier(&normalized, &extras, &version_str, marker.as_deref()),
        version: version_str,
        normalized,
        extras,
        marker,
    })
}

fn resolve_pins(
    ctx: &CommandContext,
    pins: &[PinSpec],
    force_sdist: bool,
) -> Result<Vec<ResolvedDependency>> {
    if pins.is_empty() {
        return Ok(Vec::new());
    }

    let python = px_python::detect_interpreter()?;
    let tags = detect_interpreter_tags_with(&python)?;
    let mut resolved = Vec::new();
    for pin in pins {
        let release = ctx
            .pypi()
            .fetch_release(&pin.normalized, &pin.version, &pin.specifier)?;
        let artifact = if force_sdist {
            build_wheel_via_sdist(ctx, &release, pin, &python)?
        } else {
            match select_wheel(&release.urls, &tags, &pin.specifier) {
                Ok(wheel) => {
                    let request = ArtifactRequest {
                        name: &pin.normalized,
                        version: &pin.version,
                        filename: &wheel.filename,
                        url: &wheel.url,
                        sha256: &wheel.sha256,
                    };
                    let cached = ctx.cache_store().cache_wheel(&ctx.cache().path, &request)?;
                    LockedArtifact {
                        filename: wheel.filename.clone(),
                        url: wheel.url.clone(),
                        sha256: wheel.sha256.clone(),
                        size: cached.size,
                        cached_path: cached.wheel_path.display().to_string(),
                        python_tag: wheel.python_tag.clone(),
                        abi_tag: wheel.abi_tag.clone(),
                        platform_tag: wheel.platform_tag.clone(),
                    }
                }
                Err(err) => match build_wheel_via_sdist(ctx, &release, pin, &python) {
                    Ok(artifact) => artifact,
                    Err(build_err) => {
                        return Err(err.context(format!("sdist fallback failed: {build_err}")))
                    }
                },
            }
        };
        resolved.push(ResolvedDependency {
            name: pin.name.clone(),
            specifier: pin.specifier.clone(),
            extras: pin.extras.clone(),
            marker: pin.marker.clone(),
            artifact,
        });
    }

    Ok(resolved)
}

fn build_wheel_via_sdist(
    ctx: &CommandContext,
    release: &PypiReleaseResponse,
    pin: &PinSpec,
    python: &str,
) -> Result<LockedArtifact> {
    let sdist = select_sdist(&release.urls, &pin.specifier)?;
    let built = ctx.cache_store().ensure_sdist_build(
        &ctx.cache().path,
        &SdistRequest {
            normalized_name: &pin.normalized,
            version: &pin.version,
            filename: &sdist.filename,
            url: &sdist.url,
            sha256: Some(&sdist.digests.sha256),
            python_path: python,
        },
    )?;
    Ok(LockedArtifact {
        filename: built.filename,
        url: built.url,
        sha256: built.sha256,
        size: built.size,
        cached_path: built.cached_path.display().to_string(),
        python_tag: built.python_tag,
        abi_tag: built.abi_tag,
        platform_tag: built.platform_tag,
    })
}

fn select_sdist<'a>(files: &'a [PypiFile], specifier: &str) -> Result<&'a PypiFile> {
    files
        .iter()
        .find(|file| file.packagetype == "sdist" && !file.yanked.unwrap_or(false))
        .ok_or_else(|| {
            InstallUserError::new(
                format!("PyPI does not provide an sdist for {specifier}"),
                json!({ "specifier": specifier }),
            )
            .into()
        })
}

pub(crate) fn build_http_client() -> Result<Client> {
    Client::builder()
        .user_agent(format!("px/{PX_VERSION}"))
        .timeout(Duration::from_secs(60))
        .no_proxy()
        .build()
        .context("failed to build HTTP client")
}

pub(crate) fn fetch_release(
    client: &Client,
    normalized: &str,
    version: &str,
    specifier: &str,
) -> Result<PypiReleaseResponse> {
    let url = format!("{PYPI_BASE_URL}/{normalized}/{version}/json");
    let response = client
        .get(&url)
        .send()
        .map_err(|err| anyhow!("failed to query PyPI for {specifier}: {err}"))?;
    if response.status() == StatusCode::NOT_FOUND {
        return Err(InstallUserError::new(
            format!("PyPI does not provide {specifier}"),
            json!({ "specifier": specifier }),
        )
        .into());
    }
    let response = response
        .error_for_status()
        .map_err(|err| anyhow!("PyPI returned an error for {specifier}: {err}"))?;
    response
        .json::<PypiReleaseResponse>()
        .map_err(|err| anyhow!("invalid JSON for {specifier}: {err}"))
}

fn select_wheel(
    files: &[PypiFile],
    tags: &InterpreterTags,
    specifier: &str,
) -> Result<WheelCandidate> {
    let mut candidates = Vec::new();
    for file in files {
        if file.packagetype != "bdist_wheel" || file.yanked.unwrap_or(false) {
            continue;
        }
        let Some((python_tag, abi_tag, platform_tag)) = parse_wheel_tags(&file.filename) else {
            continue;
        };
        let candidate = WheelCandidate {
            filename: file.filename.clone(),
            url: file.url.clone(),
            sha256: file.digests.sha256.clone(),
            python_tag,
            abi_tag,
            platform_tag,
        };
        if wheel_supported(&candidate, tags) {
            candidates.push(candidate);
        }
    }

    if let Some(universal) = candidates
        .iter()
        .find(|c| c.python_tag == "py3" && c.abi_tag == "none" && c.platform_tag == "any")
    {
        return Ok(universal.clone());
    }

    let mut best: Option<(i32, WheelCandidate)> = None;
    for candidate in candidates {
        let score = score_candidate(&candidate, tags);
        match &mut best {
            Some((best_score, best_candidate)) => match score.cmp(best_score) {
                Ordering::Greater => {
                    *best_score = score;
                    *best_candidate = candidate;
                }
                Ordering::Equal => {
                    if candidate.filename < best_candidate.filename {
                        *best_candidate = candidate;
                    }
                }
                Ordering::Less => {}
            },
            None => best = Some((score, candidate)),
        }
    }

    best.map(|(_, candidate)| candidate).ok_or_else(|| {
        InstallUserError::new(
            format!("PyPI did not provide any wheels for {specifier}"),
            json!({ "specifier": specifier }),
        )
        .into()
    })
}

fn score_candidate(candidate: &WheelCandidate, tags: &InterpreterTags) -> i32 {
    let mut score = 0;
    if matches_any(&tags.python, &candidate.python_tag) {
        score += 100;
    } else if candidate.python_tag.starts_with("py3") {
        score += 50;
    }

    if matches_any(&tags.abi, &candidate.abi_tag) {
        score += 40;
    } else if candidate.abi_tag == "none" {
        score += 20;
    }

    if candidate.platform_tag == "any" {
        score += 30;
    } else if matches_any(&tags.platform, &candidate.platform_tag) {
        score += 25;
    }

    score
}

fn matches_any(values: &[String], candidate: &str) -> bool {
    candidate
        .split('.')
        .any(|part| values.iter().any(|val| part.eq_ignore_ascii_case(val)))
}

fn wheel_supported(candidate: &WheelCandidate, tags: &InterpreterTags) -> bool {
    let combos = candidate_tag_combos(candidate);
    if !tags.supported.is_empty()
        && combos
            .iter()
            .any(|(py, abi, platform)| tags.supports_triple(py, abi, platform))
    {
        return true;
    }
    fallback_python(&candidate.python_tag, &tags.python)
        && fallback_abi(&candidate.abi_tag, &tags.abi)
        && fallback_platform(&candidate.platform_tag, &tags.platform)
}

fn candidate_tag_combos(candidate: &WheelCandidate) -> Vec<(String, String, String)> {
    let python = split_tag_values(&candidate.python_tag);
    let abi = split_tag_values(&candidate.abi_tag);
    let platform = split_tag_values(&candidate.platform_tag);
    let mut combos = Vec::new();
    for py in &python {
        for abi_tag in &abi {
            for plat in &platform {
                combos.push((py.clone(), abi_tag.clone(), plat.clone()));
            }
        }
    }
    combos
}

fn split_tag_values(value: &str) -> Vec<String> {
    let mut values = value
        .split('.')
        .map(|part| part.trim().to_ascii_lowercase())
        .filter(|part| !part.is_empty())
        .collect::<Vec<_>>();
    if values.is_empty() {
        values.push(value.to_ascii_lowercase());
    }
    values
}

fn fallback_python(tag: &str, supported: &[String]) -> bool {
    split_tag_values(tag)
        .iter()
        .any(|token| token == "py3" || supported.iter().any(|val| val == token))
}

fn fallback_abi(tag: &str, supported: &[String]) -> bool {
    split_tag_values(tag)
        .iter()
        .any(|token| token == "none" || supported.iter().any(|val| val == token))
}

fn fallback_platform(tag: &str, supported: &[String]) -> bool {
    split_tag_values(tag)
        .iter()
        .any(|token| platform_token_supported(supported, token))
}

fn platform_token_supported(supported: &[String], token: &str) -> bool {
    if token == "any" {
        return true;
    }
    let normalized = normalize_platform_value(token);
    for platform in supported {
        let normalized_platform = normalize_platform_value(platform);
        if normalized_platform == "any" {
            continue;
        }
        if normalized_platform == normalized
            || same_platform_family(&normalized_platform, &normalized)
        {
            return true;
        }
    }
    false
}

fn normalize_platform_value(value: &str) -> String {
    value.replace('-', "_").to_ascii_lowercase()
}

fn same_platform_family(interpreter: &str, candidate: &str) -> bool {
    if interpreter.starts_with("linux") {
        if candidate.contains("linux") {
            return arch_overlap(interpreter, candidate);
        }
    }
    if interpreter.starts_with("macosx") && candidate.starts_with("macosx") {
        return arch_overlap(interpreter, candidate);
    }
    if interpreter.starts_with("win") && candidate.starts_with("win") {
        return arch_overlap(interpreter, candidate);
    }
    false
}

const ARCH_ALIASES: &[(&str, &str)] = &[
    ("x86_64", "x86_64"),
    ("amd64", "x86_64"),
    ("aarch64", "aarch64"),
    ("arm64", "arm64"),
    ("armv7l", "armv7l"),
    ("armv6l", "armv6l"),
    ("i686", "i686"),
    ("i386", "i386"),
    ("ppc64le", "ppc64le"),
    ("s390x", "s390x"),
];

fn arch_overlap(a: &str, b: &str) -> bool {
    match (arch_hint(a), arch_hint(b)) {
        (Some(left), Some(right)) => left == right,
        (None, None) => true,
        _ => false,
    }
}

fn arch_hint(value: &str) -> Option<&'static str> {
    let lower = value.to_ascii_lowercase();
    for (alias, canonical) in ARCH_ALIASES {
        if lower.contains(alias) {
            return Some(*canonical);
        }
    }
    None
}

fn parse_wheel_tags(filename: &str) -> Option<(String, String, String)> {
    if !filename.ends_with(".whl") {
        return None;
    }
    let trimmed = filename.trim_end_matches(".whl");
    let parts: Vec<&str> = trimmed.split('-').collect();
    if parts.len() < 5 {
        return None;
    }
    let python_tag = parts[parts.len() - 3].to_string();
    let abi_tag = parts[parts.len() - 2].to_string();
    let platform_tag = parts[parts.len() - 1].to_string();
    Some((python_tag, abi_tag, platform_tag))
}

fn detect_interpreter_tags_with(python: &str) -> Result<InterpreterTags> {
    let script = r#"import json, sys, sysconfig
major = sys.version_info[0]
minor = sys.version_info[1]
py = [f"cp{major}{minor}", f"py{major}{minor}", f"py{major}", "py3"]
abi = [f"cp{major}{minor}", "abi3", "none"]
plat = sysconfig.get_platform().lower().replace("-", "_").replace(".", "_")
data = {"python": py, "abi": abi, "platform": [plat, "any"], "tags": []}

def collect_tags():
    try:
        from pip._internal.utils.compatibility_tags import get_supported
        return list(get_supported())
    except Exception:
        try:
            from packaging import tags as packaging_tags
        except Exception:
            return []
        else:
            return list(packaging_tags.sys_tags())

tags = collect_tags()
if tags:
    data["tags"] = [
        {
            "python": str(tag.interpreter).lower(),
            "abi": str(tag.abi).lower(),
            "platform": str(tag.platform).lower(),
        }
        for tag in tags
    ]

print(json.dumps(data))
"#;
    let cmd = Command::new(python)
        .arg("-c")
        .arg(script)
        .output()
        .with_context(|| format!("failed to interrogate interpreter tags via {python}"))?;
    if !cmd.status.success() {
        let stderr = String::from_utf8_lossy(&cmd.stderr);
        bail!("python tag probe failed: {stderr}");
    }
    let payload: InterpreterTagsPayload =
        serde_json::from_slice(&cmd.stdout).context("invalid interpreter tag payload")?;
    Ok(InterpreterTags {
        python: payload
            .python
            .into_iter()
            .map(|value| value.to_ascii_lowercase())
            .collect(),
        abi: payload
            .abi
            .into_iter()
            .map(|value| value.to_ascii_lowercase())
            .collect(),
        platform: payload
            .platform
            .into_iter()
            .map(|value| value.to_ascii_lowercase())
            .collect(),
        supported: payload
            .tags
            .into_iter()
            .map(|tag| InterpreterSupportedTag {
                python: tag.python.to_ascii_lowercase(),
                abi: tag.abi.to_ascii_lowercase(),
                platform: tag.platform.to_ascii_lowercase(),
            })
            .collect(),
    })
}

fn detect_marker_environment_with(python: &str) -> Result<ResolverEnv> {
    let script = r#"import json, os, platform, sys
impl_name = getattr(sys.implementation, "name", "cpython")
impl_version = platform.python_version()
python_full = platform.python_version()
python_short = f"{sys.version_info[0]}.{sys.version_info[1]}"
data = {
    "implementation_name": impl_name,
    "implementation_version": impl_version,
    "os_name": os.name,
    "platform_machine": platform.machine(),
    "platform_python_implementation": platform.python_implementation(),
    "platform_release": platform.release(),
    "platform_system": platform.system(),
    "platform_version": platform.version(),
    "python_full_version": python_full,
    "python_version": python_short,
    "sys_platform": sys.platform,
}
print(json.dumps(data))
"#;
    let cmd = Command::new(python)
        .arg("-c")
        .arg(script)
        .output()
        .with_context(|| format!("failed to probe marker environment via {python}"))?;
    if !cmd.status.success() {
        let stderr = String::from_utf8_lossy(&cmd.stderr);
        bail!("python marker probe failed: {stderr}");
    }
    let payload: MarkerEnvPayload =
        serde_json::from_slice(&cmd.stdout).context("invalid marker env payload")?;
    Ok(ResolverEnv {
        implementation_name: payload.implementation_name,
        implementation_version: payload.implementation_version,
        os_name: payload.os_name,
        platform_machine: payload.platform_machine,
        platform_python_implementation: payload.platform_python_implementation,
        platform_release: payload.platform_release,
        platform_system: payload.platform_system,
        platform_version: payload.platform_version,
        python_full_version: payload.python_full_version,
        python_version: payload.python_version,
        sys_platform: payload.sys_platform,
    })
}

#[derive(Deserialize)]
struct MarkerEnvPayload {
    implementation_name: String,
    implementation_version: String,
    os_name: String,
    platform_machine: String,
    platform_python_implementation: String,
    platform_release: String,
    platform_system: String,
    platform_version: String,
    python_full_version: String,
    python_version: String,
    sys_platform: String,
}

fn normalize_dist_name(name: &str) -> String {
    name.to_ascii_lowercase().replace(['_', '.'], "-")
}

fn format_specifier(
    normalized: &str,
    extras: &[String],
    version: &str,
    marker: Option<&str>,
) -> String {
    let mut spec = normalized.to_string();
    let extras = canonical_extras(extras);
    if !extras.is_empty() {
        spec.push('[');
        spec.push_str(&extras.join(","));
        spec.push(']');
    }
    spec.push_str("==");
    spec.push_str(version);
    if let Some(marker) = marker.and_then(|m| {
        let trimmed = m.trim();
        if trimmed.is_empty() {
            None
        } else {
            Some(trimmed)
        }
    }) {
        spec.push_str(" ; ");
        spec.push_str(marker);
    }
    spec
}

fn canonical_extras(extras: &[String]) -> Vec<String> {
    let mut values = extras
        .iter()
        .map(|extra| extra.to_ascii_lowercase())
        .collect::<Vec<_>>();
    values.sort();
    values.dedup();
    values
}

#[derive(Clone, Debug)]
struct WheelCandidate {
    filename: String,
    url: String,
    sha256: String,
    python_tag: String,
    abi_tag: String,
    platform_tag: String,
}

struct InterpreterTags {
    python: Vec<String>,
    abi: Vec<String>,
    platform: Vec<String>,
    supported: Vec<InterpreterSupportedTag>,
}

impl InterpreterTags {
    fn supports_triple(&self, py: &str, abi: &str, platform: &str) -> bool {
        if self.supported.is_empty() {
            return false;
        }
        self.supported
            .iter()
            .any(|tag| tag.python == py && tag.abi == abi && tag.platform == platform)
    }
}

#[derive(Deserialize)]
struct InterpreterTagsPayload {
    python: Vec<String>,
    abi: Vec<String>,
    platform: Vec<String>,
    #[serde(default)]
    tags: Vec<InterpreterTagPayload>,
}

#[derive(Deserialize)]
struct InterpreterTagPayload {
    python: String,
    abi: String,
    platform: String,
}

#[derive(Clone)]
struct InterpreterSupportedTag {
    python: String,
    abi: String,
    platform: String,
}

fn current_project_root() -> Result<PathBuf> {
    Ok(px_project::current_project_root()?)
}

fn summarize_autopins(entries: &[AutopinEntry]) -> Option<String> {
    if entries.is_empty() {
        return None;
    }
    let mut labels = Vec::new();
    for entry in entries.iter().take(3) {
        labels.push(entry.short_label());
    }
    let mut summary = format!(
        "Pinned {} package{} automatically",
        entries.len(),
        if entries.len() == 1 { "" } else { "s" }
    );
    if !labels.is_empty() {
        summary.push_str(" (");
        summary.push_str(&labels.join(", "));
        if entries.len() > 3 {
            summary.push_str(&format!(", +{} more", entries.len() - 3));
        }
        summary.push(')');
    }
    Some(summary)
}

fn pins_with_override(
    marker_env: &MarkerEnvironment,
    dependencies: &[String],
    override_pins: &InstallOverride,
) -> Result<Vec<PinSpec>> {
    let mut lookup: HashMap<String, VecDeque<PinSpec>> = HashMap::new();
    for pin in &override_pins.pins {
        lookup
            .entry(autopin_pin_key(pin))
            .or_insert_with(VecDeque::new)
            .push_back(pin.clone());
    }
    let mut pins = Vec::new();
    for spec in dependencies {
        if !marker_applies(spec, &marker_env) {
            continue;
        }
        let key = autopin_spec_key(spec);
        if let Some(queue) = lookup.get_mut(&key) {
            if let Some(pin) = queue.pop_front() {
                pins.push(pin);
                continue;
            }
        }
        pins.push(parse_exact_pin(spec)?);
    }
    Ok(pins)
}

fn write_dependencies(doc: &mut DocumentMut, specs: &[String]) -> Result<()> {
    let table = project_table_mut(doc)?;
    let mut array = Array::new();
    for spec in specs {
        array.push_formatted(TomlValue::from(spec.clone()));
    }
    table.insert("dependencies", Item::Value(TomlValue::Array(array)));
    Ok(())
}

fn project_table(doc: &DocumentMut) -> Result<&Table> {
    doc.get("project")
        .and_then(Item::as_table)
        .ok_or_else(|| anyhow!("[project] must be a table"))
}

fn project_table_mut(doc: &mut DocumentMut) -> Result<&mut Table> {
    doc.entry("project")
        .or_insert(Item::Table(Table::new()))
        .as_table_mut()
        .ok_or_else(|| anyhow!("[project] must be a table"))
}

fn dependency_name(spec: &str) -> String {
    let trimmed = strip_wrapping_quotes(spec.trim());
    let mut end = trimmed.len();
    for (idx, ch) in trimmed.char_indices() {
        if ch.is_ascii_whitespace() || matches!(ch, '<' | '>' | '=' | '!' | '~' | ';') {
            end = idx;
            break;
        }
    }
    let head = &trimmed[..end];
    let base = head.split('[').next().unwrap_or(head);
    base.to_lowercase()
}

fn strip_wrapping_quotes(input: &str) -> &str {
    if input.len() >= 2 {
        let bytes = input.as_bytes();
        let first = bytes[0];
        let last = bytes[input.len() - 1];
        if (first == b'"' && last == b'"') || (first == b'\'' && last == b'\'') {
            return &input[1..input.len() - 1];
        }
    }
    input
}

fn outcome_from_output(
    command_name: &str,
    target: &str,
    output: RunOutput,
    prefix: &str,
    extra: Option<Value>,
) -> ExecutionOutcome {
    let mut details = json!({
        "stdout": output.stdout,
        "stderr": output.stderr,
        "code": output.code,
        "target": target,
    });

    if let Some(extra_value) = extra {
        if let Value::Object(map) = extra_value {
            if let Some(details_map) = details.as_object_mut() {
                for (key, value) in map {
                    details_map.insert(key, value);
                }
            }
        } else {
            details["extra"] = extra_value;
        }
    }

    if output.code == 0 {
        let stdout = output.stdout.trim_end();
        if !stdout.is_empty() {
            details["passthrough"] = Value::Bool(true);
            return ExecutionOutcome::success(stdout.to_string(), details);
        }
        let stderr = output.stderr.trim_end();
        if !stderr.is_empty() {
            details["passthrough"] = Value::Bool(true);
            return ExecutionOutcome::success(stderr.to_string(), details);
        }
        let message = format!("{prefix} {command_name}({target}) succeeded");
        ExecutionOutcome::success(message, details)
    } else {
        let message = if output.stderr.trim().is_empty() {
            format!(
                "{prefix} {command_name}({target}) exited with {}",
                output.code
            )
        } else {
            details["passthrough"] = Value::Bool(true);
            output.stderr.trim_end().to_string()
        };
        ExecutionOutcome::failure(message, details)
    }
}

fn missing_pytest(stderr: &str) -> bool {
    stderr.contains("No module named") && stderr.contains("pytest")
}

struct PythonContext {
    project_root: PathBuf,
    python: String,
    pythonpath: String,
    allowed_paths: Vec<PathBuf>,
}

impl PythonContext {
    fn new(ctx: &CommandContext) -> Result<Self> {
        let project_root = ctx.project_root()?;
        ensure_project_environment_synced(&project_root)?;
        ensure_project_site_bootstrap(&project_root, ctx.fs());
        let python = ctx.python_runtime().detect_interpreter()?;
        let (pythonpath, allowed_paths) = build_pythonpath(ctx.fs(), &project_root)?;
        Ok(Self {
            project_root,
            python,
            pythonpath,
            allowed_paths,
        })
    }

    fn base_env(&self, command_args: &Value) -> Result<Vec<(String, String)>> {
        let mut envs = Vec::new();
        envs.push(("PYTHONPATH".into(), self.pythonpath.clone()));
        envs.push(("PYTHONUNBUFFERED".into(), "1".into()));
        let allowed =
            env::join_paths(&self.allowed_paths).context("allowed path contains invalid UTF-8")?;
        let allowed = allowed
            .into_string()
            .map_err(|_| anyhow!("allowed path contains non-utf8 data"))?;
        envs.push(("PX_ALLOWED_PATHS".into(), allowed));
        envs.push((
            "PX_PROJECT_ROOT".into(),
            self.project_root.display().to_string(),
        ));
        envs.push(("PX_COMMAND_JSON".into(), command_args.to_string()));
        Ok(envs)
    }
}

fn build_pythonpath(
    fs: &dyn effects::FileSystem,
    project_root: &Path,
) -> Result<(String, Vec<PathBuf>)> {
    let mut paths = Vec::new();
    let src = project_root.join("src");
    if src.exists() {
        paths.push(src);
    }
    paths.push(project_root.to_path_buf());

    if let Ok(site_dir) = fs.canonicalize(&project_root.join(".px").join("site")) {
        paths.push(site_dir.clone());
        let pth = site_dir.join("px.pth");
        if pth.exists() {
            if let Ok(contents) = fs.read_to_string(&pth) {
                for line in contents.lines() {
                    let trimmed = line.trim();
                    if trimmed.is_empty() {
                        continue;
                    }
                    let path = PathBuf::from(trimmed);
                    if path.exists() {
                        paths.push(path);
                    }
                }
            }
        }
    }

    paths.retain(|p| p.exists());
    if paths.is_empty() {
        paths.push(project_root.to_path_buf());
    }

    let joined = env::join_paths(&paths).context("failed to build PYTHONPATH")?;
    let pythonpath = joined
        .into_string()
        .map_err(|_| anyhow!("pythonpath contains non-UTF paths"))?;
    Ok((pythonpath, paths))
}

fn ensure_project_environment_synced(project_root: &Path) -> Result<()> {
    let manifest_path = project_root.join("pyproject.toml");
    if !manifest_path.exists() {
        return Err(InstallUserError::new(
            format!("pyproject.toml not found in {}", project_root.display()),
            json!({
                "hint": "run `px migrate --apply` or pass ENTRY explicitly",
                "project_root": project_root.display().to_string(),
                "manifest": manifest_path.display().to_string(),
            }),
        )
        .into());
    }
    let snapshot = manifest_snapshot_at(project_root)?;
    let lock_path = snapshot.lock_path.clone();
    let lock = match load_lockfile_optional(&lock_path)? {
        Some(lock) => lock,
        None => {
            return Err(InstallUserError::new(
                "missing px.lock (run `px install`)",
                json!({
                    "lockfile": lock_path.display().to_string(),
                    "hint": "run `px install` to generate px.lock before running this command",
                }),
            )
            .into())
        }
    };

    let drift = detect_lock_drift(&snapshot, &lock, None);
    if !drift.is_empty() {
        return Err(InstallUserError::new(
            "px.lock is out of date",
            json!({
                "lockfile": lock_path.display().to_string(),
                "drift": drift,
                "hint": "run `px install` to refresh px.lock",
            }),
        )
        .into());
    }

    let missing = verify_locked_artifacts(&lock);
    if !missing.is_empty() {
        return Err(InstallUserError::new(
            "cached artifacts missing",
            json!({
                "lockfile": lock_path.display().to_string(),
                "missing": missing,
                "hint": "run `px install` to rehydrate the environment",
            }),
        )
        .into());
    }

    Ok(())
}

fn python_context(ctx: &CommandContext) -> Result<PythonContext, ExecutionOutcome> {
    match PythonContext::new(ctx) {
        Ok(py) => Ok(py),
        Err(err) => match err.downcast::<InstallUserError>() {
            Ok(user) => Err(ExecutionOutcome::user_error(user.message, user.details)),
            Err(err) => Err(ExecutionOutcome::failure(
                "failed to prepare python environment",
                json!({ "error": err.to_string() }),
            )),
        },
    }
}

pub fn to_json_response(info: CommandInfo, outcome: &ExecutionOutcome, _code: i32) -> Value {
    let status = match outcome.status {
        CommandStatus::Ok => "ok",
        CommandStatus::UserError => "user-error",
        CommandStatus::Failure => "failure",
    };
    let details = match &outcome.details {
        Value::Object(_) => outcome.details.clone(),
        Value::Null => json!({}),
        other => json!({ "value": other }),
    };
    json!({
        "status": status,
        "message": format_status_message(info, &outcome.message),
        "details": details,
    })
}

pub fn format_status_message(info: CommandInfo, message: &str) -> String {
    let group_name = info.group.to_string();
    let prefix = if group_name == info.name {
        format!("px {}", info.name)
    } else {
        format!("px {} {}", group_name, info.name)
    };
    if message.is_empty() {
        prefix
    } else if message.starts_with(&prefix) {
        message.to_string()
    } else {
        format!("{prefix}: {message}")
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::pypi::{PypiDigests, PypiFile};
    use px_lockfile::LockedDependency;
    use std::path::PathBuf;
    use tempfile::tempdir;

    use crate::SystemEffects;

    #[test]
    fn config_respects_env_flags() {
        let snapshot = EnvSnapshot::testing(&[
            ("PX_ONLINE", "1"),
            ("PX_RESOLVER", "1"),
            ("PX_FORCE_SDIST", "1"),
            ("PX_TEST_FALLBACK_STD", "1"),
            ("PX_SKIP_TESTS", "1"),
        ]);
        let effects = SystemEffects::new();
        let config = Config::from_snapshot(&snapshot, effects.cache()).expect("config");
        assert!(config.network.online);
        assert!(config.resolver.enabled);
        assert!(config.resolver.force_sdist);
        assert!(config.test.fallback_builtin);
        assert_eq!(config.test.skip_tests_flag.as_deref(), Some("1"));
    }

    #[test]
    fn resolver_enabled_by_default() {
        let snapshot = EnvSnapshot::testing(&[]);
        let effects = SystemEffects::new();
        let config = Config::from_snapshot(&snapshot, effects.cache()).expect("config");
        assert!(config.resolver.enabled);
    }

    #[test]
    fn resolver_can_be_disabled_via_env() {
        let snapshot = EnvSnapshot::testing(&[("PX_RESOLVER", "0")]);
        let effects = SystemEffects::new();
        let config = Config::from_snapshot(&snapshot, effects.cache()).expect("config");
        assert!(!config.resolver.enabled);
    }

    #[test]
    fn marker_applies_respects_python_version() {
        let env = px_project::resolver::current_marker_environment().expect("marker env");
        assert!(
            !marker_applies("tomli>=1.1.0; python_version < '3.11'", &env),
            "non-matching marker should be skipped"
        );
    }

    #[test]
    fn parse_exact_pin_handles_extras_and_markers() {
        let spec = r#"requests[socks]==2.32 ; python_version >= "3.10""#;
        let pin = parse_exact_pin(spec).expect("pin");
        assert_eq!(pin.name, "requests");
        assert_eq!(pin.version, "2.32");
        assert_eq!(pin.extras, vec!["socks".to_string()]);
        assert!(
            pin.specifier.contains("[socks]==2.32"),
            "specifier should include extras"
        );
        assert!(
            pin.marker
                .as_deref()
                .map(|m| m.contains("python_version"))
                .unwrap_or(false),
            "marker should be preserved"
        );
    }

    #[test]
    fn python_script_target_detects_relative_paths() {
        let root = PathBuf::from("/tmp/project");
        let (arg, path) =
            python_script_target("src/app.py", &root).expect("relative script detected");
        assert_eq!(arg, "src/app.py");
        assert_eq!(PathBuf::from(path), root.join("src/app.py"));
    }

    #[test]
    fn python_script_target_detects_absolute_paths() {
        let absolute = PathBuf::from("/opt/demo/main.py");
        let entry = absolute.to_string_lossy().to_string();
        let root = PathBuf::from("/tmp/project");
        let (arg, path) = python_script_target(&entry, &root).expect("absolute script detected");
        assert_eq!(arg, entry);
        assert_eq!(PathBuf::from(path), absolute);
    }

    #[test]
    fn python_script_target_ignores_non_python_files() {
        let root = PathBuf::from("/tmp/project");
        assert!(python_script_target("bin/tool", &root).is_none());
    }

    #[test]
    fn materialize_project_site_writes_cached_paths() {
        let temp = tempdir().expect("tempdir");
        let root = temp.path();
        let cache_dir = root.join("cache");
        fs::create_dir_all(&cache_dir).expect("cache dir");
        let wheel = cache_dir.join("demo-1.0.0.whl");
        fs::write(&wheel, b"demo").expect("wheel stub");
        let dist_dir = wheel.with_extension("dist");
        fs::create_dir_all(&dist_dir).expect("dist dir");

        let snapshot = ManifestSnapshot {
            root: root.to_path_buf(),
            manifest_path: root.join("pyproject.toml"),
            lock_path: root.join("px.lock"),
            name: "demo".into(),
            python_requirement: ">=3.11".into(),
            dependencies: Vec::new(),
        };
        let lock = LockSnapshot {
            version: 1,
            project_name: Some("demo".into()),
            python_requirement: Some(">=3.11".into()),
            dependencies: Vec::new(),
            mode: Some("p0-pinned".into()),
            resolved: vec![LockedDependency {
                name: "demo".into(),
                artifact: Some(LockedArtifact {
                    filename: "demo.whl".into(),
                    url: "https://example.invalid/demo.whl".into(),
                    sha256: "abc123".into(),
                    size: 4,
                    cached_path: wheel.display().to_string(),
                    python_tag: "py3".into(),
                    abi_tag: "none".into(),
                    platform_tag: "any".into(),
                }),
            }],
            graph: None,
        };

        let effects = SystemEffects::new();
        materialize_project_site(&snapshot, &lock, effects.fs()).expect("materialize site");

        let pxpth = snapshot.root.join(".px").join("site").join("px.pth");
        assert!(
            pxpth.exists(),
            ".px/site/px.pth should be created alongside install"
        );
        let contents = fs::read_to_string(pxpth).expect("read px.pth");
        assert!(
            contents.contains(dist_dir.to_str().unwrap()),
            "px.pth should reference unpacked artifact path"
        );
    }

    #[test]
    fn materialize_project_site_skips_missing_artifacts() {
        let temp = tempdir().expect("tempdir");
        let root = temp.path();
        let snapshot = ManifestSnapshot {
            root: root.to_path_buf(),
            manifest_path: root.join("pyproject.toml"),
            lock_path: root.join("px.lock"),
            name: "demo".into(),
            python_requirement: ">=3.11".into(),
            dependencies: Vec::new(),
        };
        let lock = LockSnapshot {
            version: 1,
            project_name: Some("demo".into()),
            python_requirement: Some(">=3.11".into()),
            dependencies: Vec::new(),
            mode: Some("p0-pinned".into()),
            resolved: vec![LockedDependency {
                name: "missing".into(),
                artifact: Some(LockedArtifact {
                    filename: "missing.whl".into(),
                    url: "https://example.invalid/missing.whl".into(),
                    sha256: "deadbeef".into(),
                    size: 0,
                    cached_path: root.join("nope").display().to_string(),
                    python_tag: "py3".into(),
                    abi_tag: "none".into(),
                    platform_tag: "any".into(),
                }),
            }],
            graph: None,
        };

        let effects = SystemEffects::new();
        materialize_project_site(&snapshot, &lock, effects.fs())
            .expect("materialize site with gap");
        let pxpth = snapshot.root.join(".px").join("site").join("px.pth");
        assert!(pxpth.exists(), "px.pth should still be created");
        let contents = fs::read_to_string(pxpth).expect("read px.pth");
        assert!(
            contents.trim().is_empty(),
            "missing artifacts should not be written to px.pth"
        );
    }

    #[test]
    fn select_wheel_prefers_linux_over_macos() {
        let files = vec![
            wheel_file("demo-1.0.0-cp312-cp312-macosx_10_13_x86_64.whl"),
            wheel_file("demo-1.0.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"),
        ];
        let tags = linux_interpreter_tags();
        let wheel = select_wheel(&files, &tags, "demo==1.0.0").expect("linux match");
        assert!(wheel.platform_tag.contains("manylinux"));
    }

    #[test]
    fn select_wheel_rejects_incompatible_platforms() {
        let files = vec![wheel_file("demo-1.0.0-cp312-cp312-macosx_10_13_x86_64.whl")];
        let tags = linux_interpreter_tags();
        let err = select_wheel(&files, &tags, "demo==1.0.0").expect_err("mac wheel rejected");
        assert!(err.to_string().contains("did not provide any wheels"));
    }

    #[test]
    fn heuristic_platform_matching_handles_manylinux() {
        let files = vec![wheel_file(
            "demo-1.0.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
        )];
        let mut tags = linux_interpreter_tags();
        tags.supported.clear();
        let wheel = select_wheel(&files, &tags, "demo==1.0.0").expect("fallback tags");
        assert!(wheel.platform_tag.contains("manylinux"));
    }

    fn wheel_file(name: &str) -> PypiFile {
        PypiFile {
            filename: name.into(),
            url: format!("https://example.invalid/{name}"),
            packagetype: "bdist_wheel".into(),
            yanked: Some(false),
            digests: PypiDigests {
                sha256: "deadbeef".into(),
            },
        }
    }

    fn linux_interpreter_tags() -> InterpreterTags {
        InterpreterTags {
            python: vec!["cp312".into(), "py312".into(), "py3".into()],
            abi: vec!["cp312".into(), "abi3".into(), "none".into()],
            platform: vec!["linux_x86_64".into(), "any".into()],
            supported: vec![
                InterpreterSupportedTag {
                    python: "cp312".into(),
                    abi: "cp312".into(),
                    platform: "manylinux_2_17_x86_64".into(),
                },
                InterpreterSupportedTag {
                    python: "cp312".into(),
                    abi: "cp312".into(),
                    platform: "manylinux2014_x86_64".into(),
                },
            ],
        }
    }
}
